{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPda6SoZtdOsvRA2stXf0wM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/RAG-Driven-Generative-AI/blob/main/Ch01_Why_Retrieval_Augmented_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rag Nedir"
      ],
      "metadata": {
        "id": "5plb-jw_zMNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG (Retrieval-Augmented Generation), dil modellerinin (LM) bilgiyi daha doğru ve esnek bir şekilde işlemesini sağlayan bir tekniktir. Bu yöntem, dil modelinin iki temel bileşeni birleştirir: bilgi alma (retrieval) ve metin oluşturma (generation).\n",
        "\n",
        "## RAG'nın Çalışma Prensibi\n",
        "\n",
        "1. **Bilgi Alma (Retrieval):**  \n",
        "   RAG, modele verilen bir girdi (örneğin, bir soru) üzerine, ilgili bilgileri büyük bir veri tabanından veya dış kaynaklardan (örneğin, belgeler, veritabanları veya web sayfaları) alır. Bu adım, modele dışarıdan bağlam ve güncel bilgiler sağlar.\n",
        "\n",
        "2. **Metin Oluşturma (Generation):**  \n",
        "   Alınan bilgiler, dil modeline beslenir ve model, bu bilgilere dayanarak bir yanıt veya metin üretir. Bu sayede, modelin ürettiği içerik daha doğru, alakalı ve güvenilir olur.\n",
        "\n",
        "### RAG'nın Avantajları:\n",
        "- **Daha Doğru Bilgi:** RAG, dil modelinin halüsinasyon yapma olasılığını azaltır (yanlış veya uydurma bilgi üretme). Çünkü model, doğruluğu bilinen dış kaynaklardan alınan bilgileri kullanarak yanıtlar üretir.\n",
        "- **Güncel Bilgiler:** Dil modelleri genellikle belirli bir eğitim verisiyle sınırlıdır ve zamanla güncelliklerini yitirebilirler. RAG, dış kaynaklardan bilgi alarak modelin daha güncel bilgilere erişmesini sağlar.\n",
        "- **Esneklik:** Farklı görevler için uyarlanabilir; örneğin, soru-cevap, özetleme veya içerik oluşturma gibi görevlerde kullanılabilir.\n",
        "\n",
        "### Kullanım Alanları:\n",
        "- **Soru-Cevap Sistemleri:** Kullanıcı sorularına daha doğru ve bağlama uygun yanıtlar vermek.\n",
        "- **Bilgi Tabanlı Metin Üretimi:** Teknik belgeler, raporlar veya makaleler oluşturmak için ilgili bilgileri dış kaynaklardan almak.\n",
        "- **Chatbot ve Sanal Asistanlar:** Daha bilgili ve doğru yanıtlar veren sohbet robotları oluşturmak.\n",
        "\n",
        "RAG, dil modellerinin yeteneklerini genişleten ve daha güvenilir sonuçlar elde etmelerini sağlayan önemli bir tekniktir."
      ],
      "metadata": {
        "id": "GiyWdcxa5WTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A RAG framework necessarily contains two main components:** a retriever and a generator"
      ],
      "metadata": {
        "id": "BMoajHvMzxpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG (Retrieval-Augmented Generation) çerçevesinin temel bileşenlerini Türkçe maddeler halinde açıklayalım:\n",
        "\n",
        "1. **Retriever (Bulucu/ Erişim Bileşeni)**:\n",
        "   - RAG çerçevesinin ilk ana bileşeni \"Retriever\" olarak adlandırılır.\n",
        "   - Bu bileşen, verilen bir girdi (örneğin, bir soru) temelinde, ilgili bilgilerin büyük bir veri tabanından veya bilgi kaynağından alınmasını sağlar.\n",
        "   - Retriever, genellikle anlamsal arama veya benzerlik tabanlı arama yöntemlerini kullanarak ilgili belgeleri, pasajları veya bilgileri bulur.\n",
        "\n",
        "2. **Generator (Üretici)**:\n",
        "   - RAG çerçevesinin ikinci ana bileşeni \"Generator\"dır.\n",
        "   - Bu bileşen, Retriever tarafından bulunan ilgili bilgilere dayanarak, belirli bir görevi yerine getirmek için metin üretir (örneğin, bir soruyu yanıtlama).\n",
        "   - Generator, genellikle bir dil modelidir ve Retriever tarafından sağlanan bağlamı kullanarak tutarlı ve ilgili metinler üretir.\n",
        "\n",
        "Bu iki bileşen birlikte çalışarak, RAG çerçevesi karmaşık görevleri daha etkili bir şekilde yerine getirebilir. Örneğin, bir soru-cevap görevinde, Retriever ilgili bilgileri bulur ve Generator bu bilgilere dayanarak doğru ve anlamlı bir yanıt üretir."
      ],
      "metadata": {
        "id": "sKjASC9q5wE4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retriever ve Generator modelleri, özellikle doğal dil işleme (NLP) alanında, bilgi erişimi ve metin üretme görevlerinde kullanılan önemli bileşenlerdir. Bu iki tip modelin bir arada kullanılması, örneğin, bir soru-cevap sistemi veya diyalog sistemi oluştururken sıkça karşılaşılan bir yaklaşımdır. Retriever, ilgili belgeleri veya bilgileri büyük bir veri tabanından çekip alırken, Generator bu bilgileri kullanarak yeni metinler üretir.\n",
        "\n",
        "İşte Retriever ve Generator modelleri için kullanılan bazı popüler araçlar ve kütüphaneler:\n",
        "\n",
        "## Rag Bölümleri\n",
        "\n",
        "\n",
        "## Retriever\n",
        "\n",
        "1. **Dense Passage Retriever (DPR)**: DPR, Facebook AI tarafından geliştirilen ve metin tabanlı sorular için ilgili pasajları yoğun vektör temsilleri kullanarak getiren bir retriever modelidir.\n",
        "   - **Örnek:** `transformers` kütüphanesi DPR'yi destekler.\n",
        "\n",
        "2. **Elasticsearch**: Elasticsearch, büyük ölçekli veri aramalarında kullanılan güçlü bir arama ve analiz motorudur. Metin tabanlı retriever uygulamaları için sıkça kullanılır.\n",
        "   - **Örnek:** Python'da `elasticsearch` kütüphanesi kullanılarak etkileşime geçilebilir.\n",
        "\n",
        "3. **FAISS (Facebook AI Similarity Search)**: FAISS, yoğun vektörler arasında hızlı benzerlik araması yapmak için kullanılan bir kütüphanedir.\n",
        "   - **Örnek:** `faiss` kütüphanesi Python ve C++ için kullanılabilir.\n",
        "\n",
        "## Generator için:\n",
        "\n",
        "1. **Transformers (Hugging Face)**: Hugging Face'in `transformers` kütüphanesi, birçok önceden eğitilmiş dil modeli (BERT, T5, BART, vb.) için arayüz sağlar. Bu modeller metin üretme görevlerinde kullanılabilir.\n",
        "   - **Örnek:** T5 veya BART modelleri metin üretme için kullanılabilir.\n",
        "\n",
        "2. **T5 (Text-to-Text Transfer Transformer)**: T5, metin-den-metne formatında çeşitli NLP görevlerini yerine getirebilen bir modeldir.\n",
        "   - **Örnek:** `transformers` kütüphanesi T5'yi destekler.\n",
        "\n",
        "3. **BART**: BART, denoising otomatik kodlayıcı olarak eğitilen ve metin üretme dahil birçok NLP görevinde kullanılabilen bir modeldir.\n",
        "   - **Örnek:** `transformers` kütüphanesi BART'ı destekler.\n",
        "\n",
        "### Örnek Uygulama:\n",
        "\n",
        "Bir soru-cevap sistemi düşünün. Burada Retriever (örneğin DPR) ilk olarak büyük bir belge havuzundan soruyla ilgili belgeleri çeker. Daha sonra, Generator (örneğin T5 veya BART) bu belgeleri kullanarak sorunun cevabını üretir.\n",
        "\n",
        "```python\n",
        "from transformers import DPRContextEncoder, DPRQuestionEncoder, T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Retriever için DPR modelini yükle\n",
        "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n",
        "\n",
        "# Generator için T5 modelini ve tokenizer'ı yükle\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# Örnek kullanım\n",
        "input_ids = tokenizer(\"Soru: Türkiye'nin başkenti neresidir?\", return_tensors=\"pt\").input_ids\n",
        "output = model.generate(input_ids)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))\n",
        "```\n",
        "\n",
        "Bu örnek, Retriever ve Generator'un nasıl kullanılabileceğine dair basit bir gösterimdir. Gerçek dünya uygulamalarında, Retriever ve Generator bileşenlerinin eğitimi, ayarlanması ve birleştirilmesi daha karmaşık olabilir."
      ],
      "metadata": {
        "id": "lRxkZ0pz6ChQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DPRContextEncoder, DPRQuestionEncoder, T5ForConditionalGeneration, T5Tokenizer\n",
        "\n",
        "# Retriever için DPR modelini yükle\n",
        "ctx_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-multiset-base\")\n",
        "question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-multiset-base\")\n",
        "\n",
        "# Generator için T5 modelini ve tokenizer'ı yükle\n",
        "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "# Örnek kullanım\n",
        "input_ids = tokenizer(\"Soru: Türkiye'nin başkenti neresidir?\", return_tensors=\"pt\").input_ids\n",
        "output = model.generate(input_ids)\n",
        "\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_ec-lLc6SNw",
        "outputId": "db5c3339-da59-4869-f4ec-07fff5480551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at facebook/dpr-question_encoder-multiset-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
            "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "şkenti neresidir?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# RAG ya da Fine-Tuning\n",
        "\n",
        "## Genel Bakış\n",
        "\n",
        "RAG ve Fine-Tuning, makine öğrenmesi modellerinin geliştirilmesinde kullanılan iki farklı yaklaşımdır. Bu iki yaklaşım arasındaki farkları ve hangi durumda hangisinin kullanılması gerektiğini anlamak önemlidir.\n",
        "\n",
        "## RAG ve Fine-Tuning Arasındaki Farklar\n",
        "\n",
        "* RAG, parametrik olmayan (non-parametric) bilgi kullanırken, Fine-Tuning parametrik (parametric) bilgi kullanır.\n",
        "* RAG, veri tabanında depolanan verileri kullanarak çıktı üretirken, Fine-Tuning modelin ağırlıklarını güncelleyerek çıktı üretir.\n",
        "* RAG, dinamik ve değişken verilerle çalışırken, Fine-Tuning statik verilerle çalışır.\n",
        "\n",
        "## Hangi Durumda RAG Kullanılmalıdır?\n",
        "\n",
        "* Veri dinamik ve sürekli değişiyorsa (örneğin, hava durumu, hisse senedi değerleri, şirket haberleri).\n",
        "* Veri çok büyük ve yönetilmesi zor ise, RAG kullanmak daha uygun olabilir.\n",
        "\n",
        "## Hangi Durumda Fine-Tuning Kullanılmalıdır?\n",
        "\n",
        "* Veri statik ve değişmiyorsa.\n",
        "* Modelin belirli bir görev için optimize edilmesi gerekiyorsa.\n",
        "\n",
        "## RAG ve Fine-Tuning Birlikte Kullanılabilir\n",
        "\n",
        "* RAG, modelin genel verimliliğini artırmak için kullanılabilir.\n",
        "* Fine-Tuning, RAG çerçevesindeki retrieval ve generation bileşenlerinin performansını artırmak için kullanılabilir.\n",
        "\n",
        "## Karar Verme Eşiği\n",
        "\n",
        "* Projenin özel gereksinimleri ve hedefleri dikkate alınarak, RAG ve Fine-Tuning arasında bir denge kurulmalıdır.\n",
        "* Parametrik ve non-parametrik bilgi arasındaki oran, hangi yaklaşımın kullanılacağına karar vermede önemlidir."
      ],
      "metadata": {
        "id": "b_w3S6ai4zPd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Bileşenleri"
      ],
      "metadata": {
        "id": "SY1Ic_U78bMS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu kavramlar, genellikle Yapay Zeka (YZ) ve özellikle de Dil Modelleri (LM) veya Generative AI sistemlerinde kullanılan bileşenlerdir. Her birinin işlevini açıklayalım:\n",
        "\n",
        "1. **The Retriever (D - Veri Çekici/Toplayıcı)**:\n",
        "   - Veri toplama, işleme, depolama ve geri alma işlemlerini yönetir.\n",
        "   - Sistemin ihtiyaç duyduğu bilgileri veritabanlarından veya diğer kaynaklardan çekmekle sorumludur.\n",
        "   - Alınan veriler genellikle modelin eğitilmesi, doğrulanması veya çıktı üretebilmesi için gerekli olan verilerdir.\n",
        "\n",
        "2. **The Generator (G - Üretici)**:\n",
        "   - Giriş artırma (input augmentation), prompt mühendisliği (prompt engineering) ve içerik üretme (generation) işlemlerini gerçekleştirir.\n",
        "   - Kullanıcıdan alınan girdileri işler ve uygun çıktılar üretir.\n",
        "   - Prompt mühendisliği, modelden istenen çıktıyı alabilmek için girdilerin nasıl düzenleneceğini belirleme sürecidir.\n",
        "\n",
        "3. **The Evaluator (E - Değerlendirici)**:\n",
        "   - Matematiksel metrikler kullanarak üretilen çıktıların kalitesini değerlendirir.\n",
        "   - İnsan değerlendirmesi yaparak, üretilen içeriklerin doğruluğunu, anlaşılırlığını veya diğer kriterlere uygunluğunu kontrol eder.\n",
        "   - Geri bildirim (feedback) sağlayarak, sistemin daha sonraki iterasyonlarında iyileştirmeler yapılmasına yardımcı olur.\n",
        "\n",
        "4. **The Trainer (T - Eğitici)**:\n",
        "   - Başlangıçta önceden eğitilmiş modeli (pre-trained model) yönetir.\n",
        "   - Modelin ince ayarını (fine-tuning) yapar; yani modeli belirli bir görev veya veri setine özel olarak daha da eğitir.\n",
        "   - Bu sayede model, genel yeteneklerini koruyarak spesifik alanlarda daha başarılı hale getirilir.\n",
        "\n",
        "Bu bileşenler, bir Yapay Zeka sisteminin geliştirilmesinde ve çalıştırılmasında kritik rollere sahiptir. Özellikle dil modellemesi ve içerik üretimi gibi alanlarda, bu bileşenlerin etkili bir şekilde çalışması sistemin başarısını doğrudan etkiler."
      ],
      "metadata": {
        "id": "pjDfBxdo7SIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG (Retrieval-Augmented Generation) ekosisteminin retriever bileşeni ve ilgili kavramları açıklayacağım.\n",
        "\n",
        "## **The Retriever (D)**:\n",
        "\n",
        " RAG ekosisteminin retriever bileşeni, veri toplama, işleme, depolama ve geri alma işlemlerini gerçekleştirir. Bu bileşen, RAG ekosisteminin başlangıç noktasıdır ve veri toplama sürecini başlatır.\n",
        "\n",
        "**Collect (D1)**: Veri toplama aşaması, çeşitli kaynaklardan (blog gönderileri, resimler, ses dosyaları, videolar vb.) veri toplama işlemidir. Bu veriler farklı formatlarda (PDF, JSON, MP3, MP4, PNG, JPG vb.) olabilir ve yapılandırılmamış veya karmaşık bir şekilde bulunabilir. Pinecone, OpenAI, Chroma ve Activeloop gibi platformlar, bu verileri işlemek ve depolamak için hazır araçlar sağlar.\n",
        "\n",
        "**Process (D2)**: Veri işleme aşaması, toplanan verilerin işlenmesi ve dönüştürülmesini içerir. Bu aşamada, veri nesneleri (örneğin, metin, resim, video) çıkarılır, chunking (parçalara ayırma), embedding (vektörlere dönüştürme) ve indexing (dizinleme) gibi teknikler kullanılarak uniform özellik temsilleri oluşturulur.\n",
        "\n",
        "**Storage (D3)**: Veri depolama aşaması, işlenen verilerin depolanmasını içerir. Vector store'lar (örneğin, Deep Lake, Pinecone, Chroma) gibi akıllı kütüphaneler, verileri matematiksel varlıklar olarak vektörlere dönüştürerek güçlü hesaplamalar yapabilir. Bu sayede, veriler dinamik ve sorgulanabilir bir sistem haline getirilir.\n",
        "\n",
        "**Retrieval Query (D4)**: Geri alma sorgusu, kullanıcı girdisi veya otomatik girdi (G1) tarafından tetiklenir. Veriler, uygun bir formata dönüştürülerek vector store'lara ve veri kümelerine yüklenir. Ardından, anahtar kelime aramaları, akıllı embedding'ler ve indexing gibi teknikler kullanılarak veriler etkin bir şekilde geri alınır. Örneğin, cosine similarity kullanılarak, birbirine yakın olan öğeler bulunabilir ve arama sonuçları hızlı ve ilgili hale getirilir.\n",
        "\n",
        "Bu kavramlar, RAG ekosisteminin retriever bileşeninin temel öğelerini oluşturur ve büyük miktarda veri işleme, depolama ve geri alma işlemlerini etkin bir şekilde gerçekleştirmeyi sağlar.\n"
      ],
      "metadata": {
        "id": "JeVpEBg07zdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAG (Retrieval-Augmented Generation) ekosistemindeki \"Generator (G)\" kavramını ve ilgili bileşenlerini ayrıntılı olarak açıklayacağım.\n",
        "\n",
        "## **Generator (G)**\n",
        "\n",
        "Generator, RAG ekosisteminde girdi (input) ile retrieval (D) arasındaki etkileşimi takiben, üretken bir model kullanarak çıktı (output) üreten bileşendir.\n",
        "\n",
        "**Generator Bileşenleri**\n",
        "\n",
        "1. **Girdi (G1)**\n",
        " * Girdi, otomatik görevler (örneğin e-posta işleme) veya Kullanıcı Arayüzü (UI) üzerinden insan tarafından girilen komutlar olabilir.\n",
        " * Bu esneklik, çeşitli endüstrilerde üretkenliği artırmak için AI'nın sorunsuz bir şekilde entegre edilmesini sağlar.\n",
        "2. **Artırılmış Girdi ile İnsan Geri Bildirimi (G2)**\n",
        " * Girdiye insan geri bildirimi (HF) eklenebilir.\n",
        " * İnsan geri bildirimi, RAG ekosistemini oldukça uyarlanabilir hale getirir ve veri alma ve üretken AI girdileri üzerinde tam kontrol sağlar.\n",
        "3. **Prompt Mühendisliği (G3)**\n",
        " * Hem retriever (D) hem de generator (G), üretken AI modelinin işleyeceği standart ve artırılmış mesajı hazırlamak için prompt mühendisliğine büyük ölçüde güvenmektedir.\n",
        " * Prompt mühendisliği, retriever'ın çıktısını ve kullanıcı girdisini bir araya getirir.\n",
        "4. **Üretim ve Çıktı (G4)**\n",
        " * Bir üretken AI modelinin seçimi, projenin hedeflerine bağlıdır.\n",
        " * Llama, Gemini, GPT ve diğer modeller çeşitli gereksinimlere uyabilir.\n",
        " * Ancak, prompt her modelin spesifikasyonlarını karşılamalıdır.\n",
        " * LangChain gibi çerçeveler, çeşitli AI modellerini uygulamalara entegre etmeyi kolaylaştırarak uyarlanabilir arayüzler ve araçlar sağlar.\n",
        "\n",
        "RAG ekosistemini kullanan bazı örnekler:\n",
        "\n",
        "* Otomatik e-posta işleme ve yanıtlama sistemleri\n",
        "* İnsan-insan etkileşimi içeren sohbet robotları\n",
        "* İçerik oluşturma ve düzenleme araçları\n",
        "* Akıllı metin özetleme ve çeviri sistemleri\n",
        "\n",
        "Bu örnekler, RAG ekosisteminin çeşitli endüstrilerde ve uygulamalarda nasıl kullanılabileceğini göstermektedir."
      ],
      "metadata": {
        "id": "qmXVBBr78ORy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Değerlendirici (E)**\n",
        "\n",
        "Bir üretken yapay zeka modelinin performansını değerlendirmek için genellikle matematiksel ölçütlere güveniyoruz. Ancak, bu ölçütler bize sadece resmin bir kısmını verir. Bir yapay zeka'nın etkinliğinin nihai testinin insan değerlendirmesine bağlı olduğu unutulmamalıdır.\n",
        "\n",
        "**Değerlendirme Kavramları**\n",
        "\n",
        "Aşağıdaki kavramlar, bir üretken yapay zeka modelinin değerlendirilmesinde önemli rol oynar:\n",
        "\n",
        "1. **Ölçütler (E1) / Metrics**\n",
        "   - **Tanım:** Matematiksel ölçütler, bir yapay zeka sisteminin performansı hakkında sayısal değerler sağlar.\n",
        "   - **Örnekler:**\n",
        "     - **Cosine Similarity (Kosinüs Benzerliği):** İki vektör arasındaki benzerliği ölçer.\n",
        "     - **Diğer ölçütler:** Precision (Hassasiyet), Recall (Geri Çağırma), F1 Score, vb.\n",
        "   - **Açıklama:** Bu ölçütler, alınan verilerin alakalı ve doğru olduğunu garanti eder. Veri noktaları arasındaki ilişkileri ve alaka düzeyini nicelendirerek modelin performansı ve güvenilirliği için sağlam bir temel sağlar.\n",
        "\n",
        "2. **İnsan Geri Bildirimi (E2) / Human Feedback**\n",
        "   - **Tanım:** Üretken yapay zeka sistemlerinin nihai değerlendirmesi insan tarafından yapılır.\n",
        "   - **Açıklama:** Matematiksel ölçütler ne kadar yeterli görünse de, bir sistemin insan kullanıcılar tarafından kabul görüp görmeyeceği veya eleştirilip eleştirilmeyeceği insan değerlendirmesine bağlıdır.\n",
        "   - **Uyarlanabilir RAG (Adaptive RAG):** İnsan, gerçek hayat, pragmatik geri bildirim faktörünü tanıtır ve böylece RAG tarafından yönlendirilen üretken yapay zeka ekosistemini geliştirir.\n",
        "\n",
        "**Uyarlanabilir RAG Ekosistemleri**\n",
        "\n",
        "Uyarlanabilir RAG, insan geri bildirimi ile geliştirilen bir RAG-driven (Retrieval-Augmented Generation, yani Alıntı ile Artırılmış Üretim) üretken yapay zeka ekosistemidir. Bu ekosistemler, aşağıdaki özelliklere sahiptir:\n",
        "\n",
        "- **İnsan Geri Bildirimini Entegrasyon:** Sistem, kullanıcıların geri bildirimlerini dikkate alarak kendini geliştirir.\n",
        "- **Gelişmiş Performans:** Uyarlanabilir RAG, RAG performansını artırmak için uzman insan geri bildirimini kullanır.\n",
        "- **Gerçek Hayat Uygulamaları:** Sistemler, gerçek hayat senaryolarında daha etkili hale gelir.\n",
        "\n",
        "Örnek ekosistemler:\n",
        "- **Sanal Asistanlar:** İnsan geri bildirimi ile daha doğru ve alakalı yanıtlar veren sanal asistanlar.\n",
        "- **Otomatik İçerik Üretimi:** İnsan geri bildirimi ile daha kaliteli ve ilgili içerik üreten sistemler.\n",
        "- **Akıllı Öğrenme Sistemleri:** Kullanıcı geri bildirimleri ile öğrenme materyallerini kişiselleştiren eğitim platformları.\n",
        "\n",
        "Bu ekosistemler, üretken yapay zeka modellerinin daha etkili ve kullanıcı dostu olmasına katkıda bulunur."
      ],
      "metadata": {
        "id": "1vamRuIn835o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aşağıdaki açıklamaları dikkate alarak, teknik terimleri İngilizce olarak ve yanına Türkçe karşılıklarını yazarak ayrıntılı ve maddeler halinde açıklayacağım. Ayrıca, bu özellikleri taşıyan ekosistemleri sıralayacağım.\n",
        "\n",
        "## Trainer (T)\n",
        "\n",
        "**Açıklamalar:**\n",
        "\n",
        "1. **The Trainer (T) - Eğitici (T)**: Standart bir üretken yapay zeka modeli (Generative AI Model), geniş kapsamlı genel amaçlı verilerle önceden eğitilir (Pre-trained).\n",
        "\t* **Pre-trained**: Önceden eğitilmiş\n",
        "\t* **Generative AI Model**: Üretken Yapay Zeka Modeli\n",
        "2. **Fine-Tuning (T2) - İnce Ayar**: Model, alan특化 verileriyle (Domain-specific data) ince ayar yapılarak daha da geliştirilir.\n",
        "\t* **Domain-specific data**: Alanına özgü veriler\n",
        "\t* **Fine-Tuning**: İnce ayar yapma\n",
        "3. **Static RAG Data - Statik RAG Verileri**: Statik RAG verileri, ince ayar sürecine entegre edilir.\n",
        "\t* **RAG**: Retrieval-Augmented Generation (Alıntı ile Geliştirilmiş Üretim)\n",
        "\t* **Static RAG Data**: Statik RAG verileri\n",
        "4. **Human Feedback - İnsan Geri Bildirimi**: İnsan geri bildirimi, değerli bilgiler sağlar ve Reinforcement Learning from Human Feedback (RLHF) varyantında ince ayar sürecine entegre edilebilir.\n",
        "\t* **Human Feedback**: İnsan geri bildirimi\n",
        "\t* **Reinforcement Learning from Human Feedback (RLHF)**: İnsan Geri Bildiriminden Pekiştirmeli Öğrenme\n",
        "5. **Entry-level Naïve, Advanced, and Modular RAG - Giriş Seviyesi Naif, Gelişmiş ve Modüler RAG**: Python'da giriş seviyesi naif, gelişmiş ve modüler RAG kodlanmaya hazırdır.\n",
        "\t* **Naïve RAG**: Naif RAG\n",
        "\t* **Advanced RAG**: Gelişmiş RAG\n",
        "\t* **Modular RAG**: Modüler RAG\n",
        "\n",
        "**Bu özellikleri taşıyan ekosistemler:**\n",
        "\n",
        "1. **Hugging Face**: Hugging Face, üretken yapay zeka modelleri için popüler bir platformdur ve RAG gibi çeşitli modelleri destekler.\n",
        "2. **Transformers**: Transformers, üretken yapay zeka modelleri için popüler bir kütüphanedir ve RAG gibi çeşitli modelleri destekler.\n",
        "3. **TensorFlow**: TensorFlow, büyük ölçekli yapay zeka uygulamaları için popüler bir framework'tür ve RAG gibi çeşitli modelleri destekler.\n",
        "4. **PyTorch**: PyTorch, üretken yapay zeka modelleri için popüler bir kütüphanedir ve RAG gibi çeşitli modelleri destekler.\n",
        "\n",
        "Bu ekosistemler, üretken yapay zeka modelleri geliştirmek ve RAG gibi çeşitli modelleri desteklemek için çeşitli araçlar ve kütüphaneler sağlar."
      ],
      "metadata": {
        "id": "vFtA8G8o9qVZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aşağıdaki metni dikkate alarak, Türkçe olarak teknik terimleri İngilizce ve yanında Türkçe olarak yazarak, ayrıntılı ve maddeler halinde açıklayacağım. Ayrıca, bunu yapan ekosistemleri de yazacağım.\n",
        "\n",
        "# **RAG (Retrieval-Augmented Generation) Ekosistemleri**\n",
        "\n",
        "RAG, bir conversational agent'ın (sohbet robotu) sorularını yanıtlamak için kullanılan bir tekniktir. Aşağıdaki maddelerde, RAG'ın temel bileşenlerini ve ekosistemlerini açıklayacağım.\n",
        "\n",
        "**1. Naïve, Advanced ve Modular RAG**\n",
        "\n",
        "* **Naïve RAG (Basit RAG)**: Anahtar kelime eşleştirme (Keyword Matching) ve basit arama yöntemleri kullanarak belge erişimini sağlar.\n",
        "* **Advanced RAG (Gelişmiş RAG)**: Vektör arama (Vector Search) ve indeks tabanlı arama (Index-Based Search) yöntemleri kullanarak daha gelişmiş belge erişimini sağlar.\n",
        "* **Modular RAG (Modüler RAG)**: Esnek belge erişim yöntemleri kullanarak, farklı arama tekniklerini bir arada kullanmayı sağlar.\n",
        "\n",
        "**2. Temel Bileşenler**\n",
        "\n",
        "* **Generator Function (Üretici Fonksiyon)**: OpenAI'ın GPT-4o modelini kullanarak, kullanıcı girişlerine göre yanıtlar üretir.\n",
        "* **Retriever (Belge Erişim Birimi)**: Belge erişimini sağlamak için kullanılan bir bileşendir. Naïve, Advanced ve Modular RAG tekniklerini kullanarak belge erişimini sağlar.\n",
        "* **Data Setup (Veri Kurulumu)**: Belge listesi (db_records) oluşturularak, belge erişimini sağlamak için kullanılır.\n",
        "\n",
        "**3. Ekosistemler**\n",
        "\n",
        "* **OpenAI GPT-4o**: Üretici fonksiyon tarafından kullanılan bir dil modelidir.\n",
        "* **Python**: RAG'ın temel bileşenlerini oluşturmak için kullanılan bir programlama dilidir.\n",
        "* **GitHub Repository**: RAG_Overview.ipynb adlı notebook'u içeren bir depodur.\n",
        "\n",
        "**4. Uygulama Adımları**\n",
        "\n",
        "1. **Environment Setup (Çevre Kurulumu)**: OpenAI API entegrasyonu için çevre kurulumu yapılır.\n",
        "2. **Generator Function (Üretici Fonksiyon)**: GPT-4o modelini kullanarak yanıtlar üretmek için bir fonksiyon oluşturulur.\n",
        "3. **Data Setup (Veri Kurulumu)**: Belge listesi (db_records) oluşturulur.\n",
        "4. **Query (Sorgu)**: Kullanıcı girişi için bir sorgu oluşturulur.\n",
        "5. **Retrieval Metrics (Belge Erişim Ölçütleri)**: Belge erişim yanıtlarını ölçmek için kullanılan ölçütlerdir.\n",
        "6. **Naïve RAG, Advanced RAG ve Modular RAG**: Farklı belge erişim teknikleri kullanılarak belge erişimini sağlar.\n"
      ],
      "metadata": {
        "id": "6DBIb50z97Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Foundations and basic implementation"
      ],
      "metadata": {
        "id": "P-qTTJorHCEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Environment"
      ],
      "metadata": {
        "id": "XCS57PnrHqY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. OpenAI Kütüphanesinin Kurulumu**\n",
        "\n",
        "İlk olarak, GPT-4o modeline erişmek için OpenAI kütüphanesinin (`openai`) kurulması gerekmektedir. Bunun için aşağıdaki komut kullanılır:\n",
        "\n",
        "`!pip install openai==1.40.3`\n",
        "\n",
        "Bu komut, OpenAI kütüphanesinin 1.40.3 sürümünü kurar. Sürümün dondurulması (freezing) önerilir, çünkü RAG framework ekosisteminde birçok paket kurulacaktır ve sürüm uyumsuzlukları sorunlara neden olabilir.\n",
        "\n",
        "**2. API Anahtarının Alınması**\n",
        "\n",
        "OpenAI kütüphanesi kurulduktan sonra, bir OpenAI hesabı oluşturulması ve bir API anahtarı alınması gerekir. API anahtarını almadan önce, maliyetlerin ve ödeme planlarının kontrol edilmesi önerilir.\n",
        "\n",
        "**3. API Anahtarının Saklanması ve Okunması**\n",
        "\n",
        "API anahtarı alındıktan sonra, güvenli bir yerde saklanması gerekir. Bu örnekte, Google Drive kullanılmıştır, ancak başka yöntemler de kullanılabilir. API anahtarı, bir dosyadan okunabilir veya doğrudan koda girilebilir.\n",
        "\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY = f.readline().strip()\n",
        "f.close()\n",
        "```\n",
        "\n",
        "Bu kod, Google Drive'ı bağlar ve `api_key.txt` dosyasından API anahtarını okur.\n",
        "\n",
        "**4. OpenAI API Anahtarının Tanımlanması**\n",
        "\n",
        "API anahtarı okunduktan sonra, OpenAI kütüphanesine tanımlanması gerekir:\n",
        "\n",
        "```python\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] = API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "```\n",
        "\n",
        "Bu kod, API anahtarını ortam değişkeni olarak tanımlar ve OpenAI kütüphanesine atar.\n",
        "\n",
        "**Diğer Teknikler ve Kütüphaneler**\n",
        "\n",
        "Bu örnekte, OpenAI kütüphanesinin yanı sıra, Google Colab ve Google Drive kullanılmıştır. Başka yöntemler de kullanılabilir, örneğin:\n",
        "\n",
        "* API anahtarını doğrudan koda girmek yerine, bir çevre değişkeni olarak tanımlamak.\n",
        "* API anahtarını bir kütüphane veya framework'un sağladığı bir mekanizma ile saklamak ve okumak.\n",
        "\n",
        "**Kodların Açıklaması**\n",
        "\n",
        "Kullanılan kodlar, OpenAI kütüphanesinin kurulumu, API anahtarının alınması, saklanması ve okunması, ve OpenAI kütüphanesine tanımlanması işlemlerini gerçekleştirir. Bu işlemler, bir projenin başlangıç aşamasında gerekli olan ortam kurulumu için önemlidir.\n",
        "\n",
        "**Neden Böyle Yapılıyor?**\n",
        "\n",
        "Ortam kurulumu, bir projenin başlangıç aşamasında önemlidir, çünkü doğru kütüphanelerin ve API anahtarlarının kullanılmasını sağlar. API anahtarının güvenli bir şekilde saklanması ve okunması, kötü amaçlı kişilerin anahtara erişmesini engellemek için önemlidir. OpenAI kütüphanesinin doğru sürümünün kurulması, uyumsuzlukları önlemek için önemlidir."
      ],
      "metadata": {
        "id": "xtDDAQC1HtKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - The Generator"
      ],
      "metadata": {
        "id": "Rl2otp0kIXhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Yapılacak İşlemler ve Açıklamaları**\n",
        "\n",
        "Aşağıdaki kod, OpenAI'nın GPT-4o modelini kullanarak bir metin oluşturma (text generation) işlemi gerçekleştirmektedir. Kod, öncelikle OpenAI kütüphanesini içe aktarır (`import openai`) ve bir OpenAI istemcisi (`client`) oluşturur.\n",
        "\n",
        "### Kodun İşlevi\n",
        "\n",
        "1. **Metin Oluşturma Fonksiyonu**: `call_llm_with_full_text` adlı fonksiyon, bir girdi metni (`itext`) alır ve GPT-4o modeline bir istem (`prompt`) gönderir. İstem, girdi metni ve bir talimat içerir.\n",
        "2. **GPT-4o Modeline İstem Gönderme**: Fonksiyon, GPT-4o modeline bir istek gönderir ve yanıtı alır. İstek, bir sistem mesajı, bir asistan mesajı ve bir kullanıcı mesajı içerir. Sistem mesajı, modelin bir Doğal Dil İşleme (Natural Language Processing, NLP) uzmanı olduğunu belirtir. Asistan mesajı, modelin girdi metni okuyup ayrıntılı bir yanıt vermesi gerektiğini belirtir. Kullanıcı mesajı, girdi metni ve talimatı içerir.\n",
        "3. **Yanıtın Biçimlendirilmesi**: `print_formatted_response` adlı fonksiyon, GPT-4o modelinden alınan yanıtı biçimlendirir ve yazdırır. Yanıt, `textwrap` kütüphanesi kullanılarak 80 sütun genişliğinde bir paragraf olarak biçimlendirilir.\n",
        "\n",
        "### Kullanılan Teknikler ve Parametreler\n",
        "\n",
        "* **GPT-4o Modeli**: OpenAI tarafından geliştirilen bir büyük dil modelidir (Large Language Model, LLM).\n",
        "* **Temperature Parametresi**: Modelin yaratıcılığını kontrol eden bir parametredir. Düşük değerler (örneğin, 0.1) daha kesin yanıtlar üretirken, yüksek değerler (örneğin, 0.7) daha yaratıcı yanıtlar üretir.\n",
        "* **Textwrap Kütüphanesi**: Metni biçimlendirmek için kullanılan bir kütüphanedir.\n",
        "\n",
        "### Kodun Açıklaması\n",
        "\n",
        "```python\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import time\n",
        "\n",
        "# OpenAI istemcisi oluşturma\n",
        "client = OpenAI()\n",
        "gptmodel = \"gpt-4o\"\n",
        "\n",
        "# Metin oluşturma fonksiyonu\n",
        "def call_llm_with_full_text(itext):\n",
        "    # Girdi metni birleştirme\n",
        "    text_input = '\\n'.join(itext)\n",
        "    prompt = f\"Please elaborate on the following content:\\n{text_input}\"\n",
        "\n",
        "    try:\n",
        "        # GPT-4o modeline istek gönderme\n",
        "        response = client.chat.completions.create(\n",
        "            model=gptmodel,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
        "                {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.1  # Temperature parametresi\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception as e:\n",
        "        return str(e)\n",
        "\n",
        "# Yanıt biçimlendirme fonksiyonu\n",
        "import textwrap\n",
        "def print_formatted_response(response):\n",
        "    # Yanıtı biçimlendirme\n",
        "    wrapper = textwrap.TextWrapper(width=80)\n",
        "    wrapped_text = wrapper.fill(text=response)\n",
        "    print(\"Response:\")\n",
        "    print(\"---------------\")\n",
        "    print(wrapped_text)\n",
        "    print(\"---------------\")\n",
        "```\n",
        "\n",
        "### Neden Böyle Yapıldı?\n",
        "\n",
        "* GPT-4o modeli, büyük bir dil modelidir ve çeşitli doğal dil işleme görevlerinde kullanılabilir.\n",
        "* Temperature parametresi, modelin yaratıcılığını kontrol etmek için kullanılır. Düşük değerler daha kesin yanıtlar üretirken, yüksek değerler daha yaratıcı yanıtlar üretir.\n",
        "* Textwrap kütüphanesi, metni biçimlendirmek için kullanılır ve yanıtı daha okunabilir hale getirir.\n",
        "\n",
        "### Başka Teknikler\n",
        "\n",
        "* Diğer büyük dil modelleri (örneğin, BERT, RoBERTa) de metin oluşturma görevlerinde kullanılabilir.\n",
        "* Farklı parametreler (örneğin, `max_tokens`, `top_p`) de modelin davranışını kontrol etmek için kullanılabilir."
      ],
      "metadata": {
        "id": "1vLw4Z9GIfiC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 - The Data"
      ],
      "metadata": {
        "id": "RvmemUelI4Qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metin, veri toplama (data collection) işleminin text, resim, ses ve video içerdiğini belirtmektedir. Ancak bu notebook'ta (Jupyter Notebook), veri toplama yerine veri geri getirme (data retrieval) işlemleri üzerinde durulmaktadır. Veri toplama işlemi daha sonraki bölümlerde (Chapter 2) ele alınacaktır.\n",
        "\n",
        "**Veri İşleme Aşamaları**\n",
        "\n",
        "RAG ekosisteminin retriever (D) bileşeni üç veri işleme aşamasından oluşur:\n",
        "\n",
        "1. **Veri Toplama (Collect, D1)**: Verilerin toplanması aşamasıdır.\n",
        "2. **Veri İşleme (Process, D2)**: Toplanan verilerin işlenmesi aşamasıdır.\n",
        "3. **Veri Depolama (Storage, D3)**: İşlenen verilerin depolanması aşamasıdır.\n",
        "\n",
        "Bu üç aşama, retriever sorgusu (D4) için hazırlık aşamalarıdır. Retriever sorgusu, bu üç aşamadan bağımsızdır.\n",
        "\n",
        "**Örnek Kod**\n",
        "\n",
        "Yukarıdaki metinde, veri işlemenin tamamlandığını ve veri kümesinin hazır olduğunu varsayan bir Python kodu örneği verilmiştir:\n",
        "```python\n",
        "db_records = [\n",
        "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
        "    # ...\n",
        "]\n",
        "```\n",
        "Bu kod, `db_records` adlı bir Python listesi oluşturur ve bu liste veri kümesini içerir.\n",
        "\n",
        "**Veri Kümesini Görüntüleme**\n",
        "\n",
        "Aşağıdaki kod, veri kümesini biçimlendirilmiş bir şekilde görüntülemek için kullanılır:\n",
        "```python\n",
        "import textwrap\n",
        "paragraph = ' '.join(db_records)\n",
        "wrapped_text = textwrap.fill(paragraph, width=80)\n",
        "print(wrapped_text)\n",
        "```\n",
        "Bu kod, `db_records` listesindeki cümleleri birleştirir ve `textwrap` modülünü kullanarak biçimlendirilmiş bir metin oluşturur.\n",
        "\n",
        "**Neden Böyle Yapılıyor?**\n",
        "\n",
        "Veri işlemenin bu şekilde yapılması, RAG ekosisteminin retriever bileşeninin veri işlemeden bağımsız olarak çalışmasını sağlar. Bu sayede, veri işleme aşamaları retriever sorgusundan önce gerçekleştirilebilir.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "RAG ekosisteminde kullanılan diğer teknikler arasında:\n",
        "\n",
        "* **Deep Lake**: Derin öğrenme tabanlı bir veri gölü (data lake) çözümüdür.\n",
        "* **OpenAI**: Doğal dil işleme modelleri geliştiren bir şirketdir.\n",
        "\n",
        "Bu teknikler, RAG ekosisteminin geliştirilmesinde ve veri işlemede kullanılabilir.\n",
        "\n",
        "**Kodların Açıklaması**\n",
        "\n",
        "Yukarıdaki kod örneklerinde kullanılan teknikler:\n",
        "\n",
        "* Python listeleri (`db_records`)\n",
        "* `textwrap` modülü (biçimlendirilmiş metin oluşturma)\n",
        "* `join()` fonksiyonu (cümleleri birleştirme)\n",
        "\n",
        "Bu teknikler, veri işlemede ve RAG ekosisteminin geliştirilmesinde kullanılır."
      ],
      "metadata": {
        "id": "zJ33DLMoI8Qh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Query"
      ],
      "metadata": {
        "id": "z2SJO64EJO37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sorgu (Query) İşlemleri ve Retrieval-Augmented Generation (RAG) Kullanımı**\n",
        "\n",
        "Bu bölümde, bir organizasyondaki yüzlerce kullanıcının \"RAG\" terimini \"LLM\" (Large Language Model) ve \"vector stores\" ile ilişkilendirmesi ve bu terimlerin anlamını anlamak istemesi durumu ele alınmaktadır. Kullanıcılar, bir conversational agent (sohbet robotu) olan GPT-4o'ya bir sorgu gönderirler: `query = \"define a rag store\"`. Bu sorgu, retrieval (D4) ve generator arasındaki bağlantıyı temsil eder ve RAG (naive, advanced ve modular) konfigürasyonlarından birini tetikler.\n",
        "\n",
        "**Sorgu İşlemleri**\n",
        "\n",
        "Program, sorguyu GPT-4o modeline gönderir ve biçimlendirilmiş çıktıyı görüntüler:\n",
        "\n",
        "```python\n",
        "# Fonksiyonu çağır ve sonucu yazdır\n",
        "llm_response = call_llm_with_full_text(query)\n",
        "print_formatted_response(llm_response)\n",
        "```\n",
        "\n",
        "Çıktı, GPT-4o'nun sorguyu nasıl yorumladığını gösterir:\n",
        "\n",
        "```\n",
        "Response:\n",
        "---------------\n",
        "Certainly! The content you've provided appears to be a sequence of characters\n",
        "that, when combined, form the phrase \"define a rag store.\" Let's break it down\n",
        "step by step:…\n",
        "…\n",
        "```\n",
        "\n",
        "GPT-4o, sorguyu anlamaya çalışır, ancak kullanıcının niyetini tam olarak anlayamaz ve bir dizi olasılık sunar. Bu, GPT-4o'nun olasılık tabanlı algoritmasının bir sonucudur.\n",
        "\n",
        "**RAG'ın Önemi**\n",
        "\n",
        "Bu durumda, RAG devreye girer. RAG, retrieval ve generation işlemlerini birleştirerek daha doğru ve ilgili sonuçlar sağlar. RAG'ın kullanılması, GPT-4o'nun daha iyi bir yanıt vermesini sağlar.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "RAG dışında başka teknikler de vardır:\n",
        "\n",
        "* **Knowledge Graph**: Bilgiyi grafik yapısında temsil eden bir tekniktir.\n",
        "* **Entity Recognition**: Metindeki varlıkları tanımaya yarayan bir tekniktir.\n",
        "\n",
        "**Kod Açıklaması**\n",
        "\n",
        "Kullanılan kod, GPT-4o modelini çağırmak ve biçimlendirilmiş çıktıyı görüntülemek için basit bir Python kodudur. `call_llm_with_full_text` fonksiyonu, sorguyu GPT-4o modeline gönderir ve yanıtı alır. `print_formatted_response` fonksiyonu, yanıtı biçimlendirir ve görüntüler.\n",
        "\n",
        "**Neden RAG Kullanılır?**\n",
        "\n",
        "RAG, retrieval ve generation işlemlerini birleştirerek daha doğru ve ilgili sonuçlar sağlar. Bu, özellikle kullanıcıların belirsiz veya eksik sorgular gönderdiği durumlarda önemlidir. RAG, GPT-4o gibi olasılık tabanlı modellere daha iyi bir yanıt vermesini sağlar."
      ],
      "metadata": {
        "id": "GXj3huItJSMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Advanced techniques and evaluation"
      ],
      "metadata": {
        "id": "9d6J7sQsJoK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 - Retrieval Metrics"
      ],
      "metadata": {
        "id": "Ok4uTM2cJ-6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Retrieval Metrics (İyileştirme Metrikleri)**\n",
        "\n",
        "Bu bölüm, metin belgelerinin (text documents) alaka düzeyini değerlendirmek için kullanılan cosine similarity (kosinüs benzerliği) kavramını incelemektedir. Daha sonra, metinler arasındaki benzerlik hesaplamalarının doğruluğunu artırmak için sinonim genişletmesi (synonym expansion) ve metin ön işleme (text preprocessing) tekniklerini kullanarak geliştirilmiş benzerlik metriklerini uygulamaktadır.\n",
        "\n",
        "**Kosinus Benzerliği (Cosine Similarity)**\n",
        "\n",
        "Kosinus benzerliği, iki vektör arasındaki açının kosinüsünü ölçer. Bu durumda, iki vektör, kullanıcı sorgusu (user query) ve bir derlemdeki (corpus) her bir belgedir.\n",
        "\n",
        "Öncelikle, gerekli sınıf ve fonksiyonları içe aktarmak gerekir:\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "```\n",
        "`TfidfVectorizer`, metin belgelerini TF-IDF özelliklerinin bir matrisi haline dönüştürür. TF-IDF, bir kelimenin bir belge koleksiyonundaki önemini ölçer ve yaygın kelimeleri ayırt eder.\n",
        "\n",
        "`cosine_similarity`, vektörler arasındaki benzerliği hesaplamak için kullanılan fonksiyonudur.\n",
        "\n",
        "`calculate_cosine_similarity(text1, text2)` fonksiyonu, sorgu metni (text1) ve veri kümesindeki her bir kayıt (text2) arasındaki kosinüs benzerliğini hesaplar.\n",
        "\n",
        "Fonksiyon, sorgu metni ve her bir kaydı bir vektörleştirici (vectorizer) kullanarak vektörlere dönüştürür ve ardından iki vektör arasındaki kosinüs benzerliğini hesaplar ve döndürür:\n",
        "```python\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        use_idf=True,\n",
        "        norm='l2',\n",
        "        ngram_range=(1, 2),  \n",
        "        sublinear_tf=True,   \n",
        "        analyzer='word'      \n",
        "    )\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]\n",
        "```\n",
        "Bu fonksiyonun ana parametreleri:\n",
        "\n",
        "* `stop_words='english'`: İngilizce yaygın kelimeleri yok sayar\n",
        "* `use_idf=True`: Ters belge frekansı ağırlıklandırmasını etkinleştirir\n",
        "* `norm='l2'`: Her bir çıktı vektörüne L2 normalizasyonu uygular\n",
        "* `ngram_range=(1, 2)`: Tek kelimeleri ve iki kelime kombinasyonlarını dikkate alır\n",
        "* `sublinear_tf=True`: Logaritmik terim frekansı ölçeklendirmesini uygular\n",
        "* `analyzer='word'`: Metni kelime düzeyinde analiz eder\n",
        "\n",
        "Kosinus benzerliği, bazı durumlarda sınırlı olabilir. Örneğin, belirsiz sorgularla başa çıkmakta zorlanabilir.\n",
        "\n",
        "**Geliştirilmiş Benzerlik (Enhanced Similarity)**\n",
        "\n",
        "Geliştirilmiş benzerlik, doğal dil işleme araçlarını kullanarak kelimeler arasındaki anlamsal ilişkileri daha iyi yakalamaya çalışır. spaCy ve NLTK gibi kütüphaneleri kullanarak metinleri ön işleme tabi tutar, WordNet'ten sinonimlerle genişletir ve genişletilmiş kelime hazinesinin anlamsal zenginliğine dayalı olarak benzerliği hesaplar.\n",
        "\n",
        "Kod, dört ana fonksiyon içerir:\n",
        "\n",
        "* `get_synonyms(word)`: Verilen bir kelimenin sinonimlerini WordNet'ten alır\n",
        "* `preprocess_text(text)`: Metni küçük harfe dönüştürür, köklerine ayırır ve yaygın kelimeleri ve noktalama işaretlerini filtreler\n",
        "* `expand_with_synonyms(words)`: Bir kelime listesini sinonimlerle genişletir\n",
        "* `calculate_enhanced_similarity(text1, text2)`: Ön işleme tabi tutulmuş ve sinonimlerle genişletilmiş metin vektörleri arasındaki kosinüs benzerliğini hesaplar\n",
        "\n",
        "`calculate_enhanced_similarity(text1, text2)` fonksiyonu, iki metni alır ve ön işleme tabi tutulmuş ve sinonimlerle genişletilmiş metin vektörleri arasındaki kosinüs benzerliğini döndürür.\n",
        "\n",
        "Geliştirilmiş benzerlik, metrikler açısından biraz daha ileri gider. Ancak, RAG'ı üretken yapay zeka ile entegre etmek birden fazla zorluk sunar.\n",
        "\n",
        "Hangi metriği uygularsak uygulayalım, aşağıdaki sınırlamalarla karşılaşacağız:\n",
        "\n",
        "* Giriş ve belge uzunluğu: Kullanıcı sorguları genellikle kısa, alınan belgeler ise daha uzun ve zengindir, bu da doğrudan benzerlik değerlendirmelerini zorlaştırır.\n",
        "* Yaratıcı erişim: Sistemler, kullanıcı beklentilerini karşılayan ancak beklenmedik içerik hizalaması nedeniyle zayıf metrik puanları veren daha uzun belgeleri yaratıcı bir şekilde seçebilir.\n",
        "* İnsan geri bildirimi ihtiyacı: Genellikle, insan yargısı, alınan içeriğin alaka düzeyini ve etkinliğini doğru bir şekilde değerlendirmek için çok önemlidir, çünkü otomatik metrikler kullanıcı memnuniyetini tam olarak yakalayamayabilir.\n",
        "\n",
        "Her zaman matematiksel metrikler ve insan geri bildirimi arasında doğru dengeyi bulmak zorunda kalacağız.\n",
        "\n",
        "Bu teknik dışında başka teknikler de vardır. Örneğin, Jaccard benzerliği, Levenshtein mesafesi, vb.\n",
        "\n",
        "Kodların açıklamaları:\n",
        "\n",
        "* `TfidfVectorizer`: Metin belgelerini TF-IDF özelliklerinin bir matrisi haline dönüştürür.\n",
        "* `cosine_similarity`: Vektörler arasındaki benzerliği hesaplar.\n",
        "* `get_synonyms(word)`: Verilen bir kelimenin sinonimlerini WordNet'ten alır.\n",
        "* `preprocess_text(text)`: Metni küçük harfe dönüştürür, köklerine ayırır ve yaygın kelimeleri ve noktalama işaretlerini filtreler.\n",
        "\n",
        "Bu teknikler, metinler arasındaki benzerliği hesaplamak için kullanılır ve doğal dil işleme uygulamalarında yaygın olarak kullanılır."
      ],
      "metadata": {
        "id": "XdwpVIqcKD6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 - Naive RAG"
      ],
      "metadata": {
        "id": "hmy-oSGwKo_K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive RAG (Retrieval-Augmented Generation) İşlemleri**\n",
        "\n",
        "Naive RAG, belirli bir organizasyon içinde iyi tanımlanmış belgelerle (örneğin, yasal ve tıbbi belgeler) çalışırken anahtar kelime arama ve eşleştirme ile verimli olabilir. Bu belgeler genellikle resimler için net başlıklara veya etiketlere sahiptir. Bu bölümde, anahtar kelime arama ve eşleştirme işlevini uygulayacağız.\n",
        "\n",
        "**Anahtar Kelime Arama ve Eşleştirme**\n",
        "\n",
        "Bu işlemin amacı, kullanıcı girdisini anahtar kelimelere ayırmak, veri kümesindeki her bir kaydı anahtar kelimelere ayırmak, ortak eşleşmelerin uzunluğunu belirlemek ve en iyi skora sahip kaydı seçmektir.\n",
        "\n",
        "**Kod Açıklaması**\n",
        "\n",
        "```python\n",
        "def find_best_match_keyword_search(query, db_records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "\n",
        "    # Kullanıcı girdisini anahtar kelimelere ayırma\n",
        "    query_keywords = set(query.lower().split())\n",
        "\n",
        "    # Veri kümesindeki her bir kaydı anahtar kelimelere ayırma\n",
        "    for record in db_records:\n",
        "        record_keywords = set(record.lower().split())\n",
        "        common_keywords = query_keywords.intersection(record_keywords)\n",
        "        current_score = len(common_keywords)\n",
        "\n",
        "        # En iyi skoru ve kaydı güncelleme\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "\n",
        "    return best_score, best_record\n",
        "```\n",
        "\n",
        "Bu kod, kullanıcı girdisini ve veri kümesindeki her bir kaydı anahtar kelimelere ayırır ve ortak anahtar kelimelerin sayısını hesaplar. En yüksek skora sahip kayıt, en iyi eşleşme olarak seçilir.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "*   **Vektör Tabanlı Arama**: Naive RAG'ın aksine, vektör tabanlı arama, belgeleri vektör uzayında temsil eder ve benzerlik ölçütleri kullanarak arama yapar.\n",
        "*   **Derin Öğrenme Tabanlı Arama**: Derin öğrenme modelleri, belgeleri temsil etmek ve arama yapmak için kullanılabilir.\n",
        "\n",
        "**Önemli Noktalar**\n",
        "\n",
        "*   Naive RAG, iyi tanımlanmış belgelerle çalışırken etkili olabilir.\n",
        "*   Anahtar kelime arama ve eşleştirme, basit bir arama yöntemidir.\n",
        "*   Vektör tabanlı arama ve derin öğrenme tabanlı arama gibi diğer teknikler, daha karmaşık arama görevleri için kullanılabilir.\n",
        "\n",
        "**Metrikler**\n",
        "\n",
        "*   **Cosine Similarity**: İki vektör arasındaki benzerliği ölçer.\n",
        "*   **Enhanced Similarity**: Gelişmiş benzerlik ölçütü, daha iyi sonuçlar sağlar.\n",
        "\n",
        "**Kod Çıktısı**\n",
        "\n",
        "*   En iyi anahtar kelime skoru: 3\n",
        "*   En iyi eşleşme kaydı: \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
        "*   Cosine similarity skoru: 0.126\n",
        "*   Enhanced similarity skoru: 0.642\n",
        "\n",
        "**Geliştirilmiş Girdi**\n",
        "\n",
        "*   Kullanıcı girdisi ve en iyi eşleşme kaydı birleştirilerek geliştirilmiş girdi oluşturulur.\n",
        "\n",
        "**Üretim**\n",
        "\n",
        "*   Geliştirilmiş girdi, GPT-4o modeline iletilir ve çıktı üretilir.\n",
        "\n",
        "**Sonuç**\n",
        "\n",
        "Naive RAG, basit arama görevleri için etkili olabilir. Ancak, daha karmaşık arama görevleri için vektör tabanlı arama ve derin öğrenme tabanlı arama gibi diğer teknikler kullanılabilir."
      ],
      "metadata": {
        "id": "naE1z6LyK1gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Naive RAG (Retrieval-Augmented Generation) İşlemleri**\n",
        "\n",
        "Naive RAG, belirli bir organizasyon içinde iyi tanımlanmış belgelerle (örneğin, yasal ve tıbbi belgeler) çalışırken anahtar kelime arama ve eşleştirme ile verimli olabilir. Bu belgeler genellikle resimler için net başlıklara veya etiketlere sahiptir. Bu bölümde, anahtar kelime arama ve eşleştirme işlevini uygulayacağız.\n",
        "\n",
        "**Anahtar Kelime Arama ve Eşleştirme**\n",
        "\n",
        "Bu işlemin amacı, kullanıcı girdisini anahtar kelimelere ayırmak, veri kümesindeki her bir kaydı anahtar kelimelere ayırmak, ortak eşleşmelerin uzunluğunu belirlemek ve en iyi skora sahip kaydı seçmektir.\n",
        "\n",
        "**Kod Açıklaması**\n",
        "\n",
        "```python\n",
        "def find_best_match_keyword_search(query, db_records):\n",
        "    best_score = 0\n",
        "    best_record = None\n",
        "\n",
        "    # Kullanıcı girdisini anahtar kelimelere ayırma\n",
        "    query_keywords = set(query.lower().split())\n",
        "\n",
        "    # Veri kümesindeki her bir kaydı anahtar kelimelere ayırma\n",
        "    for record in db_records:\n",
        "        record_keywords = set(record.lower().split())\n",
        "        common_keywords = query_keywords.intersection(record_keywords)\n",
        "        current_score = len(common_keywords)\n",
        "\n",
        "        # En iyi skoru ve kaydı güncelleme\n",
        "        if current_score > best_score:\n",
        "            best_score = current_score\n",
        "            best_record = record\n",
        "\n",
        "    return best_score, best_record\n",
        "```\n",
        "\n",
        "Bu kod, kullanıcı girdisini ve veri kümesindeki her bir kaydı anahtar kelimelere ayırır ve ortak anahtar kelimelerin sayısını hesaplar. En yüksek skora sahip kayıt, en iyi eşleşme olarak seçilir.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "*   **Vektör Tabanlı Arama**: Naive RAG'ın aksine, vektör tabanlı arama, belgeleri vektör uzayında temsil eder ve benzerlik ölçütleri kullanarak arama yapar.\n",
        "*   **Derin Öğrenme Tabanlı Arama**: Derin öğrenme modelleri, belgeleri temsil etmek ve arama yapmak için kullanılabilir.\n",
        "\n",
        "**Önemli Noktalar**\n",
        "\n",
        "*   Naive RAG, iyi tanımlanmış belgelerle çalışırken etkili olabilir.\n",
        "*   Anahtar kelime arama ve eşleştirme, basit bir arama yöntemidir.\n",
        "*   Vektör tabanlı arama ve derin öğrenme tabanlı arama gibi diğer teknikler, daha karmaşık arama görevleri için kullanılabilir.\n",
        "\n",
        "**Metrikler**\n",
        "\n",
        "*   **Cosine Similarity**: İki vektör arasındaki benzerliği ölçer.\n",
        "*   **Enhanced Similarity**: Gelişmiş benzerlik ölçütü, daha iyi sonuçlar sağlar.\n",
        "\n",
        "**Kod Çıktısı**\n",
        "\n",
        "*   En iyi anahtar kelime skoru: 3\n",
        "*   En iyi eşleşme kaydı: \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
        "*   Cosine similarity skoru: 0.126\n",
        "*   Enhanced similarity skoru: 0.642\n",
        "\n",
        "**Geliştirilmiş Girdi**\n",
        "\n",
        "*   Kullanıcı girdisi ve en iyi eşleşme kaydı birleştirilerek geliştirilmiş girdi oluşturulur.\n",
        "\n",
        "**Üretim**\n",
        "\n",
        "*   Geliştirilmiş girdi, GPT-4o modeline iletilir ve çıktı üretilir.\n",
        "\n",
        "**Sonuç**\n",
        "\n",
        "Naive RAG, basit arama görevleri için etkili olabilir. Ancak, daha karmaşık arama görevleri için vektör tabanlı arama ve derin öğrenme tabanlı arama gibi diğer teknikler kullanılabilir."
      ],
      "metadata": {
        "id": "jPsDWDS8KqzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3- Advanced RAG"
      ],
      "metadata": {
        "id": "RaCfI9RuLZv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Advanced RAG (Retrieval-Augmented Generation) Teknikleri**\n",
        "\n",
        "Bu bölümde, büyük veri setlerinde keyword search yöntemlerinin yetersiz kalabileceğini ve bu nedenle daha verimli arama tekniklerine ihtiyaç duyulduğunu anlatıyor. Advanced RAG, metin verilerini sayısal temsillere dönüştürerek arama verimliliğini ve işleme hızını artıran bir yöntemdir.\n",
        "\n",
        "**Vector Search**\n",
        "\n",
        "Vector search, kullanıcı sorgusunu ve belgeleri sayısal vektörlere dönüştürerek matematiksel hesaplamalar yapar ve büyük veri hacimlerinde ilgili verileri daha hızlı bir şekilde alır.\n",
        "\n",
        "*   Kodda, `find_best_match` fonksiyonu, sorgu vektörü ile veri setindeki her bir kayıt arasındaki cosine similarity'yi hesaplayarak en iyi eşleşen belgeyi bulur.\n",
        "*   `calculate_cosine_similarity` fonksiyonu, iki vektör arasındaki benzerliği hesaplar.\n",
        "\n",
        "Vector search neden kullanılır?\n",
        "\n",
        "*   Küçük veri setlerinde her şey kolay görünse de, milyonlarca karmaşık belge içeren veri setlerinde keyword search yöntemleri yetersiz kalabilir.\n",
        "*   Vektörler, metinlerin daha derin dilbilimsel örüntülerini yakalayabilir.\n",
        "\n",
        "**Index-Based Search**\n",
        "\n",
        "Index-based search, kullanıcı sorgusunun vektörünü doğrudan belge içeriğinin vektörüyle değil, bu içeriği temsil eden indekslenmiş bir vektörle karşılaştırır.\n",
        "\n",
        "*   `TfidfVectorizer` sınıfı, metin belgelerini TF-IDF (Term Frequency-Inverse Document Frequency) özelliklerinin bir matrisi haline getirir.\n",
        "*   `find_best_match` fonksiyonu, sorguyu TF-IDF vektör formatına dönüştürür, sorgu vektörü ile tfidf_matrix arasındaki cosine similarity'yi hesaplar ve en yüksek benzerlik puanına sahip indeksi bulur.\n",
        "\n",
        "Neden index-based search kullanılır?\n",
        "\n",
        "*   Vector search, veri seti boyutu arttıkça verimliliğini kaybedebilir.\n",
        "*   Index-based search, belge vektörlerini önceden hesaplayarak daha hızlı karşılaştırmalar yapar.\n",
        "\n",
        "**Kod Açıklamaları**\n",
        "\n",
        "*   `vectorizer, tfidf_matrix = setup_vectorizer(db_records)`: Veri setindeki belgeleri TF-IDF vektörlerine dönüştürür.\n",
        "*   `best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)`: Sorgu ile en benzer belgeyi bulur.\n",
        "*   `augmented_input = query + \": \" + best_matching_record`: Sorguyu, bulunan en iyi eşleşen belge ile birleştirir.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "*   Naïve RAG: Basit bir RAG yaklaşımıdır.\n",
        "*   Modular RAG: Farklı RAG tekniklerini bir arada kullanmayı sağlar.\n",
        "\n",
        "**Avantajları ve Dezavantajları**\n",
        "\n",
        "*   Vector search ve index-based search, arama verimliliğini artırır.\n",
        "*   Ancak, her iki yöntem de kendi avantaj ve dezavantajlarına sahiptir. Örneğin, vector search daha doğru sonuçlar verebilirken, index-based search daha hızlı olabilir.\n",
        "\n",
        "Bu teknikler, doğal dil işleme (NLP) ve bilgi erişimi alanlarında önemli uygulamalara sahiptir. Özellikle büyük veri setlerinde ve karmaşık belgelerin işlenmesi gereken durumlarda, Advanced RAG teknikleri büyük önem taşır."
      ],
      "metadata": {
        "id": "zP3dYSeaLcMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4 - Modular RAG"
      ],
      "metadata": {
        "id": "pJmS51T3L0x7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modüler RAG (Retrieval-Augmented Generation) Sistemleri**\n",
        "\n",
        "Bu bölümde, bir RAG sisteminde farklı arama metodolojilerinin (anahtar kelime, vektör ve indeks tabanlı arama) nasıl entegre edilebileceği anlatılmaktadır. Her bir metodun kendine özgü avantajları vardır ve veri alma bağlamında belirli ihtiyaçları karşılar.\n",
        "\n",
        "**Arama Metodolojileri**\n",
        "\n",
        "1. **Anahtar Kelime Araması (Keyword Search)**: Basit veri alma işlemleri için uygundur. Anahtar kelime araması, sorgu ve belgeler arasındaki ortak anahtar kelimeleri sayarak en iyi eşleşmeyi bulur.\n",
        "2. **Vektör Araması (Vector Search)**: Anlamsal olarak zengin belgeler için idealdir. Vektör araması, sorgu TF-IDF (Term Frequency-Inverse Document Frequency) ve belge matrisi arasındaki benzerlikleri hesaplayarak en iyi eşleşmeyi bulur.\n",
        "3. **İndeks Tabanlı Arama (Index-Based Search)**: Büyük veri kümeleri için hızlı arama sağlar. İndeks tabanlı arama, önceden hesaplanmış TF-IDF matrisini kullanarak en iyi eşleşen belgeyi hızlı bir şekilde alır.\n",
        "\n",
        "**Modüler RAG Sınıfı**\n",
        "\n",
        "Bu bölümde, `RetrievalComponent` adlı bir sınıf oluşturulmaktadır. Bu sınıf, bir RAG projesinde farklı arama metodolojilerini çağırmak için kullanılabilir.\n",
        "\n",
        "```python\n",
        "class RetrievalComponent:\n",
        "    def __init__(self, method='vector'):\n",
        "        self.method = method\n",
        "        if self.method == 'vector' or self.method == 'indexed':\n",
        "            self.vectorizer = TfidfVectorizer()\n",
        "            self.tfidf_matrix = None\n",
        "\n",
        "    def fit(self, records):\n",
        "        if self.method == 'vector' or self.method == 'indexed':\n",
        "            self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
        "\n",
        "    def retrieve(self, query):\n",
        "        if self.method == 'keyword':\n",
        "            return self.keyword_search(query)\n",
        "        elif self.method == 'vector':\n",
        "            return self.vector_search(query)\n",
        "        elif self.method == 'indexed':\n",
        "            return self.indexed_search(query)\n",
        "\n",
        "    def keyword_search(self, query):\n",
        "        # Anahtar kelime araması implementasyonu\n",
        "\n",
        "    def vector_search(self, query):\n",
        "        # Vektör araması implementasyonu\n",
        "\n",
        "    def indexed_search(self, query):\n",
        "        # İndeks tabanlı arama implementasyonu\n",
        "```\n",
        "\n",
        "**Kullanım Örneği**\n",
        "\n",
        "```python\n",
        "retrieval = RetrievalComponent(method='vector')  # 'keyword', 'vector', 'indexed' seçeneklerinden birini seçin\n",
        "retrieval.fit(db_records)\n",
        "best_matching_record = retrieval.retrieve(query)\n",
        "print_formatted_response(best_matching_record)\n",
        "```\n",
        "\n",
        "Bu örnekte, vektör araması metodunu kullanarak en iyi eşleşen belgeyi bulmak için `RetrievalComponent` sınıfı kullanılmaktadır.\n",
        "\n",
        "**Diğer Teknikler**\n",
        "\n",
        "* **BM25**: Anahtar kelime araması için kullanılan bir diğer tekniktir. BM25, kelime frekansı ve belge frekansı gibi faktörleri dikkate alarak daha doğru sonuçlar sağlar.\n",
        "* **Dense Passage Retriever (DPR)**: Vektör araması için kullanılan bir diğer tekniktir. DPR, sorgu ve belgeleri yoğun vektörlere dönüştürerek benzerlikleri hesaplar.\n",
        "\n",
        "**Neden Böyle Yapıldı?**\n",
        "\n",
        "* Modüler RAG sistemleri, farklı arama metodolojilerini entegre ederek daha esnek ve güçlü bir sistem oluşturmayı sağlar.\n",
        "* Her bir arama metodolojisi, belirli ihtiyaçları karşılamak için optimize edilmiştir.\n",
        "* `RetrievalComponent` sınıfı, farklı arama metodolojilerini çağırmak için bir arayüz sağlar, böylece geliştiriciler farklı metodolojileri kolayca deneyebilir ve karşılaştırabilir."
      ],
      "metadata": {
        "id": "Y1e1nrjpL25i"
      }
    }
  ]
}