{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPusL1InIOvhc2w9lbqli/x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/RAG-Driven-Generative-AI/blob/main/Ch02_RAG_Embedding_Vector_Stores_with_Deep_Lake_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Embedding Vector Stores ile Derin GÃ¶l (Deep Lake) ve OpenAI KullanÄ±mÄ±\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, RAG (Retrieval-Augmented Generation) tabanlÄ± Ã¼retken yapay zeka (Generative AI) uygulamalarÄ±nda karÅŸÄ±laÅŸÄ±lan karmaÅŸÄ±klÄ±klar ve bu karmaÅŸÄ±klÄ±klarÄ± aÅŸmak iÃ§in kullanÄ±lan teknikler ele alÄ±nacaktÄ±r. Ã–zellikle, metinlerin Ã¶zetlenmesi ve anlamlandÄ±rÄ±lmasÄ± iÃ§in kullanÄ±lan \"embedding\" vektÃ¶rlerinin depolanmasÄ± ve yÃ¶netilmesi konusu derinlemesine incelenecektir.\n",
        "\n",
        "### Embedding VektÃ¶rleri ve Ã–nemi\n",
        "\n",
        "Embedding vektÃ¶rleri, yapÄ±landÄ±rÄ±lmÄ±ÅŸ veya yapÄ±landÄ±rÄ±lmamÄ±ÅŸ metinleri kompakt, yÃ¼ksek boyutlu vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rerek metinlerin anlamsal Ã¶zÃ¼nÃ¼ yakalar. Bu sayede, bilgi eriÅŸimi daha hÄ±zlÄ± ve verimli hale gelir. Ancak, bÃ¼yÃ¼k veri setleri ile Ã§alÄ±ÅŸÄ±rken, belge embedding'lerinin oluÅŸturulmasÄ± ve depolanmasÄ± gerekliliÄŸi ortaya Ã§Ä±kar ve bu da depolama sorunlarÄ±na yol aÃ§ar.\n",
        "\n",
        "### Neden Anahtar Kelimeler Yerine Embedding KullanÄ±lÄ±r?\n",
        "\n",
        "Anahtar kelimeler yerine embedding vektÃ¶rlerinin kullanÄ±lmasÄ±nÄ±n nedeni, embedding'lerin metinlerin daha derin anlamsal anlamlarÄ±nÄ± yakalayabilmesi ve daha incelikli, baÄŸlam farkÄ±nda bilgi eriÅŸimi saÄŸlamasÄ±dÄ±r. Bu, daha iyi ve daha ilgili sonuÃ§lar elde edilmesini saÄŸlar.\n",
        "\n",
        "## VektÃ¶r MaÄŸazalarÄ± (Vector Stores)\n",
        "\n",
        "Embedding vektÃ¶rlerinin organize edilmesi ve hÄ±zlÄ± bir ÅŸekilde eriÅŸilebilmesi iÃ§in vektÃ¶r maÄŸazalarÄ± kullanÄ±lÄ±r. Bu bÃ¶lÃ¼mde, ham verilerden Activeloop Deep Lake vektÃ¶r maÄŸazasÄ±na nasÄ±l gidileceÄŸi, OpenAI embedding modellerinin yÃ¼klenmesi ve Ã§eÅŸitli platformlar arasÄ± paketlerin kurulmasÄ± ve uygulanmasÄ± ele alÄ±nacaktÄ±r.\n",
        "\n",
        "### RAG Pipeline'Ä±n BileÅŸenlere AyrÄ±lmasÄ±\n",
        "\n",
        "RAG pipeline'Ä±nÄ± baÄŸÄ±msÄ±z bileÅŸenlere ayÄ±rarak, birden fazla takÄ±mÄ±n aynÄ± anda proje Ã¼zerinde Ã§alÄ±ÅŸabilmesi saÄŸlanÄ±r. Bu sayede, proje daha verimli ve yÃ¶netilebilir hale gelir.\n",
        "\n",
        "## Uygulama: Python ile RAG Pipeline Kurulumu\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, Python kullanarak sÄ±fÄ±rdan Ã¼Ã§ bileÅŸenli bir RAG pipeline'Ä± kurulacaktÄ±r. Activeloop Deep Lake, OpenAI ve Ã¶zel geliÅŸtirilen fonksiyonlar kullanÄ±larak, RAG tabanlÄ± Ã¼retken yapay zeka pipeline'Ä± iÃ§in bir ÅŸablon oluÅŸturulacaktÄ±r.\n",
        "\n",
        "### KarÅŸÄ±laÅŸÄ±lan Zorluklar\n",
        "\n",
        "- **Paket ve BaÄŸÄ±mlÄ±lÄ±k SorunlarÄ±:** Ã‡apraz platform ortam sorunlarÄ± ile paket ve baÄŸÄ±mlÄ±lÄ±klarÄ±n yÃ¶netimi.\n",
        "- **Veri ParÃ§alama (Chunking), Embedding VektÃ¶rleri ve YÃ¼kleme:** Veri parÃ§alama, embedding vektÃ¶rlerinin oluÅŸturulmasÄ± ve vektÃ¶r maÄŸazalarÄ±na yÃ¼klenmesi.\n",
        "\n",
        "### Ã‡Ã¶zÃ¼m: GPT-4o Modeli ile Retrieval Queries KullanÄ±mÄ±\n",
        "\n",
        "GPT-4o modelinin girdisini retrieval queries ile zenginleÅŸtirerek saÄŸlam Ã§Ä±ktÄ±larÄ±n Ã¼retilmesi saÄŸlanacaktÄ±r.\n",
        "\n",
        "## SonuÃ§\n",
        "\n",
        "Bu bÃ¶lÃ¼mÃ¼n sonunda, vektÃ¶r maÄŸazalarÄ±nda gÃ¶mÃ¼lÃ¼ belgelerin Ã¼retken yapay zeka iÃ§in nasÄ±l kullanÄ±lacaÄŸÄ± tam olarak anlaÅŸÄ±lmÄ±ÅŸ olacaktÄ±r.\n",
        "\n",
        "### Ä°lgili Kaynaklar\n",
        "\n",
        "- [Activeloop Deep Lake](https://www.activeloop.ai/)\n",
        "- [OpenAI](https://www.openai.com/)\n",
        "\n",
        "### KullanÄ±lan Teknikler ve Kodlar\n",
        "\n",
        "- **Embedding VektÃ¶rleri:** Metinlerin anlamsal Ã¶zÃ¼nÃ¼ yakalamak iÃ§in kullanÄ±lÄ±r. Ã–rnek kod: `sentence-transformers` kÃ¼tÃ¼phanesini kullanarak embedding oluÅŸturma.\n",
        "- **VektÃ¶r MaÄŸazalarÄ±:** Embedding vektÃ¶rlerini organize etmek ve hÄ±zlÄ± eriÅŸim saÄŸlamak iÃ§in kullanÄ±lÄ±r. Ã–rnek: Activeloop Deep Lake.\n",
        "- **RAG Pipeline:** Retrieval-Augmented Generation pipeline'Ä±, bilgi eriÅŸimi ve metin Ã¼retimi iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "### Neden Bu Teknikler KullanÄ±lÄ±r?\n",
        "\n",
        "- Daha verimli ve anlamlÄ± bilgi eriÅŸimi saÄŸlamak.\n",
        "- BÃ¼yÃ¼k veri setlerini daha iyi yÃ¶netmek.\n",
        "- Ãœretken yapay zeka uygulamalarÄ±nda daha doÄŸru ve ilgili sonuÃ§lar elde etmek.\n",
        "\n",
        "### KullanÄ±labilecek Projeler\n",
        "\n",
        "- **DoÄŸal Dil Ä°ÅŸleme (NLP) Projeleri:** Metin sÄ±nÄ±flandÄ±rma, duygu analizi, metin Ã¶zetleme.\n",
        "- **Ãœretken Yapay Zeka UygulamalarÄ±:** Chatbot'lar, iÃ§erik oluÅŸturma araÃ§larÄ±.\n",
        "- **Bilgi EriÅŸim Sistemleri:** Arama motorlarÄ±, belge yÃ¶netim sistemleri.\n",
        "\n",
        "## Markdown Ä°fadeleri ile Ã–zet\n",
        "\n",
        "## RAG ve Embedding VektÃ¶rleri\n",
        "## VektÃ¶r MaÄŸazalarÄ± ve Ã–nemi\n",
        "## Uygulama ve KarÅŸÄ±laÅŸÄ±lan Zorluklar\n",
        "## SonuÃ§ ve Ä°lgili Kaynaklar"
      ],
      "metadata": {
        "id": "sAhFf_g8wN8Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From raw data to embeddings in vector stores\n",
        "\n",
        "## GiriÅŸ\n",
        "Bu bÃ¶lÃ¼mde, ham verilerden vektÃ¶r depolarÄ±nda (vector stores) gÃ¶mÃ¼lÃ¼ temsillere (embeddings) kadar olan sÃ¼reÃ§ aÃ§Ä±klanmaktadÄ±r. GÃ¶mÃ¼lÃ¼ temsiller, metin, resim veya ses gibi her tÃ¼rlÃ¼ veriyi gerÃ§ek sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rerek matematiksel temsiller oluÅŸturur.\n",
        "\n",
        "## GÃ¶mÃ¼lÃ¼ Templerin OluÅŸturulmasÄ± (Creating Embeddings)\n",
        "GÃ¶mÃ¼lÃ¼ temsiller, OpenAI `text-embedding-3-small` gibi bir model kullanÄ±larak oluÅŸturulur. Bu model, ham verileri (kitaplar, makaleler, bloglar, resimler veya ÅŸarkÄ±lar) temizledikten sonra gÃ¶mÃ¼lÃ¼ temsillere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Activeloop Deep Lake gibi araÃ§lar, metni Ã¶nceden tanÄ±mlanmÄ±ÅŸ parÃ§alara (chunks) ayÄ±rarak daha detaylÄ± gÃ¶mÃ¼lÃ¼ temsiller oluÅŸturur. Bu parÃ§alarÄ±n boyutu, Ã¶rneÄŸin 1,000 karakter olabilir.\n",
        "\n",
        "## ÅeffaflÄ±k ve RAG (Transparency and RAG)\n",
        "RAG (Retrieval-Augmented Generation) Ã§erÃ§eveleri, oluÅŸturulan her iÃ§erik parÃ§asÄ±nÄ±n kaynak verilere kadar izlenebilir olmasÄ±nÄ± saÄŸlar. Bu, Ã§Ä±ktÄ±larÄ±n ÅŸeffaflÄ±ÄŸÄ±nÄ± garanti eder. OpenAI Ã¼retken modeli, artÄ±rÄ±lmÄ±ÅŸ girdiyi dikkate alarak yanÄ±t verir. GÃ¶mÃ¼lÃ¼ temsiller doÄŸrudan gÃ¶rÃ¼nÃ¼r ve metne baÄŸlÄ±dÄ±r, parametrik modellerin aksine.\n",
        "\n",
        "## VektÃ¶r Deposu (Vector Store)\n",
        "VektÃ¶r deposu, yÃ¼ksek boyutlu verileri (gÃ¶mÃ¼lÃ¼ temsiller gibi) iÅŸlemek Ã¼zere tasarlanmÄ±ÅŸ Ã¶zel bir veritabanÄ±dÄ±r. Activeloop gibi sunucusuz platformlarda veri kÃ¼meleri oluÅŸturulabilir ve API aracÄ±lÄ±ÄŸÄ±yla kodda eriÅŸilebilir.\n",
        "\n",
        "## VektÃ¶r Deposunun Ã–zellikleri\n",
        "VektÃ¶r depolarÄ±, gÃ¼Ã§lÃ¼ indeksleme yÃ¶ntemleri (indexing methods) ile donatÄ±lmÄ±ÅŸtÄ±r. Bu, RAG modelinin Ã¼retim aÅŸamasÄ±nda en ilgili gÃ¶mÃ¼lÃ¼ temsilleri hÄ±zlÄ± bir ÅŸekilde bulmasÄ±nÄ± ve getirmesini saÄŸlar. KullanÄ±cÄ± girdilerini artÄ±rarak modelin yÃ¼ksek kaliteli Ã§Ä±ktÄ± Ã¼retme yeteneÄŸini artÄ±rÄ±r.\n",
        "\n",
        "## RAG Ä°ÅŸlem HattÄ±nÄ±n OluÅŸturulmasÄ± (Building a RAG Pipeline)\n",
        "Veri toplama, iÅŸleme ve getirme iÅŸlemlerinden artÄ±rÄ±lmÄ±ÅŸ girdi oluÅŸturmaya kadar olan sÃ¼reÃ§ RAG iÅŸlem hattÄ±nÄ± oluÅŸturur.\n",
        "\n",
        "## KullanÄ±lan Teknikler ve Kodlar\n",
        "- **GÃ¶mÃ¼lÃ¼ Templerin OluÅŸturulmasÄ±**: OpenAI `text-embedding-3-small` modeli kullanÄ±lÄ±r.\n",
        "- **VektÃ¶r Deposu**: Activeloop Deep Lake gibi araÃ§lar kullanÄ±lÄ±r.\n",
        "- **Ä°ndeksleme YÃ¶ntemleri**: VektÃ¶r depolarÄ±nda gÃ¼Ã§lÃ¼ indeksleme yÃ¶ntemleri kullanÄ±lÄ±r.\n",
        "\n",
        "## Neden Bu Teknikler KullanÄ±lÄ±r?\n",
        "- GÃ¶mÃ¼lÃ¼ temsiller, verileri matematiksel olarak temsil ederek benzer verilerin getirilmesini saÄŸlar.\n",
        "- RAG Ã§erÃ§eveleri, Ã§Ä±ktÄ±larÄ±n ÅŸeffaflÄ±ÄŸÄ±nÄ± garanti eder.\n",
        "- VektÃ¶r depolarÄ±, yÃ¼ksek boyutlu verileri verimli bir ÅŸekilde iÅŸler.\n",
        "\n",
        "## KullanÄ±labilecek Projeler\n",
        "- DoÄŸal dil iÅŸleme (NLP) projeleri\n",
        "- GÃ¶rÃ¼ntÃ¼ ve ses iÅŸleme projeleri\n",
        "- Ã–neri sistemleri (recommendation systems)\n",
        "\n",
        "## Kaynaklar\n",
        "- [Activeloop Deep Lake](https://www.activeloop.ai/)\n",
        "- [OpenAI](https://www.openai.com/)\n",
        "\n",
        "## Ek Teknikler\n",
        "- **Cosine Similarity**: GÃ¶mÃ¼lÃ¼ temsiller arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r.\n",
        "- **Approximate Nearest Neighbors (ANN)**: VektÃ¶r depolarÄ±nda hÄ±zlÄ± arama yapmak iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "Bu teknikler ve araÃ§lar, bÃ¼yÃ¼k miktarda veriyi iÅŸleyerek yÃ¼ksek kaliteli Ã§Ä±ktÄ± Ã¼retmek iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "WE5XNvF8xJ8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Pipeline'Ä± DÃ¼zenleme (Organizing RAG in a Pipeline)\n",
        "\n",
        "RAG (Retrieve, Augment, Generate) pipeline'Ä± genellikle verileri toplar, temizler, Ã¶rneÄŸin dokÃ¼manlarÄ± parÃ§alara ayÄ±rÄ±r (`chunking`), gÃ¶mme (`embedding`) iÅŸlemlerini gerÃ§ekleÅŸtirir ve bir vektÃ¶r veri deposunda (`vector store dataset`) saklar. Daha sonra, vektÃ¶r veri kÃ¼mesi (`vector dataset`), Ã¼retken bir yapay zeka (`generative AI`) modelinin girdi (`input`) sÃ¼resini artÄ±rmak iÃ§in sorgulanÄ±r (`queried`). Ancak, bir vektÃ¶r deposu (`vector store`) kullanÄ±rken bu RAG iÅŸlem sÄ±rasÄ±nÄ± tek bir programda Ã§alÄ±ÅŸtÄ±rmamak Ã¶nerilir.\n",
        "\n",
        "## Ä°ÅŸlemleri AyÄ±rma (Separating the Process)\n",
        "\n",
        "En azÄ±ndan iÅŸlemleri Ã¼Ã§ bileÅŸene ayÄ±rmak gerekir:\n",
        "1. **Veri Toplama ve HazÄ±rlama (`Data collection and preparation`)**: Verilerin toplanmasÄ± ve temizlenmesi.\n",
        "2. **Veri GÃ¶mme ve YÃ¼kleme (`Data embedding and loading into the dataset of a vector store`)**: Verilerin gÃ¶mme iÅŸlemlerinin yapÄ±lmasÄ± ve vektÃ¶r veri deposuna yÃ¼klenmesi.\n",
        "3. **Sorgulama ve Ãœretken Model (`Querying the vectorized dataset to augment the input of a generative AI model`)**: VektÃ¶r veri kÃ¼mesinin sorgulanmasÄ± ve Ã¼retken modelin girdi sÃ¼resini artÄ±rmak iÃ§in kullanÄ±lmasÄ±.\n",
        "\n",
        "## Bu YaklaÅŸÄ±mÄ±n Nedenleri (Reasons for this Component Approach)\n",
        "\n",
        "1. **UzmanlaÅŸma (`Specialization`)**: Her takÄ±m Ã¼yesinin en iyi olduÄŸu alanda Ã§alÄ±ÅŸmasÄ±na olanak tanÄ±r.\n",
        "2. **Ã–lÃ§eklenebilirlik (`Scalability`)**: FarklÄ± bileÅŸenlerin ayrÄ± ayrÄ± Ã¶lÃ§eklendirilmesini ve geliÅŸtirilmesini saÄŸlar.\n",
        "3. **Paralel GeliÅŸtirme (`Parallel development`)**: Her takÄ±mÄ±n diÄŸerlerinden baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸmasÄ±na ve geliÅŸtirmeler yapmasÄ±na olanak tanÄ±r.\n",
        "4. **BakÄ±m (`Maintenance`)**: BileÅŸenlerin baÄŸÄ±msÄ±z olarak bakÄ±mÄ±nÄ±n yapÄ±lmasÄ±nÄ± saÄŸlar.\n",
        "5. **GÃ¼venlik ve Gizlilik (`Security concerns and privacy`)**: Her takÄ±mÄ±n ayrÄ± ayrÄ± yetkilendirilmesini ve eriÅŸim kontrolÃ¼nÃ¼ saÄŸlar.\n",
        "\n",
        "## KullanÄ±lan Teknikler ve Kodlar (Techniques and Codes Used)\n",
        "\n",
        "- `Chunking`: DokÃ¼manlarÄ±n daha kÃ¼Ã§Ã¼k parÃ§alara ayrÄ±lmasÄ±.\n",
        "- `Embedding`: Verilerin vektÃ¶r temsillerinin oluÅŸturulmasÄ±.\n",
        "- `Vector Store`: VektÃ¶rlerin saklandÄ±ÄŸÄ± veri deposu.\n",
        "\n",
        "Bu teknikler dÄ±ÅŸÄ±nda, RAG pipeline'Ä±nda kullanÄ±lan diÄŸer teknikler arasÄ±nda ` Named Entity Recognition (NER)`, `Part-of-Speech (POS) Tagging` ve `Dependency Parsing` gibi doÄŸal dil iÅŸleme (`Natural Language Processing, NLP`) teknikleri de bulunabilir.\n",
        "\n",
        "## Neden BÃ¶yle YapÄ±lÄ±r? (Why is it Done this Way?)\n",
        "\n",
        "RAG pipeline'Ä±nÄ± ayrÄ± bileÅŸenlere ayÄ±rmak, bÃ¼yÃ¼k Ã¶lÃ§ekli projelerde ve Ã¼retim ortamlarÄ±nda (`production environments`) daha iyi bir yÃ¶netim ve bakÄ±m saÄŸlar. AyrÄ±ca, her bileÅŸenin baÄŸÄ±msÄ±z olarak geliÅŸtirilmesi ve Ã¶lÃ§eklendirilmesi mÃ¼mkÃ¼ndÃ¼r.\n",
        "\n",
        "## KullanÄ±m AlanlarÄ± (Use Cases)\n",
        "\n",
        "RAG pipeline'Ä±, metin tabanlÄ± Ã¼retken modellerin geliÅŸtirilmesinde ve kullanÄ±lmasÄ±nda kullanÄ±labilir. Ã–rneÄŸin, sohbet robotlarÄ± (`chatbots`), metin Ã¶zetleme (`text summarization`) ve iÃ§erik oluÅŸturma (`content generation`) gibi alanlarda kullanÄ±labilir.\n",
        "\n",
        "## Kaynaklar (Resources)\n",
        "\n",
        "- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)\n",
        "- [Vector Databases: A Beginner's Guide](https://www.youtube.com/watch?v=OQBKp9gdHO4)\n",
        "- [A Beginner Guide Vektor Database](https://www.youtube.com/watch?v=NEreO2zlXDk)\n",
        "- [Vector Databases: Complete Tutorial](https://www.youtube.com/watch?v=8KrTO9bS91s)\n",
        "- [What is Vektor Database](https://www.youtube.com/watch?v=gl1r1XV0SLw&pp=ygUPdmVrdG9yIGRhdGFiYXNl)\n",
        "- [Top 5 Vektor Database](https://www.youtube.com/watch?v=csTU7-Wg8Hs)\n",
        "- [OpenAi Embedding Vektor Databese](https://www.youtube.com/watch?v=ySus5ZS0b94)\n",
        "- [Types Vektor Database](https://www.youtube.com/watch?v=VfcRxtBKI54)\n",
        "- [Vektor DataBase PGVektor vs Pinecone](https://www.youtube.com/watch?v=mke1V-2__D0)\n",
        "- [Ä°ntroduction VektÃ¶r Database](https://www.youtube.com/watch?v=f0EcGl9O_Wg&pp=ygUPdmVrdG9yIGRhdGFiYXNl)\n",
        "- [Vektor DataBase Pinecone](https://www.youtube.com/watch?v=56JSsEbMQVA)\n",
        "-[Vektor DataBase ChromeDb](https://www.youtube.com/watch?v=HjvYsUL8NZQ)\n",
        "- [Natural Language Processing (almost) from Scratch](https://arxiv.org/abs/1103.0398)"
      ],
      "metadata": {
        "id": "J6ZGfVqLx5lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG (Retrieval-Augmented Generation) TabanlÄ± Ãœretken Yapay Zeka Ä°ÅŸlem HattÄ± (Pipeline)\n",
        "\n",
        "RAG-driven generative AI pipeline, bÃ¼yÃ¼k dil modellerinin (LLM) geliÅŸtirilmesinde kullanÄ±lan bir yaklaÅŸÄ±mdÄ±r. Bu yaklaÅŸÄ±m, birden fazla bileÅŸeni bir araya getirerek, Ã¼retken yapay zeka uygulamalarÄ±nÄ±n geliÅŸtirilmesini saÄŸlar.\n",
        "\n",
        "### RAG Ä°ÅŸlem HattÄ±nÄ±n BileÅŸenleri\n",
        "\n",
        "RAG iÅŸlem hattÄ± Ã¼Ã§ ana bileÅŸenden oluÅŸur:\n",
        "\n",
        "1. **Veri Toplama ve HazÄ±rlama (Data Collection and Prep - D1 ve D2)**: Bu bileÅŸen, ham verilerin toplanmasÄ± ve temizlenmesi iÅŸlemlerini iÃ§erir. Bu iÅŸlemler, verilerin doÄŸru ve tutarlÄ± olmasÄ±nÄ± saÄŸlar.\n",
        "2. **Veri Embedding ve Depolama (Data Embedding and Storage - D2 ve D3)**: Bu bileÅŸen, toplanan verilerin OpenAI'Ä±n embedding modeli kullanÄ±larak vektÃ¶rleÅŸtirilmesi ve bu vektÃ¶rlerin bir vektÃ¶r veritabanÄ±nda (Ã¶rneÄŸin, Activeloop Deep Lake) depolanmasÄ± iÅŸlemlerini iÃ§erir.\n",
        "3. **ArtÄ±rÄ±lmÄ±ÅŸ Ãœretim (Augmented Generation - D4, G1-G4 ve E1)**: Bu bileÅŸen, kullanÄ±cÄ± girdileri ve retrieval sorgularÄ± temel alÄ±narak iÃ§erik Ã¼retimini gerÃ§ekleÅŸtirir. Bu iÅŸlem, GPT-4 gibi bÃ¼yÃ¼k dil modelleri kullanÄ±larak yapÄ±lÄ±r.\n",
        "\n",
        "### RAG Ä°ÅŸlem HattÄ±nÄ±n AvantajlarÄ±\n",
        "\n",
        "RAG iÅŸlem hattÄ±nÄ±n avantajlarÄ± ÅŸunlardÄ±r:\n",
        "\n",
        "* **ModÃ¼ler YapÄ±**: RAG iÅŸlem hattÄ±, her biri farklÄ± bir bileÅŸene odaklanan birden fazla takÄ±m tarafÄ±ndan geliÅŸtirilebilir. Bu, geliÅŸtirme sÃ¼recini hÄ±zlandÄ±rÄ±r ve ekiplerin birbirlerini beklemesini Ã¶nler.\n",
        "* **Esneklik**: RAG iÅŸlem hattÄ±, farklÄ± veri kaynaklarÄ± ve farklÄ± dil modelleri ile entegre edilebilir.\n",
        "\n",
        "### KullanÄ±lan Teknikler\n",
        "\n",
        "RAG iÅŸlem hattÄ±nda kullanÄ±lan teknikler ÅŸunlardÄ±r:\n",
        "\n",
        "* **Embedding**: Metin verilerinin vektÃ¶rleÅŸtirilmesi iÅŸlemidir. Bu iÅŸlem, OpenAI'Ä±n embedding modeli kullanÄ±larak yapÄ±lÄ±r.\n",
        "* **VektÃ¶r VeritabanÄ±**: VektÃ¶rleÅŸtirilmiÅŸ verilerin depolanmasÄ± iÃ§in kullanÄ±lan bir veritabanÄ±dÄ±r. Ã–rnek olarak Activeloop Deep Lake verilebilir.\n",
        "* **GPT-4**: BÃ¼yÃ¼k bir dil modelidir. Bu model, artÄ±rÄ±lmÄ±ÅŸ Ã¼retim bileÅŸeninde kullanÄ±lÄ±r.\n",
        "\n",
        "### Neden BÃ¶yle YapÄ±lÄ±r?\n",
        "\n",
        "RAG iÅŸlem hattÄ±, bÃ¼yÃ¼k dil modellerinin geliÅŸtirilmesini hÄ±zlandÄ±rmak ve kolaylaÅŸtÄ±rmak iÃ§in tasarlanmÄ±ÅŸtÄ±r. Bu yaklaÅŸÄ±m, birden fazla bileÅŸeni bir araya getirerek, Ã¼retken yapay zeka uygulamalarÄ±nÄ±n geliÅŸtirilmesini saÄŸlar.\n",
        "\n",
        "### KullanÄ±labilecek Projeler\n",
        "\n",
        "RAG iÅŸlem hattÄ±, aÅŸaÄŸÄ±daki projelerde kullanÄ±labilir:\n",
        "\n",
        "* **Chatbot**: RAG iÅŸlem hattÄ±, chatbot uygulamalarÄ±nda kullanÄ±labilir.\n",
        "* **Ä°Ã§erik Ãœretimi**: RAG iÅŸlem hattÄ±, iÃ§erik Ã¼retim uygulamalarÄ±nda kullanÄ±labilir.\n",
        "* **Dil Ã‡eviri**: RAG iÅŸlem hattÄ±, dil Ã§eviri uygulamalarÄ±nda kullanÄ±labilir.\n",
        "\n",
        "### Kaynaklar\n",
        "\n",
        "* [Retrieval-Augmented Generation for Large Language Models: A Survey](https://arxiv.org/abs/2108.12409)\n",
        "* [RAG: Retrieval-Augmented Generation](https://www.pinecone.io/learn/rag-retrieval-augmented-generation/)\n",
        "* [Activeloop Deep Lake](https://www.activeloop.ai/deep-lake/)"
      ],
      "metadata": {
        "id": "KUgZ5XVS0Mab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building RAG Pipeline"
      ],
      "metadata": {
        "id": "kSoFyYRL7bib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RAG Pipeline Kurulumu  (Installation Packages and Libraries)\n",
        "\n",
        "RAG (Retrieval-Augmented Generation) pipeline'Ä± oluÅŸturmak iÃ§in gerekli paket ve kÃ¼tÃ¼phaneleri kurmak gerekmektedir. Bu iÅŸlem sÄ±rasÄ±nda, baÄŸÄ±mlÄ±lÄ±k Ã§akÄ±ÅŸmalarÄ±nÄ± (dependency conflicts) ve kÃ¼tÃ¼phanelerin fonksiyonlarÄ±yla ilgili sorunlarÄ± Ã¶nlemek iÃ§in paket sÃ¼rÃ¼mlerini dondurmak (freeze package versions) Ã¶nemlidir.\n",
        "\n",
        "### BaÄŸÄ±mlÄ±lÄ±k Ã‡akÄ±ÅŸmalarÄ± ve SÃ¼rÃ¼m SorunlarÄ± (Dependency Conflicts and Version Issues)\n",
        "\n",
        "- **SÃ¼rÃ¼m Ã‡akÄ±ÅŸmalarÄ± (Version Conflicts):** KullanÄ±lan kÃ¼tÃ¼phanelerin farklÄ± sÃ¼rÃ¼mleri arasÄ±nda Ã§akÄ±ÅŸmalar olabilir. Ã–rneÄŸin, bir kÃ¼tÃ¼phane belirli bir sÃ¼rÃ¼mdeki baÅŸka bir kÃ¼tÃ¼phaneye baÄŸÄ±mlÄ± olabilir.\n",
        "- **Uygulama Ã‡alÄ±ÅŸtÄ±rma SorunlarÄ± (Application Execution Issues):** Bir uygulamanÄ±n Ã§alÄ±ÅŸmasÄ± iÃ§in bazÄ± kÃ¼tÃ¼phanelerin gÃ¼ncellenmesi gerekebilir. Ã–rneÄŸin, AÄŸustos 2024'te Deep Lake kurulumu iÃ§in Pillow sÃ¼rÃ¼m 10.x.x gereklirken, Google Colab'da bu sÃ¼rÃ¼m 9.x.x idi. Bu nedenle, Deep Lake kurulumundan Ã¶nce Pillow'un kaldÄ±rÄ±lÄ±p yeniden kurulumu gerekmiÅŸtir.\n",
        "- **SÃ¼rÃ¼m DonmasÄ± (Version Freezing):** SÃ¼rÃ¼m dondurma, uzun sÃ¼re aynÄ± sÃ¼rÃ¼mde kalÄ±ndÄ±ÄŸÄ±nda bazÄ± kÃ¼tÃ¼phanelerin iÅŸlevselliÄŸini kaybetmesine (deprecation) veya hatalarÄ±n dÃ¼zeltilmemesine neden olabilir.\n",
        "\n",
        "### Paket SÃ¼rÃ¼mlerini Dondurma (Freezing Package Versions)\n",
        "\n",
        "Paket sÃ¼rÃ¼mlerini dondurmak, bir uygulama iÃ§in belirli bir sÃ¼re boyunca kararlÄ±lÄ±k saÄŸlar, ancak uzun vadede sorunlara yol aÃ§abilir. DiÄŸer taraftan, sÃ¼rÃ¼mleri Ã§ok hÄ±zlÄ± gÃ¼ncelleme de diÄŸer kÃ¼tÃ¼phanelerin iÅŸlemez hale gelmesine neden olabilir. Bu nedenle, sÃ¼rekli bir kalite kontrol sÃ¼reci (continual quality control process) gereklidir.\n",
        "\n",
        "### Kurulum AdÄ±mlarÄ± (Installation Steps)\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, RAG pipeline'Ä± iÃ§in gerekli ortamÄ± oluÅŸturmak Ã¼zere kurulum adÄ±mlarÄ± gerÃ§ekleÅŸtirilecektir. Paket sÃ¼rÃ¼mleri dondurulacaktÄ±r.\n",
        "\n",
        "### KullanÄ±lan Teknikler ve Alternatifler (Used Techniques and Alternatives)\n",
        "\n",
        "- **Paket SÃ¼rÃ¼m YÃ¶netimi (Package Version Management):** `pip freeze` veya `conda env export` gibi komutlar kullanÄ±larak mevcut paket sÃ¼rÃ¼mleri dondurulabilir.\n",
        "- **Ortam YÃ¶netimi (Environment Management):** `conda` veya `virtualenv` gibi araÃ§lar kullanÄ±larak izole edilmiÅŸ ortamlar oluÅŸturulabilir.\n",
        "\n",
        "### Kod Ã–rnekleri (Code Examples)\n",
        "\n",
        "```bash\n",
        "# pip kullanarak paket sÃ¼rÃ¼mlerini dondurma\n",
        "pip freeze > requirements.txt\n",
        "\n",
        "# conda kullanarak ortamÄ± export etme\n",
        "conda env export > environment.yml\n",
        "```\n",
        "\n",
        "### Neden BÃ¶yle YapÄ±lÄ±yor? (Why is it Done This Way?)\n",
        "\n",
        "Paket sÃ¼rÃ¼mlerini dondurmak, geliÅŸtirme ortamÄ±nda tutarlÄ±lÄ±k ve kararlÄ±lÄ±k saÄŸlar. Ancak, gÃ¼venlik yamalarÄ± ve yeni Ã¶zelliklerden yararlanmak iÃ§in dÃ¼zenli olarak gÃ¼ncelleme yapmak Ã¶nemlidir.\n",
        "\n",
        "### KullanÄ±m AlanlarÄ± (Use Cases)\n",
        "\n",
        "- **Makine Ã–ÄŸrenimi Projeleri (Machine Learning Projects):** Ã–zellikle karmaÅŸÄ±k baÄŸÄ±mlÄ±lÄ±klara sahip makine Ã¶ÄŸrenimi projelerinde paket sÃ¼rÃ¼m yÃ¶netimi kritiktir.\n",
        "- **YazÄ±lÄ±m GeliÅŸtirme Projeleri (Software Development Projects):** Her tÃ¼rlÃ¼ yazÄ±lÄ±m geliÅŸtirme projesinde, baÄŸÄ±mlÄ±lÄ±k yÃ¶netimi iÃ§in paket sÃ¼rÃ¼m dondurma ve ortam yÃ¶netimi Ã¶nemlidir.\n",
        "\n",
        "### Kaynaklar (Resources)\n",
        "\n",
        "- [Pip Documentation](https://pip.pypa.io/en/stable/)\n",
        "- [Conda Documentation](https://docs.conda.io/en/latest/)\n",
        "- [Virtualenv Documentation](https://virtualenv.pypa.io/en/latest/)\n",
        "\n",
        "Bu teknikler ve araÃ§lar, yazÄ±lÄ±m projelerinde kararlÄ±lÄ±k ve tekrar Ã¼retilebilirlik (reproducibility) saÄŸlamak iÃ§in kullanÄ±lÄ±r."
      ],
      "metadata": {
        "id": "v0DfOrPJ95UK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### YapÄ±lacak Ä°ÅŸlemler ve Teknikler\n",
        "Bu bÃ¶lÃ¼mde, bir makine Ã¶ÄŸrenimi projesinde gerekli olan ortamÄ±n kurulmasÄ± ve yapÄ±landÄ±rÄ±lmasÄ± iÅŸlemleri anlatÄ±lmaktadÄ±r. KullanÄ±lan teknikler ve kodlar aÃ§Ä±klanacaktÄ±r.\n",
        "\n",
        "### 1. Gerekli Paketlerin KurulmasÄ± (Installing Requirements)\n",
        "Projede kullanÄ±lacak kÃ¼tÃ¼phanelerin kurulmasÄ± iÅŸlemidir. Bu iÅŸlem iÃ§in `pip install` komutu kullanÄ±lÄ±r. Ã–rneÄŸin:\n",
        "```bash\n",
        "!pip install beautifulsoup4==4.12.3\n",
        "!pip install requests==2.31.0\n",
        "```\n",
        "Bu komutlar, `beautifulsoup4` ve `requests` kÃ¼tÃ¼phanelerini belirtilen sÃ¼rÃ¼mlerde kurar.\n",
        "\n",
        "### 2. Google Drive BaÄŸlama (Mounting Google Drive)\n",
        "Google Colab'da Ã§alÄ±ÅŸÄ±rken, Google Drive'Ä± baÄŸlamak iÃ§in aÅŸaÄŸÄ±daki kod kullanÄ±lÄ±r:\n",
        "```python\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "Bu, Google Drive'Ä±n `/content/drive` dizinine baÄŸlanmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "### 3. GitHub'dan Dosya Ä°ndirme (Downloading Files from GitHub)\n",
        "GitHub'dan dosya indirmek iÃ§in `subprocess` modÃ¼lÃ¼ kullanÄ±lÄ±r. Ã–rneÄŸin:\n",
        "```python\n",
        "import subprocess\n",
        "url = \"https://raw.githubusercontent.com/Denis2054/RAG-Driven-Generative-AI/main/commons/grequests.py\"\n",
        "output_file = \"grequests.py\"\n",
        "curl_command = [\"curl\", \"-o\", output_file, url]\n",
        "subprocess.run(curl_command, check=True)\n",
        "```\n",
        "Bu kod, belirtilen URL'den `grequests.py` dosyasÄ±nÄ± indirir.\n",
        "\n",
        "### 4. Gerekli KÃ¼tÃ¼phanelerin KurulmasÄ± (Installing Requirements)\n",
        "Projede kullanÄ±lacak kÃ¼tÃ¼phanelerin kurulmasÄ± iÅŸlemidir. Ã–rneÄŸin:\n",
        "```bash\n",
        "!pip install deeplake==3.9.18\n",
        "!pip install openai==1.40.3\n",
        "```\n",
        "Bu komutlar, `deeplake` ve `openai` kÃ¼tÃ¼phanelerini belirtilen sÃ¼rÃ¼mlerde kurar.\n",
        "\n",
        "### 5. DNS Sunucusunun YapÄ±landÄ±rÄ±lmasÄ± (Configuring DNS Server)\n",
        "Activeloop Deep Lake kÃ¼tÃ¼phanesinin Ã§alÄ±ÅŸmasÄ± iÃ§in Google'Ä±n Public DNS sunucusunun yapÄ±landÄ±rÄ±lmasÄ± gerekir. AÅŸaÄŸÄ±daki kod bunu saÄŸlar:\n",
        "```python\n",
        "with open('/etc/resolv.conf', 'w') as file:\n",
        "   file.write(\"nameserver 8.8.8.8\")\n",
        "```\n",
        "Bu, `/etc/resolv.conf` dosyasÄ±nÄ± `nameserver 8.8.8.8` olarak gÃ¼nceller.\n",
        "\n",
        "### 6. Kimlik DoÄŸrulama (Authentication)\n",
        "OpenAI ve Activeloop API'larÄ±na eriÅŸmek iÃ§in kimlik doÄŸrulama iÅŸlemleri yapÄ±lÄ±r. Ã–rneÄŸin:\n",
        "```python\n",
        "# OpenAI API Key\n",
        "f = open(\"drive/MyDrive/files/api_key.txt\", \"r\")\n",
        "API_KEY=f.readline().strip()\n",
        "f.close()\n",
        "import os\n",
        "import openai\n",
        "os.environ['OPENAI_API_KEY'] =API_KEY\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Activeloop API Token\n",
        "f = open(\"drive/MyDrive/files/activeloop.txt\", \"r\")\n",
        "API_token=f.readline().strip()\n",
        "f.close()\n",
        "ACTIVELOOP_TOKEN=API_token\n",
        "os.environ['ACTIVELOOP_TOKEN'] =ACTIVELOOP_TOKEN\n",
        "\n",
        "```\n",
        "\n",
        "## Ornek download kodu\n",
        "\n",
        "```python\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "# add a private token after the filename if necessary\n",
        "def download(directory, filename):\n",
        "    # The base URL of the image files in the GitHub repository\n",
        "    base_url = 'https://raw.githubusercontent.com/Denis2054/RAG-Driven-Generative-AI/main/'\n",
        "    # Complete URL for the file\n",
        "    file_url = f\"{base_url}{directory}/{filename}\"\n",
        "    # Use curl to download the file, including an Authorization header for the private token\n",
        "    try:\n",
        "        # Prepare the curl command with the Authorization header\n",
        "        #curl_command = f'curl -H \"Authorization: token {private_token}\" -o {filename} {file_url}'\n",
        "        curl_command = f'curl -H -o {filename} {file_url}'\n",
        "        # Execute the curl command\n",
        "        subprocess.run(curl_command, check=True, shell=True)\n",
        "        print(f\"Downloaded '{filename}' successfully.\")\n",
        "    except subprocess.CalledProcessError:\n",
        "        print(f\"Failed to download '{filename}'. Check the URL, your internet connection, and if the token is correct and has appropriate permissions.\")\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "Bu kodlar, OpenAI ve Activeloop API'larÄ±na eriÅŸmek iÃ§in gerekli kimlik doÄŸrulama iÅŸlemlerini yapar.\n",
        "\n",
        "## KullanÄ±lan Teknikler ve Nedenleri\n",
        "- `pip install`: Python paketlerini kurmak iÃ§in kullanÄ±lÄ±r.\n",
        "- `google.colab.drive.mount`: Google Colab'da Google Drive'Ä± baÄŸlamak iÃ§in kullanÄ±lÄ±r.\n",
        "- `subprocess`: Harici komutlarÄ± Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±lÄ±r.\n",
        "- DNS sunucusunun yapÄ±landÄ±rÄ±lmasÄ±: Activeloop Deep Lake kÃ¼tÃ¼phanesinin Ã§alÄ±ÅŸmasÄ± iÃ§in gereklidir.\n",
        "- Kimlik doÄŸrulama: OpenAI ve Activeloop API'larÄ±na eriÅŸmek iÃ§in gereklidir.\n",
        "\n",
        "## Bu Ä°ÅŸlemlerin KullanÄ±labileceÄŸi Projeler\n",
        "- Makine Ã¶ÄŸrenimi projeleri\n",
        "- Derin Ã¶ÄŸrenme projeleri\n",
        "- DoÄŸal dil iÅŸleme projeleri\n",
        "- Veri bilimi projeleri\n",
        "\n",
        "## Kaynaklar\n",
        "- [Google Colab](https://colab.research.google.com/)\n",
        "- [OpenAI](https://openai.com/)\n",
        "- [Activeloop](https://www.activeloop.ai/)\n",
        "- [Deep Lake](https://docs.activeloop.ai/)"
      ],
      "metadata": {
        "id": "BTa6B8tyDSjq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Data Collection and Preparation"
      ],
      "metadata": {
        "id": "-v88ZbU8JJWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veri Toplama ve HazÄ±rlama (Data Collection and Preparation)\n",
        "Veri toplama ve hazÄ±rlama, bir makine Ã¶ÄŸrenimi (Machine Learning) veya doÄŸal dil iÅŸleme (Natural Language Processing) projesinin ilk aÅŸamasÄ±dÄ±r. Bu aÅŸamada, projenin gerektirdiÄŸi veriler toplanÄ±r, iÅŸlenir ve uygun bir formatta saklanÄ±r.\n",
        "\n",
        "![](https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781836200918/files/Images/B31169_02_07.png)\n",
        "\n",
        "### KullanÄ±lan Teknikler\n",
        "Bu projede, veri toplama ve hazÄ±rlama aÅŸamasÄ±nda aÅŸaÄŸÄ±daki teknikler kullanÄ±lmÄ±ÅŸtÄ±r:\n",
        "* **HTTP Ä°stekleri (HTTP Requests)**: `requests` kÃ¼tÃ¼phanesi kullanÄ±larak Wikipedia makalelerine HTTP istekleri gÃ¶nderilir ve iÃ§erik alÄ±nÄ±r.\n",
        "* **HTML AyrÄ±ÅŸtÄ±rma (HTML Parsing)**: `BeautifulSoup` kÃ¼tÃ¼phanesi kullanÄ±larak alÄ±nan HTML iÃ§erik ayrÄ±ÅŸtÄ±rÄ±lÄ±r ve gerekli bilgiler Ã§Ä±karÄ±lÄ±r.\n",
        "* **DÃ¼zenli Ä°fadeler (Regular Expressions)**: `re` kÃ¼tÃ¼phanesi kullanÄ±larak metin iÃ§erisindeki sayÄ±sal referanslar kaldÄ±rÄ±lÄ±r.\n",
        "\n",
        "### Kod AÃ§Ä±klamalarÄ±\n",
        "#### Veri Toplama\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "# Wikipedia makalelerinin URL'leri\n",
        "urls = [\n",
        "    \"https://en.wikipedia.org/wiki/Space_exploration\",\n",
        "    \"https://en.wikipedia.org/wiki/Apollo_program\",\n",
        "    \"https://en.wikipedia.org/wiki/Hubble_Space_Telescope\",\n",
        "    \"https://en.wikipedia.org/wiki/Mars_rover\",\n",
        "    \"https://en.wikipedia.org/wiki/International_Space_Station\",\n",
        "    \"https://en.wikipedia.org/wiki/SpaceX\",\n",
        "    \"https://en.wikipedia.org/wiki/Juno_(spacecraft)\",\n",
        "    \"https://en.wikipedia.org/wiki/Voyager_program\",\n",
        "    \"https://en.wikipedia.org/wiki/Galileo_(spacecraft)\",\n",
        "    \"https://en.wikipedia.org/wiki/Kepler_Space_Telescope\"\n",
        "]\n",
        "```\n",
        "Bu kodda, Wikipedia makalelerinin URL'leri bir liste iÃ§erisinde tanÄ±mlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "#### Veri HazÄ±rlama\n",
        "```python\n",
        "def clean_text(content):\n",
        "    # SayÄ±sal referanslarÄ± kaldÄ±r\n",
        "    content = re.sub(r'\\[\\d+\\]', '', content)\n",
        "    return content\n",
        "\n",
        "def fetch_and_clean(url):\n",
        "    # URL'den iÃ§erik al\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    # Ana iÃ§erik kÄ±smÄ±nÄ± bul\n",
        "    content = soup.find('div', {'class': 'mw-parser-output'})\n",
        "    # Bibliyografya kÄ±smÄ±nÄ± kaldÄ±r\n",
        "    for section_title in ['References', 'Bibliography', 'External links', 'See also']:\n",
        "        section = content.find('span', id=section_title)\n",
        "        if section:\n",
        "            # Bu kÄ±sÄ±mdan sonraki tÃ¼m iÃ§erikleri kaldÄ±r\n",
        "            for sib in section.parent.find_next_siblings():\n",
        "                sib.decompose()\n",
        "            section.parent.decompose()\n",
        "    # Metni Ã§Ä±kar ve temizle\n",
        "    text = content.get_text(separator=' ', strip=True)\n",
        "    text = clean_text(text)\n",
        "    return text\n",
        "```\n",
        "Bu kodda, `clean_text` fonksiyonu sayÄ±sal referanslarÄ± kaldÄ±rÄ±r, `fetch_and_clean` fonksiyonu ise URL'den iÃ§erik alÄ±r, ana iÃ§erik kÄ±smÄ±nÄ± bulur, bibliyografya kÄ±smÄ±nÄ± kaldÄ±rÄ±r ve metni Ã§Ä±karÄ±r.\n",
        "\n",
        "#### Veri Yazma\n",
        "```python\n",
        "with open('llm.txt', 'w', encoding='utf-8') as file:\n",
        "    for url in urls:\n",
        "        clean_article_text = fetch_and_clean(url)\n",
        "        file.write(clean_article_text + '\\n')\n",
        "print(\"Ä°Ã§erik llm.txt dosyasÄ±na yazÄ±ldÄ±\")\n",
        "```\n",
        "Bu kodda, temizlenmiÅŸ iÃ§erikler `llm.txt` dosyasÄ±na yazÄ±lÄ±r.\n",
        "\n",
        "### Neden BÃ¶yle YapÄ±ldÄ±?\n",
        "Veri toplama ve hazÄ±rlama aÅŸamasÄ±, makine Ã¶ÄŸrenimi ve doÄŸal dil iÅŸleme projelerinde Ã¶nemlidir Ã§Ã¼nkÃ¼:\n",
        "* **Veri kalitesi**: Veri kalitesi, modelin performansÄ± Ã¼zerinde bÃ¼yÃ¼k bir etkiye sahiptir.\n",
        "* **Veri formatÄ±**: Veri formatÄ±, modelin gerektirdiÄŸi formatta olmalÄ±dÄ±r.\n",
        "\n",
        "Bu projede, Wikipedia makaleleri toplanmÄ±ÅŸ ve temizlenmiÅŸtir. Bu, makine Ã¶ÄŸrenimi modellerinin eÄŸitilmesi iÃ§in uygun bir veri kÃ¼mesi oluÅŸturur.\n",
        "\n",
        "### KullanÄ±labilecek Projeler\n",
        "Bu teknikler, aÅŸaÄŸÄ±daki projelerde kullanÄ±labilir:\n",
        "* **Metin sÄ±nÄ±flandÄ±rma**: Metinleri sÄ±nÄ±flandÄ±rmak iÃ§in makine Ã¶ÄŸrenimi modelleri eÄŸitilebilir.\n",
        "* **Dil modelleme**: Dil modelleri eÄŸitilebilir ve metin oluÅŸturma, Ã§eviri gibi gÃ¶revlerde kullanÄ±labilir.\n",
        "\n",
        "### Kaynaklar\n",
        "* [BeautifulSoup documentation](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
        "* [Requests documentation](https://requests.readthedocs.io/en/latest/)\n",
        "* [Regular Expressions documentation](https://docs.python.org/3/library/re.html)\n",
        "* [Step Step Data Collection](https://www.couchbase.com/blog/guide-to-data-prep-for-rag/)\n",
        "* [Prepare Data For RAG - Ä°BM](https://developer.ibm.com/tutorials/dpk-rag-llms/)\n",
        "* [How to make data ready for your RAG application with Qdrant and FastEmbed](https://www.youtube.com/watch?v=2CESrNJ3NRI)\n",
        "* [Optimising Data for Advanced AI Responses](https://www.youtube.com/watch?v=pIGRwMjhMaQ)\n",
        "* [Best Tool For Getting Your Data Ready For RAG](https://www.youtube.com/watch?v=gvY4FgMjZUE)\n",
        "* [Python RAG Tutorial (with Local LLMs): AI For Your PDFs](https://www.youtube.com/watch?v=2TJxpyO3ei4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y_Q2AWC7JQlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Data embedding and storage"
      ],
      "metadata": {
        "id": "ipNfbRiUOe92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Veri GÃ¶mmek ve Depolamak (Data Embedding and Storage)\n",
        "\n",
        "Bu bÃ¶lÃ¼mde, veri gÃ¶mmek ve depolamak iÃ§in kullanÄ±lan teknikler ve araÃ§lar ele alÄ±nacaktÄ±r. Veri gÃ¶mmek, metin verilerini vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemidir. Bu iÅŸlem, metinlerin anlamÄ±nÄ± ve iÃ§eriÄŸini daha iyi temsil etmelerini saÄŸlar.\n",
        "\n",
        "### Veri HazÄ±rlama (Data Preparation)\n",
        "\n",
        "Ä°lk olarak, veri hazÄ±rlama aÅŸamasÄ±nda, Team #1 tarafÄ±ndan hazÄ±rlanan veriler alÄ±nÄ±r. Bu veriler, daha sonra iÅŸlenmek Ã¼zere hazÄ±r hale getirilir.\n",
        "\n",
        "```python\n",
        "from grequests import download\n",
        "source_text = \"llm.txt\"\n",
        "directory = \"Chapter02\"\n",
        "filename = \"llm.txt\"\n",
        "download(directory, filename)\n",
        "```\n",
        "\n",
        "### Veri Okuma ve DoÄŸrulama (Data Reading and Verification)\n",
        "\n",
        "Ä°ndirilen veri, ilk 20 satÄ±r okunarak doÄŸrulanÄ±r.\n",
        "\n",
        "```python\n",
        "# Open the file and read the first 20 lines\n",
        "with open('llm.txt', 'r', encoding='utf-8') as file:\n",
        "    lines = file.readlines()\n",
        "    # Print the first 20 lines\n",
        "    for line in lines[:20]:\n",
        "        print(line.strip())\n",
        "```\n",
        "\n",
        "### Veri ParÃ§alama (Chunking)\n",
        "\n",
        "Veri, daha sonra belirli bir boyutta parÃ§alara ayrÄ±lÄ±r. Bu iÅŸlem, veri iÅŸleme ve gÃ¶mme iÅŸlemlerini optimize etmek iÃ§in yapÄ±lÄ±r.\n",
        "\n",
        "```python\n",
        "with open(source_text, 'r') as f:\n",
        "    text = f.read()\n",
        "CHUNK_SIZE = 1000\n",
        "chunked_text = [text[i:i+CHUNK_SIZE] for i in range(0,len(text), CHUNK_SIZE)]\n",
        "```\n",
        "\n",
        "### VektÃ¶r Deposu OluÅŸturma (Creating a Vector Store)\n",
        "\n",
        "VektÃ¶r deposu, veri gÃ¶mmek iÃ§in kullanÄ±lÄ±r. Activeloop vektÃ¶r deposu yolu tanÄ±mlanÄ±r ve depo oluÅŸturulur.\n",
        "\n",
        "```python\n",
        "vector_store_path = \"hub://denis76/space_exploration_v1\"\n",
        "```\n",
        "\n",
        "VektÃ¶r deposu oluÅŸturma veya yÃ¼kleme iÅŸlemi yapÄ±lÄ±r.\n",
        "\n",
        "```python\n",
        "from deeplake.core.vectorstore.deeplake_vectorstore import VectorStore\n",
        "import deeplake.util\n",
        "try:\n",
        "    # Attempt to load the vector store\n",
        "    vector_store = VectorStore(path=vector_store_path)\n",
        "    print(\"Vector store exists\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Vector store does not exist. You can create it.\")\n",
        "    # Code to create the vector store goes here\n",
        "    create_vector_store=True\n",
        "```\n",
        "\n",
        "### GÃ¶mme Fonksiyonu (Embedding Function)\n",
        "\n",
        "GÃ¶mme fonksiyonu, veri parÃ§alarÄ±nÄ± vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lÄ±r. Bu Ã¶rnekte, \"text-embedding-3-small\" modeli kullanÄ±lÄ±r.\n",
        "\n",
        "```python\n",
        "def embedding_function(texts, model=\"text-embedding-3-small\"):\n",
        "   if isinstance(texts, str):\n",
        "       texts = [texts]\n",
        "   texts = [t.replace(\"\\n\", \" \") for t in texts]\n",
        "   return [data.embedding for data in openai.embeddings.create(input = texts, model=model).data]\n",
        "```\n",
        "\n",
        "### Veri Ekleme (Adding Data to the Vector Store)\n",
        "\n",
        "VektÃ¶r deposuna veri eklemek iÃ§in aÅŸaÄŸÄ±daki kod kullanÄ±lÄ±r.\n",
        "\n",
        "```python\n",
        "add_to_vector_store=True\n",
        "if add_to_vector_store == True:\n",
        "    with open(source_text, 'r') as f:\n",
        "        text = f.read()\n",
        "        CHUNK_SIZE = 1000\n",
        "        chunked_text = [text[i:i+1000] for i in range(0, len(text), CHUNK_SIZE)]\n",
        "vector_store.add(text = chunked_text,\n",
        "              embedding_function = embedding_function,\n",
        "              embedding_data = chunked_text,\n",
        "              metadata = [{\"source\": source_text}]*len(chunked_text))\n",
        "```\n",
        "\n",
        "### VektÃ¶r Deposu Bilgileri (Vector Store Information)\n",
        "\n",
        "VektÃ¶r deposu bilgileri, Activeloop'un API referansÄ± kullanÄ±larak elde edilebilir.\n",
        "\n",
        "```python\n",
        "ds = deeplake.load(vector_store_path)\n",
        "```\n",
        "\n",
        "VektÃ¶r deposu boyutu, aÅŸaÄŸÄ±daki kod kullanÄ±larak hesaplanabilir.\n",
        "\n",
        "```python\n",
        "#Estimates the size in bytes of the dataset.\n",
        "ds_size=ds.size_approx()\n",
        "# Convert bytes to megabytes and limit to 5 decimal places\n",
        "ds_size_mb = ds_size / 1048576\n",
        "print(f\"Dataset size in megabytes: {ds_size_mb:.5f} MB\")\n",
        "# Convert bytes to gigabytes and limit to 5 decimal places\n",
        "ds_size_gb = ds_size / 1073741824\n",
        "print(f\"Dataset size in gigabytes: {ds_size_gb:.5f} GB\")\n",
        "```\n",
        "\n",
        "## KullanÄ±lan Teknikler ve AraÃ§lar\n",
        "\n",
        "*   Veri gÃ¶mmek iÃ§in \"text-embedding-3-small\" modeli kullanÄ±lÄ±r.\n",
        "*   VektÃ¶r deposu olarak Activeloop kullanÄ±lÄ±r.\n",
        "*   Veri parÃ§alama iÅŸlemi, veri iÅŸleme ve gÃ¶mme iÅŸlemlerini optimize etmek iÃ§in yapÄ±lÄ±r.\n",
        "\n",
        "## Neden Bu Teknikler KullanÄ±lÄ±r?\n",
        "\n",
        "*   Veri gÃ¶mmek, metin verilerini vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rerek anlamÄ±nÄ± ve iÃ§eriÄŸini daha iyi temsil etmelerini saÄŸlar.\n",
        "*   VektÃ¶r deposu, veri gÃ¶mmek iÃ§in kullanÄ±lÄ±r ve veri sorgulama iÅŸlemlerini hÄ±zlandÄ±rÄ±r.\n",
        "\n",
        "## Bu Tekniklerin KullanÄ±labileceÄŸi Projeler\n",
        "\n",
        "*   DoÄŸal dil iÅŸleme (NLP) projeleri\n",
        "*   Metin sÄ±nÄ±flandÄ±rma projeleri\n",
        "*   Ã–neri sistemleri projeleri\n",
        "\n",
        "## Kaynaklar\n",
        "\n",
        "*   [Activeloop](https://www.activeloop.ai/)\n",
        "*   [OpenAI Embedding Models](https://platform.openai.com/docs/models/embeddings)\n",
        "*   [Deep Lake API Reference](https://docs.deeplake.ai/en/latest/)\n",
        "* [Deep Lake API Reference](https://docs.deeplake.ai/en/latest/)\n",
        "* [Vector Search RAG Tutorial](https://www.youtube.com/watch?v=JEBDfGqrAUA)\n",
        "* [Embeddings, Vector Databases, Similarity Search for RAG Systems Explained](https://www.youtube.com/watch?v=whu7SHx5cko)\n",
        "* [Mastering RAG: A Deep Dive into Embeddings](https://medium.com/@shravankoninti/mastering-rag-a-deep-dive-into-embeddings-b78782aa1259)\n",
        "* [How to Store Embeddings in Vector Search and Implement RAG](https://thenewstack.io/how-to-store-embeddings-in-vector-search-and-implement-rag/)\n",
        "* [Vector Embeddings in RAG Applications](https://wandb.ai/mostafaibrahim17/ml-articles/reports/Vector-Embeddings-in-RAG-Applications--Vmlldzo3OTk1NDA5)\n",
        "* [The Limitations of Text Embeddings in RAG Applications](https://neo4j.com/blog/developer/rag-text-embeddings-limitations/)\n",
        "* [Understanding Embeddings in RAG and How to use them - Llama-Index](https://www.youtube.com/watch?v=v6g8eo86T8A)\n",
        "* [How to automate embedding creation and sync for RAG](https://www.youtube.com/watch?v=j2B5fx1p1Ps)\n",
        "* [How to Use Multimodal RAG to Extract Text, Images, & Tables](https://www.youtube.com/watch?v=jDFpEnJeSVg)\n",
        "* [Advanced RAG: Chunking, Embeddings, and Vector Databases ğŸš€ | LLMOps](https://www.youtube.com/watch?v=tTW3dOfyCpE)\n",
        "* [Build high-performance RAG using just PostgreSQL (Full Tutorial)](https://www.youtube.com/watch?v=hAdEuDBN57g)\n",
        "* [Building Real-Time RAG Pipeline With Mongodb and Pinecone Part-1](https://www.youtube.com/watch?v=lJl_bIXO7_Y)\n",
        "* [Practical RAG - Choosing the Right Embedding Model, Chunking Strategy, and More](https://www.youtube.com/watch?v=j1XRLh7yzzY)\n",
        "* [Advanced RAG Performance: Smart Data Handling Strategies](https://www.youtube.com/watch?v=oSZCIwmp65I)\n",
        "* [RAG with OpenAI & Pinecone Vector Database](https://www.youtube.com/watch?v=IuXVTJm-iF8)\n",
        "* [GenAI 101: Getting Started with a Vector Database](https://www.youtube.com/watch?v=1N-938QsddI)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ai5b3gxbOmuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - Augmented input generation"
      ],
      "metadata": {
        "id": "FKz3-D53VWAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmented Input Generation (GeliÅŸtirilmiÅŸ GiriÅŸ Ãœretimi)\n",
        "Augmented generation, bir makine Ã¶ÄŸrenimi iÅŸlem hattÄ±nÄ±n (pipeline) Ã¼Ã§Ã¼ncÃ¼ bileÅŸenidir. KullanÄ±cÄ± girdisini geliÅŸtirmek iÃ§in alÄ±nan verileri kullanÄ±r. Bu bileÅŸen, kullanÄ±cÄ± girdisini iÅŸler, vektÃ¶r deposunu (vector store) sorgular, girdiyi geliÅŸtirir ve gpt-4-turbo'yu Ã§aÄŸÄ±rÄ±r.\n",
        "\n",
        "### Ä°ÅŸlem AdÄ±mlarÄ±\n",
        "1. **VektÃ¶r Deposu SeÃ§imi**: Ä°lk olarak, vektÃ¶r deposu yolu belirlenir.\n",
        "   ```python\n",
        "vector_store_path = \"hub://denis76/space_exploration_v1\"\n",
        "```\n",
        "2. **Veri YÃ¼kleme**: Deeplake kÃ¼tÃ¼phanesi kullanÄ±larak vektÃ¶r deposu yÃ¼klenir.\n",
        "   ```python\n",
        "from deeplake.core.vectorstore.deeplake_vectorstore import VectorStore\n",
        "import deeplake.util\n",
        "ds = deeplake.load(vector_store_path)\n",
        "vector_store = VectorStore(path=vector_store_path)\n",
        "```\n",
        "3. **KullanÄ±cÄ± Girdisi ve Sorgu Alma**: KullanÄ±cÄ± girdisi alÄ±nÄ±r ve bu girdi, daha Ã¶nce yÃ¼klenen vektÃ¶r deposunda sorgulama yapmak iÃ§in kullanÄ±lÄ±r.\n",
        "   ```python\n",
        "def get_user_prompt():\n",
        "    return input(\"Enter your search query: \")\n",
        "user_prompt = \"Tell me about space exploration on the Moon and Mars.\"\n",
        "```\n",
        "\n",
        "4. **Sorgu Ä°ÅŸlemi**: KullanÄ±cÄ± girdisi, vektÃ¶r deposunda sorgulanÄ±r ve en ilgili sonuÃ§lar alÄ±nÄ±r.\n",
        "   ```python\n",
        "search_results = vector_store.search(embedding_data=user_prompt, embedding_function=embedding_function)\n",
        "```\n",
        "\n",
        "5. **GeliÅŸmiÅŸ Girdi OluÅŸturma**: AlÄ±nan sonuÃ§lar iÃ§inden en Ã¼stteki sonuÃ§, kullanÄ±cÄ± girdisine eklenir.\n",
        "   ```python\n",
        "top_text = search_results['text'][0].strip()\n",
        "augmented_input = user_prompt + \" \" + top_text\n",
        "```\n",
        "\n",
        "6. **GPT-4 ile Ä°Ã§erik Ãœretimi**: GeliÅŸmiÅŸ girdi, GPT-4 modeline verilerek iÃ§erik Ã¼retilir.\n",
        "   ```python\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "gpt_model = \"gpt-4o\"\n",
        "def call_gpt4_with_full_text(itext):\n",
        "    # GPT-4'e Ã§aÄŸrÄ± yapar ve yanÄ±tÄ± dÃ¶ndÃ¼rÃ¼r.\n",
        "    response = client.chat.completions.create(\n",
        "        model=gpt_model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a space exploration expert.\"},\n",
        "            {\"role\": \"assistant\", \"content\": \"You can read the input and answer in detail.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.1\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "gpt4_response = call_gpt4_with_full_text(augmented_input)\n",
        "```\n",
        "\n",
        "7. **YanÄ±tÄ±n BiÃ§imlendirilmesi**: Ãœretilen iÃ§erik, Markdown biÃ§imlendirmesi kullanÄ±larak daha okunabilir hale getirilir.\n",
        "   ```python\n",
        "import textwrap\n",
        "import re\n",
        "from IPython.display import display, Markdown, HTML\n",
        "import markdown\n",
        "def print_formatted_response(response):\n",
        "    # Markdown desenlerini arar ve uygun ÅŸekilde biÃ§imlendirir.\n",
        "    if any(re.search(pattern, response, re.MULTILINE) for pattern in markdown_patterns):\n",
        "        html_output = markdown.markdown(response)\n",
        "        display(HTML(html_output))\n",
        "    else:\n",
        "        wrapper = textwrap.TextWrapper(width=80)\n",
        "        wrapped_text = wrapper.fill(text=response)\n",
        "        print(wrapped_text)\n",
        "print_formatted_response(gpt4_response)\n",
        "```\n",
        "\n",
        "### KullanÄ±lan Teknikler ve KÃ¼tÃ¼phaneler\n",
        "- **Deeplake**: VektÃ¶r deposu olarak kullanÄ±lan bir kÃ¼tÃ¼phane. Veri saklama ve sorgulama iÅŸlemlerini kolaylaÅŸtÄ±rÄ±r.\n",
        "- **OpenAI**: GPT-4 gibi geliÅŸmiÅŸ dil modellerine eriÅŸim saÄŸlar.\n",
        "- **Markdown**: Metin biÃ§imlendirme dili. Ä°Ã§erikleri daha okunabilir hale getirmek iÃ§in kullanÄ±lÄ±r.\n",
        "\n",
        "### Neden Bu Teknikler KullanÄ±ldÄ±?\n",
        "- **GeliÅŸmiÅŸ Girdi OluÅŸturma**: KullanÄ±cÄ± girdisini, ilgili bilgilerle zenginleÅŸtirerek daha doÄŸru ve detaylÄ± iÃ§erik Ã¼retilmesini saÄŸlar.\n",
        "- **VektÃ¶r Deposu**: Ä°lgili iÃ§eriklerin hÄ±zlÄ± ve etkin bir ÅŸekilde sorgulanmasÄ±nÄ± saÄŸlar.\n",
        "\n",
        "### KullanÄ±labilecek Projeler\n",
        "- **Chatbot Sistemleri**: KullanÄ±cÄ±lara daha doÄŸru ve alakalÄ± yanÄ±tlar vermek iÃ§in kullanÄ±labilir.\n",
        "- **Ä°Ã§erik Ãœretimi**: Otomatik iÃ§erik Ã¼retimi iÃ§in kullanÄ±labilir. Ã–rneÄŸin, belirli bir konuda makale veya rapor yazÄ±mÄ±.\n",
        "\n",
        "### Kaynaklar\n",
        "- [Deeplake Resmi DokÃ¼mantasyonu](https://docs.deeplake.ai/en/latest/)\n",
        "- [OpenAI API DokÃ¼mantasyonu](https://platform.openai.com/docs/api-reference)\n",
        "- [Markdown Rehberi](https://www.markdownguide.org/)\n",
        "\n",
        "\n",
        "### YouTube KaynaklarÄ±\n",
        "* [GenAI 101: Getting Started with a Vector Database](https://www.youtube.com/watch?v=1N-938QsddI)\n",
        "* [Vector Search RAG Tutorial](https://www.youtube.com/watch?v=JEBDfGqrAUA)\n",
        "* [How to Use Multimodal RAG to Extract Text, Images, & Tables](https://www.youtube.com/watch?v=jDFpEnJeSVg)\n",
        "\n",
        "### Ä°ngilizce Kaynaklar\n",
        "* [Mastering RAG: A Deep Dive into Embeddings](https://medium.com/@shravankoninti/mastering-rag-a-deep-dive-into-embeddings-b78782aa1259)\n",
        "* [How to Store Embeddings in Vector Search and Implement RAG](https://thenewstack.io/how-to-store-embeddings-in-vector-search-and-implement-rag/)\n",
        "* [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (ArXiv)](https://arxiv.org/abs/2005.11401)\n",
        "\n"
      ],
      "metadata": {
        "id": "Im07eKk6Vf5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 - Similarity - Metrics"
      ],
      "metadata": {
        "id": "uYj33qdmXosx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cosine Similarity ile Ã‡Ä±ktÄ± DeÄŸerlendirme\n",
        "Bu bÃ¶lÃ¼mde, kullanÄ±cÄ± girdisi ve Ã¼retken yapay zeka modelinin Ã§Ä±ktÄ±sÄ± arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mek iÃ§in cosine similarity (kosinÃ¼s benzerliÄŸi) uygulayacaÄŸÄ±z. AyrÄ±ca, geniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ile Ã¼retken yapay zeka modelinin Ã§Ä±ktÄ±sÄ± arasÄ±ndaki benzerliÄŸi de Ã¶lÃ§Ã¼lecektir.\n",
        "\n",
        "### KosinÃ¼s BenzerliÄŸi Fonksiyonu TanÄ±mlama\n",
        "Ä°lk olarak, kosinÃ¼s benzerliÄŸi fonksiyonunu tanÄ±mlayalÄ±m:\n",
        "\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def calculate_cosine_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    tfidf = vectorizer.fit_transform([text1, text2])\n",
        "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
        "    return similarity[0][0]\n",
        "```\n",
        "\n",
        "Bu fonksiyon, iki metin arasÄ±ndaki kosinÃ¼s benzerliÄŸini hesaplar. TF-IDF (Term Frequency-Inverse Document Frequency) vektÃ¶rleÅŸtiricisi kullanÄ±larak metinler vektÃ¶r uzayÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve ardÄ±ndan kosinÃ¼s benzerliÄŸi hesaplanÄ±r.\n",
        "\n",
        "### KullanÄ±cÄ± PromptÄ± ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik\n",
        "KullanÄ±cÄ± promptÄ± ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi hesaplayalÄ±m:\n",
        "\n",
        "```python\n",
        "similarity_score = calculate_cosine_similarity(user_prompt, gpt4_response)\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
        "```\n",
        "\n",
        "Ã‡Ä±ktÄ±:\n",
        "```\n",
        "Cosine Similarity Score: 0.396\n",
        "```\n",
        "\n",
        "Bu skor dÃ¼ÅŸÃ¼k gÃ¶rÃ¼nmektedir, ancak Ã§Ä±ktÄ± insan iÃ§in kabul edilebilir gÃ¶rÃ¼nmektedir.\n",
        "\n",
        "### GeniÅŸletilmiÅŸ KullanÄ±cÄ± Girdisi ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik\n",
        "GeniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi hesaplayalÄ±m:\n",
        "\n",
        "```python\n",
        "similarity_score = calculate_cosine_similarity(augmented_input, gpt4_response)\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
        "```\n",
        "\n",
        "Ã‡Ä±ktÄ±:\n",
        "```\n",
        "Cosine Similarity Score: 0.857\n",
        "```\n",
        "\n",
        "Bu skor daha iyi gÃ¶rÃ¼nmektedir.\n",
        "\n",
        "### KosinÃ¼s BenzerliÄŸi SÄ±nÄ±rlamalarÄ±\n",
        "KosinÃ¼s benzerliÄŸi, TF-IDF kullanÄ±rken tam kelime Ã¶rtÃ¼ÅŸmesine baÄŸlÄ±dÄ±r ve anlamsal anlamlar, eÅŸ anlamlÄ±lar veya baÄŸlamsal kullanÄ±m gibi Ã¶nemli dil Ã¶zelliklerini dikkate alÄ±r. Bu nedenle, kavramsal olarak benzer ancak kelime seÃ§imi farklÄ± olan metinler iÃ§in daha dÃ¼ÅŸÃ¼k benzerlik skorlarÄ± Ã¼retebilir.\n",
        "\n",
        "### CÃ¼mle TransformatÃ¶rleri ile Benzerlik Hesaplama\n",
        "CÃ¼mle TransformatÃ¶rleri, kelimeler ve cÃ¼mleler arasÄ±ndaki daha derin anlamsal iliÅŸkileri yakalayan embeddings kullanÄ±r. Bu yaklaÅŸÄ±m, metinler arasÄ±ndaki baÄŸlamsal ve kavramsal benzerliÄŸi tanÄ±mada daha etkilidir.\n",
        "\n",
        "Ä°lk olarak, sentence-transformers kÃ¼tÃ¼phanesini kuralÄ±m:\n",
        "\n",
        "```bash\n",
        "!pip install sentence-transformers\n",
        "```\n",
        "\n",
        "ArdÄ±ndan, MiniLM mimarisini kullanarak benzerlik hesaplayalÄ±m:\n",
        "\n",
        "```python\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
        "    return similarity[0][0]\n",
        "```\n",
        "\n",
        "Bu fonksiyon, iki metin arasÄ±ndaki kosinÃ¼s benzerliÄŸini embeddings kullanarak hesaplar.\n",
        "\n",
        "### GeniÅŸletilmiÅŸ KullanÄ±cÄ± Girdisi ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik (CÃ¼mle TransformatÃ¶rleri ile)\n",
        "GeniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi CÃ¼mle TransformatÃ¶rleri ile hesaplayalÄ±m:\n",
        "\n",
        "```python\n",
        "similarity_score = calculate_cosine_similarity_with_embeddings(augmented_input, gpt4_response)\n",
        "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
        "```\n",
        "\n",
        "Ã‡Ä±ktÄ±:\n",
        "```\n",
        "Cosine Similarity Score: 0.739\n",
        "```\n",
        "\n",
        "Bu skor, CÃ¼mle TransformatÃ¶rleri'nin metinler arasÄ±ndaki anlamsal benzerliÄŸi daha etkili bir ÅŸekilde yakaladÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.\n",
        "\n",
        "## SonuÃ§\n",
        "KosinÃ¼s benzerliÄŸi ve CÃ¼mle TransformatÃ¶rleri, metinler arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mede farklÄ± yaklaÅŸÄ±mlar sunar. Proje gereksinimlerine baÄŸlÄ± olarak, uygun metrik seÃ§ilmelidir.\n",
        "\n",
        "## Ä°lgili Kaynaklar\n",
        "\n",
        "* [Sentence Transformers](https://www.sbert.net/)\n",
        "* [Hugging Face Model Hub](https://huggingface.co/models)\n",
        "* [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "\n",
        "## KullanÄ±labilecek Projeler\n",
        "Bu teknikler, doÄŸal dil iÅŸleme (NLP) projelerinde, Ã¶zellikle de metin benzerliÄŸi ve anlamsal arama uygulamalarÄ±nda kullanÄ±labilir. Ã–rneÄŸin:\n",
        "\n",
        "* Metin sÄ±nÄ±flandÄ±rma\n",
        "* Anlamsal arama\n",
        "* Otomatik Ã¶zetleme\n",
        "* Makine Ã§evirisi deÄŸerlendirme\n",
        "\n",
        "Bu tekniklerin kullanÄ±labileceÄŸi diÄŸer projeler iÃ§in [NLP uygulamalarÄ±](https://www.nlpapplications.com/) sayfasÄ±nÄ± ziyaret edebilirsiniz."
      ],
      "metadata": {
        "id": "Q_uWLz1BXuXG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "OpenAI Ada documentation for embeddings:\n",
        "https://platform.openai.com/docs/guides/embeddings/embedding-models\n",
        "\n",
        "OpenAI GPT documentation for content generation:\n",
        " https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4\n",
        "\n",
        "Activeloop API documentation:\n",
        "https://docs.deeplake.ai/en/latest/\n",
        "\n",
        "MiniLM model reference:\n",
        "https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2"
      ],
      "metadata": {
        "id": "sNzIqbyiYWmx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBILfsT9NMXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b779b4-f772-4098-e627-35f5c78fa92c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Cosine Similarity ile Ã‡Ä±ktÄ± DeÄŸerlendirme\n",
            "Bu bÃ¶lÃ¼mde, kullanÄ±cÄ± girdisi ve Ã¼retken yapay zeka modelinin Ã§Ä±ktÄ±sÄ± arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mek iÃ§in cosine similarity (kosinÃ¼s benzerliÄŸi) uygulayacaÄŸÄ±z. AyrÄ±ca, geniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ile Ã¼retken yapay zeka modelinin Ã§Ä±ktÄ±sÄ± arasÄ±ndaki benzerliÄŸi de Ã¶lÃ§Ã¼lecektir.\n",
            "\n",
            "### KosinÃ¼s BenzerliÄŸi Fonksiyonu TanÄ±mlama\n",
            "Ä°lk olarak, kosinÃ¼s benzerliÄŸi fonksiyonunu tanÄ±mlayalÄ±m:\n",
            "\n",
            "```python\n",
            "from sklearn.feature_extraction.text import TfidfVectorizer\n",
            "from sklearn.metrics.pairwise import cosine_similarity\n",
            "\n",
            "def calculate_cosine_similarity(text1, text2):\n",
            "    vectorizer = TfidfVectorizer()\n",
            "    tfidf = vectorizer.fit_transform([text1, text2])\n",
            "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
            "    return similarity[0][0]\n",
            "```\n",
            "\n",
            "Bu fonksiyon, iki metin arasÄ±ndaki kosinÃ¼s benzerliÄŸini hesaplar. TF-IDF (Term Frequency-Inverse Document Frequency) vektÃ¶rleÅŸtiricisi kullanÄ±larak metinler vektÃ¶r uzayÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve ardÄ±ndan kosinÃ¼s benzerliÄŸi hesaplanÄ±r.\n",
            "\n",
            "### KullanÄ±cÄ± PromptÄ± ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik\n",
            "KullanÄ±cÄ± promptÄ± ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi hesaplayalÄ±m:\n",
            "\n",
            "```python\n",
            "similarity_score = calculate_cosine_similarity(user_prompt, gpt4_response)\n",
            "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
            "```\n",
            "\n",
            "Ã‡Ä±ktÄ±:\n",
            "```\n",
            "Cosine Similarity Score: 0.396\n",
            "```\n",
            "\n",
            "Bu skor dÃ¼ÅŸÃ¼k gÃ¶rÃ¼nmektedir, ancak Ã§Ä±ktÄ± insan iÃ§in kabul edilebilir gÃ¶rÃ¼nmektedir.\n",
            "\n",
            "### GeniÅŸletilmiÅŸ KullanÄ±cÄ± Girdisi ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik\n",
            "GeniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi hesaplayalÄ±m:\n",
            "\n",
            "```python\n",
            "similarity_score = calculate_cosine_similarity(augmented_input, gpt4_response)\n",
            "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
            "```\n",
            "\n",
            "Ã‡Ä±ktÄ±:\n",
            "```\n",
            "Cosine Similarity Score: 0.857\n",
            "```\n",
            "\n",
            "Bu skor daha iyi gÃ¶rÃ¼nmektedir.\n",
            "\n",
            "### KosinÃ¼s BenzerliÄŸi SÄ±nÄ±rlamalarÄ±\n",
            "KosinÃ¼s benzerliÄŸi, TF-IDF kullanÄ±rken tam kelime Ã¶rtÃ¼ÅŸmesine baÄŸlÄ±dÄ±r ve anlamsal anlamlar, eÅŸ anlamlÄ±lar veya baÄŸlamsal kullanÄ±m gibi Ã¶nemli dil Ã¶zelliklerini dikkate alÄ±r. Bu nedenle, kavramsal olarak benzer ancak kelime seÃ§imi farklÄ± olan metinler iÃ§in daha dÃ¼ÅŸÃ¼k benzerlik skorlarÄ± Ã¼retebilir.\n",
            "\n",
            "### CÃ¼mle TransformatÃ¶rleri ile Benzerlik Hesaplama\n",
            "CÃ¼mle TransformatÃ¶rleri, kelimeler ve cÃ¼mleler arasÄ±ndaki daha derin anlamsal iliÅŸkileri yakalayan embeddings kullanÄ±r. Bu yaklaÅŸÄ±m, metinler arasÄ±ndaki baÄŸlamsal ve kavramsal benzerliÄŸi tanÄ±mada daha etkilidir.\n",
            "\n",
            "Ä°lk olarak, sentence-transformers kÃ¼tÃ¼phanesini kuralÄ±m:\n",
            "\n",
            "```bash\n",
            "!pip install sentence-transformers\n",
            "```\n",
            "\n",
            "ArdÄ±ndan, MiniLM mimarisini kullanarak benzerlik hesaplayalÄ±m:\n",
            "\n",
            "```python\n",
            "from sentence_transformers import SentenceTransformer\n",
            "\n",
            "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
            "\n",
            "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
            "    embeddings1 = model.encode(text1)\n",
            "    embeddings2 = model.encode(text2)\n",
            "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
            "    return similarity[0][0]\n",
            "```\n",
            "\n",
            "Bu fonksiyon, iki metin arasÄ±ndaki kosinÃ¼s benzerliÄŸini embeddings kullanarak hesaplar.\n",
            "\n",
            "### GeniÅŸletilmiÅŸ KullanÄ±cÄ± Girdisi ve GPT-4 YanÄ±tÄ± ArasÄ±ndaki Benzerlik (CÃ¼mle TransformatÃ¶rleri ile)\n",
            "GeniÅŸletilmiÅŸ kullanÄ±cÄ± girdisi ve GPT-4 yanÄ±tÄ± arasÄ±ndaki benzerliÄŸi CÃ¼mle TransformatÃ¶rleri ile hesaplayalÄ±m:\n",
            "\n",
            "```python\n",
            "similarity_score = calculate_cosine_similarity_with_embeddings(augmented_input, gpt4_response)\n",
            "print(f\"Cosine Similarity Score: {similarity_score:.3f}\")\n",
            "```\n",
            "\n",
            "Ã‡Ä±ktÄ±:\n",
            "```\n",
            "Cosine Similarity Score: 0.739\n",
            "```\n",
            "\n",
            "Bu skor, CÃ¼mle TransformatÃ¶rleri'nin metinler arasÄ±ndaki anlamsal benzerliÄŸi daha etkili bir ÅŸekilde yakaladÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.\n",
            "\n",
            "## SonuÃ§\n",
            "KosinÃ¼s benzerliÄŸi ve CÃ¼mle TransformatÃ¶rleri, metinler arasÄ±ndaki benzerliÄŸi Ã¶lÃ§mede farklÄ± yaklaÅŸÄ±mlar sunar. Proje gereksinimlerine baÄŸlÄ± olarak, uygun metrik seÃ§ilmelidir.\n",
            "\n",
            "## Ä°lgili Kaynaklar\n",
            "\n",
            "* [Sentence Transformers](https://www.sbert.net/)\n",
            "* [Hugging Face Model Hub](https://huggingface.co/models)\n",
            "* [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
            "\n",
            "## KullanÄ±labilecek Projeler\n",
            "Bu teknikler, doÄŸal dil iÅŸleme (NLP) projelerinde, Ã¶zellikle de metin benzerliÄŸi ve anlamsal arama uygulamalarÄ±nda kullanÄ±labilir. Ã–rneÄŸin:\n",
            "\n",
            "* Metin sÄ±nÄ±flandÄ±rma\n",
            "* Anlamsal arama\n",
            "* Otomatik Ã¶zetleme\n",
            "* Makine Ã§evirisi deÄŸerlendirme\n",
            "\n",
            "Bu tekniklerin kullanÄ±labileceÄŸi diÄŸer projeler iÃ§in [NLP uygulamalarÄ±](https://www.nlpapplications.com/) sayfasÄ±nÄ± ziyaret edebilirsiniz.\n"
          ]
        }
      ],
      "source": [
        "from together import Together\n",
        "\n",
        "def ask_together(content):\n",
        "\n",
        "    client = Together()\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "    messages=[{\"role\":\"user\",\"content\":content},{\"role\":\"user\",\"content\":\"\"}],\n",
        "    temperature=0.51,\n",
        "    top_p=0.91,\n",
        "    seed=198\n",
        ")\n",
        "    return print(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "soru = \"\"\"\n",
        "\n",
        "AÅŸaÄŸÄ±da paragrafÄ± tÃ¼rkÃ§e olarak aÃ§Ä±kla ama ingilizce teknik kavramlarÄ±da yanÄ±na ekle , Konu ile ilgili aÅŸaÄŸÄ±daki text e baÄŸlÄ± kalmadan ve Ã¶nemli noktalar ekle , AÅŸaÄŸÄ±da kullanÄ±lan teknikler dÅŸÄ±nda baÅŸka teknikler var ise onlarÄ±da yaz,kodlarÄ± aÃ§Ä±kla , neden bÃ¶yle yapÄ±ldÄ±ÄŸÄ±nÄ± yaz , ayrÄ±ca bu iÅŸlemin ne tÃ¼r projelerde kullanÄ±labileceÄŸini ifade et , ayrÄ±ca konuyla ilgili internetteki kaynaklardan alacaÄŸÄ±n linkleride ekle , ayrÄ±ca markdown olarak ## ifadeleri ile yaz, LÃ¼tfen tÃ¼m kodlarÄ± eksiksiz yaz ve resim linklerini verdim onlarÄ±da ilgili yerde gÃ¶ster.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ask_together(soru)"
      ]
    }
  ]
}