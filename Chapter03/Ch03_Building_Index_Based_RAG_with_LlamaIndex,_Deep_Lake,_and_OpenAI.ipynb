{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMH3j4zknF+fNOTXsxjQPY6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/RAG-Driven-Generative-AI/blob/main/Ch03_Building_Index_Based_RAG_with_LlamaIndex%2C_Deep_Lake%2C_and_OpenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## İndeks Tabanlı RAG (Retrieval-Augmented Generative) Yapıların Oluşturulması\n",
        "\n",
        "İndeksler, kesinlik ve hız performansını artırır, ancak bundan daha fazlasını sunar. İndeksler, bir RAG modelinin ürettiği yanıtın kaynağını tamamen izlenebilir hale getirerek, kullanılan verilerin kesin konumu ve ayrıntılı içeriği hakkında görünürlük sağlar. Bu iyileştirme, yalnızca önyargı ve halüsinasyon gibi sorunları azaltmakla kalmaz, aynı zamanda telif hakkı ve veri bütünlüğü ile ilgili endişeleri de giderir.\n",
        "\n",
        "Bu bölümde, indekslenmiş verilerin üretken yapay zeka uygulamaları üzerinde nasıl daha fazla kontrol sağladığını keşfedeceğiz. Çıktı tatmin edici değilse, indeks sayesinde sorunun tam veri kaynağını belirleyip incelemek mümkün hale gelir. Bu yetenek, veri girdilerini iyileştirmek, sistem yapılandırmalarını ayarlamak veya vektör depolama yazılımı ve üretken modeller gibi bileşenleri değiştirmek için kullanılır.\n",
        "\n",
        "## İndeks Tabanlı RAG Pipeline Mimarisi\n",
        "\n",
        "İndeks tabanlı bir RAG pipeline mimarisini ortaya koyarak başlayacağız. Bu, hız, kesinlik ve izlenebilirliği artıracaktır. LlamaIndex, Deep Lake ve OpenAI'ın sorunsuz bir şekilde entegre edilebileceğini göstereceğiz. Bu, sağlam bir temel oluşturur.\n",
        "\n",
        "### Kullanılan Teknikler ve Kütüphaneler\n",
        "\n",
        "*   **LlamaIndex**: LlamaIndex, büyük dil modelleri (LLM) için indeksleme ve retrieval tabanlı bir çerçevedir.\n",
        "*   **Deep Lake**: Deep Lake, vektör depolama ve yönetimi için kullanılan bir kütüphanedir.\n",
        "*   **OpenAI**: OpenAI, üretken yapay zeka modelleri için kullanılan bir API'dir.\n",
        "\n",
        "## İndeks Türleri\n",
        "\n",
        "*   **Vektör İndeksleme (Vector Indexing)**: Vektör indeksleme, verileri vektör uzayında temsil eder ve benzerlik tabanlı aramalar için kullanılır.\n",
        "    Örnek kod:\n",
        "    ```python\n",
        "    from llama_index import VectorStoreIndex\n",
        "\n",
        "    # Vektör indeks oluşturma\n",
        "    index = VectorStoreIndex(nodes)\n",
        "    ```\n",
        "*   **Ağaç İndeksleme (Tree Indexing)**: Ağaç indeksleme, verileri hiyerarşik bir yapıya göre düzenler ve hızlı arama için kullanılır.\n",
        "    Örnek kod:\n",
        "    ```python\n",
        "    from llama_index import TreeIndex\n",
        "\n",
        "    # Ağaç indeks oluşturma\n",
        "    index = TreeIndex(nodes)\n",
        "    ```\n",
        "*   **Liste İndeksleme (List Indexing)**: Liste indeksleme, verileri sıralı bir liste halinde depolar ve basit aramalar için kullanılır.\n",
        "    Örnek kod:\n",
        "    ```python\n",
        "    from llama_index import ListIndex\n",
        "\n",
        "    # Liste indeks oluşturma\n",
        "    index = ListIndex(nodes)\n",
        "    ```\n",
        "*   **Anahtar Kelime İndeksleme (Keyword Indexing)**: Anahtar kelime indeksleme, verileri anahtar kelimelerle ilişkilendirir ve anahtar kelime tabanlı aramalar için kullanılır.\n",
        "    Örnek kod:\n",
        "    ```python\n",
        "    from llama_index import KeywordTableIndex\n",
        "\n",
        "    # Anahtar kelime indeks oluşturma\n",
        "    index = KeywordTableIndex(nodes)\n",
        "    ```\n",
        "\n",
        "## Drone Teknolojisi LLM RAG Ajanı Oluşturma\n",
        "\n",
        "Drone teknolojisi, yangın tespiti, trafik bilgisi ve spor etkinlikleri gibi birçok alanda genişlemektedir. Bu örnekte, drone teknolojisi ile ilgili bir LLM RAG ajanı oluşturacağız.\n",
        "\n",
        "### Adım 1: Veri Hazırlama\n",
        "\n",
        "Drone teknolojisi ile ilgili metin verilerini hazırlayın.\n",
        "\n",
        "### Adım 2: İndeks Oluşturma\n",
        "\n",
        "LlamaIndex kullanarak vektör, ağaç, liste ve anahtar kelime indeksleri oluşturun.\n",
        "\n",
        "### Adım 3: Deep Lake Vektör Deposu Oluşturma\n",
        "\n",
        "Deep Lake kullanarak vektör deposu oluşturun ve indeksleri bu depoya yükleyin.\n",
        "\n",
        "### Adım 4: OpenAI ile Entegrasyon\n",
        "\n",
        "OpenAI API'sini kullanarak üretken yapay zeka modeli ile entegrasyon sağlayın.\n",
        "\n",
        "### Adım 5: Skor Sıralama ve Kosinüs Benzerliği\n",
        "\n",
        "Skor sıralama ve kosinüs benzerliği metriklerini kullanarak retrieval sonuçlarını iyileştirin.\n",
        "\n",
        "### Adım 6: Meta Veri Geliştirme\n",
        "\n",
        "İzlenebilirlik için meta verileri geliştirin.\n",
        "\n",
        "### Adım 7: Sorgu Kurulumu ve Üretim Yapılandırması\n",
        "\n",
        "Sorgu kurulumu ve üretim yapılandırmasını ayarlayın.\n",
        "\n",
        "### Adım 8: Otomatik Doküman Sıralama\n",
        "\n",
        "Otomatik doküman sıralamasını tanıtın.\n",
        "\n",
        "## Sonuç\n",
        "\n",
        "Bu bölümde, indeks tabanlı RAG yapıların oluşturulmasını keşfettik. LlamaIndex, Deep Lake ve OpenAI'ın entegrasyonunu gösterdik. Vektör, ağaç, liste ve anahtar kelime indeks türlerini tanıttık. Drone teknolojisi LLM RAG ajanı oluşturma örneğini verdik.\n",
        "\n",
        "## Kaynaklar\n",
        "\n",
        "*   [LlamaIndex Dokümantasyonu](https://gpt-index.readthedocs.io/en/latest/)\n",
        "*   [Deep Lake Dokümantasyonu](https://docs.activeloop.ai/)\n",
        "*   [OpenAI API Dokümantasyonu](https://beta.openai.com/docs/)"
      ],
      "metadata": {
        "id": "G8aP2TKM7VUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## İndeks Tabanlı RAG (Retrieval-Augmented Generation) Kullanmanın Önemi\n",
        "İndeks tabanlı arama, gelişmiş RAG-driven üretken yapay zekayı bir sonraki seviyeye taşır. Büyük hacimli verilerle karşılaşıldığında, veri yığınlarından organize edilmiş, indekslenmiş düğümlere geçerek geri getirme hızını artırır ve böylece bir belgenin kaynağına ve konumuna kadar izlenebilirlik sağlar.\n",
        "\n",
        "## Vektör Tabanlı Benzerlik Araması ile İndeks Tabanlı Arama Arasındaki Farklar\n",
        "Vektör tabanlı benzerlik araması ve indeks tabanlı arama arasındaki farkları anlamak için, indeks tabanlı RAG'ın mimarisini analiz edeceğiz.\n",
        "\n",
        "### Mimarisi\n",
        "İndeks tabanlı arama, RAG'da vektör tabanlı aramadan daha hızlıdır çünkü doğrudan indeksleri kullanarak ilgili verilere erişir. Vektör tabanlı arama ise tüm kayıtlar arasında sırayla embedding karşılaştırmaları yapar.\n",
        "\n",
        "## İşlem Adımları\n",
        "1. **Veri Toplama ve Hazırlama (Pipeline #1)**: Verileri toplar ve hazırlarız. Ancak bu kez, veri kaynağını tek bir belge olarak hazırlarız ve bunları ayrı dosyalarda saklarız. Daha sonra adlarını ve konumlarını vektör deposuna yüklediğimiz meta verilere ekleriz.\n",
        "2. **Embedding ve Vektör Deposu (Pipeline #2)**: Verileri embedding yaparak vektör deposuna saklarız. Burada, llama-index-vector-stores-deeplake paketini kullanarak verileri chunking, embedding, depolama ve LLM entegrasyonu dahil olmak üzere optimize edilmiş bir başlangıç senaryosunda ihtiyacımız olan her şeye sahibiz.\n",
        "3. **İndeks Tabanlı Geri Getirme ve Üretme (Pipeline #3)**: Verileri bir veri kümesine yükleyerek indeks tabanlı geri getirme ve üretme işlemlerini başlatırız. Burada da llama-index-vector-stores-deeplake paketini kullanırız.\n",
        "\n",
        "## Kullanılan Teknikler ve Kodlar\n",
        "- **Vektör Tabanlı Benzerlik Araması**: Vektör tabanlı benzerlik araması, verileri yüksek boyutlu vektörlere dönüştürerek benzerlik araması yapar.\n",
        "- **İndeks Tabanlı Arama**: İndeks tabanlı arama, verileri indeksleyerek hızlı geri getirme sağlar.\n",
        "- **LlamaIndex ve Deep Lake**: LlamaIndex ve Deep Lake, indeks tabanlı RAG için kullanılan kütüphanelerdir.\n",
        "\n",
        "### Örnek Kod\n",
        "```python\n",
        "# Pipeline #1: Veri Toplama ve Hazırlama\n",
        "import os\n",
        "from llama_index import SimpleDirectoryReader\n",
        "\n",
        "# Veri klasörünü oku\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "# Pipeline #2: Embedding ve Vektör Deposu\n",
        "from llama_index import VectorStoreIndex\n",
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "\n",
        "# Deep Lake vektör deposunu oluştur\n",
        "vector_store = DeepLakeVectorStore(dataset_path='my_dataset')\n",
        "\n",
        "# Vektör deposunu indeksle\n",
        "index = VectorStoreIndex.from_documents(documents, vector_store)\n",
        "\n",
        "# Pipeline #3: İndeks Tabanlı Geri Getirme ve Üretme\n",
        "from llama_index import RetrieverQueryEngine\n",
        "\n",
        "# Sorgu motorunu oluştur\n",
        "query_engine = RetrieverQueryEngine(index)\n",
        "\n",
        "# Sorguyu çalıştır\n",
        "response = query_engine.query('Sorgu metni')\n",
        "\n",
        "print(response)\n",
        "```\n",
        "\n",
        "## Neden İndeks Tabanlı RAG Kullanılır?\n",
        "İndeks tabanlı RAG, büyük veri kümeleri üzerinde hızlı ve doğru geri getirme sağlar. Ayrıca, geri getirme işleminin kaynağına kadar izlenebilirlik sağlar.\n",
        "\n",
        "## Kullanım Alanları\n",
        "- **Doğal Dil İşleme**: İndeks tabanlı RAG, doğal dil işleme görevlerinde kullanılabilir.\n",
        "- **Bilgi Geri Getirme**: İndeks tabanlı RAG, bilgi geri getirme sistemlerinde kullanılabilir.\n",
        "- **Üretken Yapay Zeka**: İndeks tabanlı RAG, üretken yapay zeka uygulamalarında kullanılabilir.\n",
        "\n",
        "## Diğer Teknikler\n",
        "- **Vektör Tabanlı Benzerlik Araması**: Vektör tabanlı benzerlik araması, verileri yüksek boyutlu vektörlere dönüştürerek benzerlik araması yapar.\n",
        "- **Liste Tabanlı Arama**: Liste tabanlı arama, verileri listeleyerek arama yapar.\n",
        "- **Anahtar Kelime Tabanlı Arama**: Anahtar kelime tabanlı arama, verileri anahtar kelimelere göre arayarak geri getirme yapar.\n",
        "\n",
        "## Sonuç\n",
        "İndeks tabanlı RAG, büyük veri kümeleri üzerinde hızlı ve doğru geri getirme sağlar. LlamaIndex ve Deep Lake kütüphaneleri kullanılarak kolayca uygulanabilir."
      ],
      "metadata": {
        "id": "XY3sYaCv8p6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drone Teknolojisi için Anlamsal Arama Motoru ve Üretken Ajan Oluşturma (Building a Semantic Search Engine and Generative Agent for Drone Technology)\n",
        "\n",
        "Bu bölümde, Deep Lake vektör depoları (Deep Lake vector stores), LlamaIndex ve OpenAI kullanarak anlamsal indeks tabanlı bir arama motoru ve üretken yapay zeka ajan motoru oluşturacağız. Daha önce de belirtildiği gibi, drone teknolojisi yangın tespiti ve trafik kontrolü gibi alanlarda genişliyor. Bu nedenle, programın amacı drone teknolojisi soruları ve cevapları için indeks tabanlı bir RAG (Retrieval-Augmented Generation) ajanı sağlamaktır.\n",
        "\n",
        "## Önemli Noktalar\n",
        "*   Anlamsal indeks tabanlı arama motoru ve üretken yapay zeka ajan motoru oluşturma\n",
        "*   Deep Lake vektör depoları, LlamaIndex ve OpenAI kullanma\n",
        "*   Drone teknolojisi soruları ve cevapları için indeks tabanlı RAG ajanı oluşturma\n",
        "*   Bilgisayar görüşü tekniklerini kullanarak araçları ve diğer nesneleri tanımlama\n",
        "\n",
        "## Kodlar ve Açıklamalar\n",
        "### Ortamın Kurulumu (Installing the Environment)\n",
        "Ortamı kurmak için gerekli paketleri yükleyeceğiz. LlamaIndex, Deep Lake vektör depolama yetenekleri ve OpenAI modüllerini entegre eden paketleri yüklemek önemlidir.\n",
        "\n",
        "```python\n",
        "!pip install llama-index-vector-stores-deeplake==0.1.6\n",
        "!pip install deeplake==3.9.8\n",
        "!pip install llama-index==0.10.64\n",
        "```\n",
        "\n",
        "Bu kodlar, sırasıyla `llama-index-vector-stores-deeplake`, `deeplake` ve `llama-index` paketlerini yükler.\n",
        "\n",
        "### Paketlerin İthal Edilmesi\n",
        "Paketlerin doğru şekilde yüklendiğini doğrulamak için, `llama-index`'ten gerekli modülleri ithal edeceğiz.\n",
        "\n",
        "```python\n",
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Document\n",
        "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
        "```\n",
        "\n",
        "Bu kod, `VectorStoreIndex`, `SimpleDirectoryReader`, `Document` ve `DeepLakeVectorStore` modüllerini `llama-index`'ten ithal eder.\n",
        "\n",
        "## İşlem Hattı (Pipeline)\n",
        "Program üç ana işlem hattından oluşur:\n",
        "1.  **Dokümanların Toplanması ve Hazırlanması** (Collecting and Preparing the Documents): GitHub ve Wikipedia gibi kaynaklardan dokümanları toplar ve indeksleme için hazırlar.\n",
        "2.  **Deep Lake Vektör Deposunun Oluşturulması ve Doldurulması** (Creating and Populating a Deep Lake Vector Store): Hazırlanan dokümanlarla Deep Lake vektör deposunu oluşturur ve doldurur.\n",
        "3.  **İndeks Tabanlı RAG için Sorgu İşleme ve Üretme** (Index-based RAG for Query Processing and Generation): LLMs (Large Language Models) ve kosinüs benzerliği metriği (cosine similarity metric) kullanarak zaman ve skor performanslarını uygular.\n",
        "\n",
        "Bu işlem hatları, projenin farklı bileşenlerini bağımsız olarak ve paralel olarak ilerletmesine olanak tanır."
      ],
      "metadata": {
        "id": "Zu0H-gzBaa9y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline 1: Dokümanların Toplanması ve Hazırlanması (Collecting and Preparing the Documents)\n",
        "Bu bölümde, drone ile ilgili dokümanları, kaynaklarına geri izlenebilmeleri için gerekli meta verilerle birlikte toplayacağız ve hazırlayacağız. Hedef, bir yanıtın içeriğini, kaynağını bulmak için alınan veri parçasına kadar geri izlemektir.\n",
        "\n",
        "### İlk Adım: Veri Dizinini Oluşturma (Creating a Data Directory)\n",
        "İlk olarak, dokümanları yükleyeceğimiz bir veri dizini oluşturacağız:\n",
        "```python\n",
        "!mkdir data\n",
        "```\n",
        "Bu komut, `data` adında bir dizin oluşturur.\n",
        "\n",
        "### Veri Toplama ve Temizleme (Data Collection and Cleaning)\n",
        "Drone teknolojisi verileri için heterojen bir corpus kullanacağız ve bu verileri BeautifulSoup kullanarak işleyeceğiz:\n",
        "```python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "\n",
        "urls = [\n",
        "    \"https://github.com/VisDrone/VisDrone-Dataset\",\n",
        "    \"https://paperswithcode.com/dataset/visdrone\",\n",
        "    \"https://openaccess.thecvf.com/content_ECCVW_2018/papers/11133/Zhu_VisDrone-DET2018_The_Vision_Meets_Drone_Object_Detection_in_Image_Challenge_ECCVW_2018_paper.pdf\",\n",
        "    \"https://github.com/VisDrone/VisDrone2018-MOT-toolkit\",\n",
        "    \"https://en.wikipedia.org/wiki/Object_detection\",\n",
        "    \"https://en.wikipedia.org/wiki/Computer_vision\",\n",
        "    # ...\n",
        "]\n",
        "\n",
        "def clean_text(content):\n",
        "    # Referansları ve istenmeyen karakterleri kaldır (Removing references and unwanted characters)\n",
        "    content = re.sub(r'\\[\\d+\\]', '', content)  # Referansları kaldır (Remove references)\n",
        "    content = re.sub(r'[^\\w\\s\\.]', '', content)  # Nokta hariç noktalama işaretlerini kaldır (Remove punctuation except periods)\n",
        "    return content\n",
        "\n",
        "def fetch_and_clean(url):\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Kötü yanıtlar için istisna oluştur (Raise exception for bad responses)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        # \"mw-parser-output\" sınıfını önceliklendir, bulunamazsa \"content\" kimlikli öğeyi kullan (Prioritize \"mw-parser-output\" but fall back to \"content\" class if not found)\n",
        "        content = soup.find('div', {'class': 'mw-parser-output'}) or soup.find('div', {'id': 'content'})\n",
        "        if content is None:\n",
        "            return None\n",
        "        # Belirli bölümleri, iç içe olanları da dahil olmak üzere kaldır (Remove specific sections, including nested ones)\n",
        "        for section_title in ['References', 'Bibliography', 'External links', 'See also', 'Notes']:\n",
        "            section = content.find('span', id=section_title)\n",
        "            while section:\n",
        "                for sib in section.parent.find_next_siblings():\n",
        "                    sib.decompose()\n",
        "                section.parent.decompose()\n",
        "                section = content.find('span', id=section_title)\n",
        "        # Metni çıkar ve temizle (Extract and clean text)\n",
        "        text = content.get_text(separator=' ', strip=True)\n",
        "        text = clean_text(text)\n",
        "        return text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"{url} adresinden içerik alınırken hata oluştu: {e}\")\n",
        "        return None  # Hata durumunda None döndür (Return None on error)\n",
        "```\n",
        "Bu kod, belirtilen URL'lerden içerik çeker, temizler ve işler.\n",
        "\n",
        "### Temizlenen Verilerin Kaydedilmesi (Saving Cleaned Data)\n",
        "Her bir URL için temizlenen metni, kaynak URL'sine göre adlandırılmış bir dosyaya kaydedeceğiz:\n",
        "```python\n",
        "output_dir = './data/'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for url in urls:\n",
        "    article_name = url.split('/')[-1].replace('.html', '')  # .html uzantısını işle (Handle .html extension)\n",
        "    filename = os.path.join(output_dir, article_name + '.txt')  # Makale için dosya adı oluştur (Create a filename for the article)\n",
        "    clean_article_text = fetch_and_clean(url)\n",
        "    with open(filename, 'w', encoding='utf-8') as file:\n",
        "        file.write(clean_article_text)\n",
        "\n",
        "print(f\"İçerikler (alınabilenler) '{output_dir}' dizinindeki dosyalara yazıldı.\")\n",
        "```\n",
        "Bu kod, temizlenen metinleri `data` dizinine kaydeder.\n",
        "\n",
        "### Dokümanların Yüklenmesi (Loading Documents)\n",
        "Şimdi, dokümanları `./data/` dizininden yükleyeceğiz:\n",
        "```python\n",
        "documents = SimpleDirectoryReader(\"./data/\").load_data()\n",
        "```\n",
        "`SimpleDirectoryReader`, LlamaIndex tarafından sağlanan ve dizindeki desteklenen dosya türlerini (`*.txt`, `*.pdf`, `*.docx` gibi) yükleyen bir sınıftır.\n",
        "\n",
        "### İlk Dokümanın İncelenmesi (Inspecting the First Document)\n",
        "Yüklenen doküman listesindeki ilk öğeyi inceleyelim:\n",
        "```python\n",
        "documents[0]\n",
        "```\n",
        "Bu, ilk dokümanın içeriğini ve meta verilerini gösterir.\n",
        "\n",
        "## Önemli Noktalar (Key Points)\n",
        "- Drone ile ilgili dokümanlar toplanır ve hazırlanır.\n",
        "- Veri temizleme (`clean_text` ve `fetch_and_clean` fonksiyonları) işlemleri yapılır.\n",
        "- Temizlenen veriler `data` dizinine kaydedilir.\n",
        "- `SimpleDirectoryReader` kullanılarak dokümanlar yüklenir.\n",
        "- İlk dokümanın içeriği ve meta verileri incelenir.\n",
        "\n",
        "## Teknik Terimler (Technical Terms)\n",
        "- **Corpus** (Corpus): Belirli bir içerik veya konu ile ilgili metinlerin toplanması.\n",
        "- **BeautifulSoup** (BeautifulSoup): HTML ve XML dokümanlarını ayrıştırmak için kullanılan bir Python kütüphanesi.\n",
        "- **SimpleDirectoryReader** (SimpleDirectoryReader): LlamaIndex tarafından sağlanan, dizindeki dosyaları yüklemeye yarayan bir sınıf.\n",
        "- **RAG** (Retrieval-Augmented Generation): Bilgi erişimi ve metin oluşturma işlemlerini birleştiren bir yapay zeka modeli."
      ],
      "metadata": {
        "id": "O_wi3lsxbVju"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PipeLine 2 : (Deep Lake) Vektör Deposu Oluşturma ve Doldurma\n",
        "Bu bölümde, bir Derin Göl (Deep Lake) vektör deposu oluşturacağız ve bunu belgelerimizdeki verilerle dolduracağız. Standart bir tensor konfigürasyonu uygulayacağız:\n",
        "\n",
        "*   **text (str)**: Metin, belgeler sözlüğünde listelenen metin dosyalarından birinin içeriğidir. Sorunsuz bir şekilde işlenir ve anlamlı parçalara bölünür (`chunking`).\n",
        "*   **metadata (json)**: Bu durumda, metadata her bir metin parçasının kaynak dosyasını içerir. Bu bilgiye kodda nasıl erişeceğimizi göreceğiz.\n",
        "*   **embedding (float32)**: Embedding, LlamaIndex-Derine Göl (Deep Lake)-OpenAI paketi tarafından doğrudan çağrılan bir OpenAI embedding modeli kullanılarak oluşturulur.\n",
        "*   **id (str, otomatik olarak doldurulur)**: Her bir parçaya benzersiz bir ID atanır. Vektör deposu ayrıca 0'dan n'ye kadar bir sayı olan bir dizin içerir, ancak anlamsal olarak kullanılamaz çünkü veri kümesini her değiştirdiğimizde değişir. Ancak, benzersiz ID alanı değiştirilmeden kalacaktır.\n",
        "\n",
        "### Kodları Açıklama\n",
        "\n",
        "İlk olarak, vektör deposu ve veri kümesi yollarını tanımlarız:\n",
        "\n",
        "```python\n",
        "from llama_index.core import StorageContext\n",
        "vector_store_path = \"hub://denis76/drone_v2\"\n",
        "dataset_path = \"hub://denis76/drone_v2\"\n",
        "```\n",
        "\n",
        "Burada `vector_store_path` ve `dataset_path` değişkenlerine Derin Göl (Deep Lake) vektör deposunun ve veri kümesinin yollarını atıyoruz. Bu yolları kendi hesabınızın adıyla ve kullanmak istediğiniz veri kümesinin adıyla değiştirmelisiniz:\n",
        "\n",
        "```python\n",
        "vector_store_path = \"hub://[YOUR VECTOR STORE/\"\n",
        "```\n",
        "\n",
        "Ardından, bir vektör deposu oluşturur, onu doldurur ve belgeler üzerinde bir dizin oluştururuz:\n",
        "\n",
        "```python\n",
        "# overwrite=True veri kümesini üzerine yazar, False ise ekler\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=True)\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "# Belgelerden bir dizin oluştur\n",
        "index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
        "```\n",
        "\n",
        "`overwrite=True` olduğunda, vektör deposu oluşturulur ve mevcut olan üzerine yazılır. `overwrite=False` ise veri kümesini ekler.\n",
        "\n",
        "### Veri Kümesinin Yapısı\n",
        "\n",
        "Oluşturulan veri kümesinin yapısı aşağıdaki gibidir:\n",
        "\n",
        "*   **text**: Metin içeriği\n",
        "*   **metadata**: Metadata bilgileri (dosya yolu, dosya adı, dosya türü, dosya boyutu, oluşturma tarihi, son değiştirme tarihi vb.)\n",
        "*   **embedding**: Metin içeriğinin embedding vektörü\n",
        "*   **id**: Benzersiz ID\n",
        "\n",
        "### Veri Kümesini Yükleme ve Görselleştirme\n",
        "\n",
        "Veri kümesini yüklemek için:\n",
        "\n",
        "```python\n",
        "import deeplake\n",
        "ds = deeplake.load(dataset_path)  # Veri kümesini yükle\n",
        "```\n",
        "\n",
        "Veri kümesini Jupyter Notebook'ta veya https://app.activeloop.ai/ adresinde görselleştirebiliriz:\n",
        "\n",
        "```python\n",
        "ds.visualize()\n",
        "```\n",
        "\n",
        "### Veri Kümesini Pandas DataFrame'e Yükleme\n",
        "\n",
        "Veri kümesini bir Pandas DataFrame'e yüklemek için:\n",
        "\n",
        "```python\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Veri kümesindeki tensorları bir sözlüğe yükle\n",
        "data = {}\n",
        "for tensor_name in ds.tensors:\n",
        "    tensor_data = ds[tensor_name].numpy()\n",
        "    if tensor_data.ndim > 1:\n",
        "        data[tensor_name] = [np.array(e).flatten().tolist() for e in tensor_data]\n",
        "    else:\n",
        "        if tensor_name == \"text\":\n",
        "            data[tensor_name] = [t.tobytes().decode('utf-8') if t else \"\" for t in tensor_data]\n",
        "        else:\n",
        "            data[tensor_name] = tensor_data.tolist()\n",
        "\n",
        "# Sözlükten Pandas DataFrame oluştur\n",
        "df = pd.DataFrame(data)\n",
        "```\n",
        "\n",
        "### Kaydı Görüntüleme\n",
        "\n",
        "Bir kaydı görüntülemek için:\n",
        "\n",
        "```python\n",
        "# Seçilen kaydı görüntüleme fonksiyonu\n",
        "def display_record(record_number):\n",
        "    record = df.iloc[record_number]\n",
        "    display_data = {\n",
        "        \"ID\": record[\"id\"] if \"id\" in record else \"N/A\",\n",
        "        \"Metadata\": record[\"metadata\"] if \"metadata\" in record else \"N/A\",\n",
        "        \"Text\": record[\"text\"] if \"text\" in record else \"N/A\",\n",
        "        \"Embedding\": record[\"embedding\"] if \"embedding\" in record else \"N/A\"\n",
        "    }\n",
        "\n",
        "# Kaydı görüntüle\n",
        "rec = 0  # İstenen kayıt numarasıyla değiştirin\n",
        "display_record(rec)\n",
        "```\n",
        "\n",
        "### Önemli Noktalar\n",
        "\n",
        "*   Derin Göl (Deep Lake) vektör deposu oluşturma ve doldurma\n",
        "*   Veri kümesinin yapısı (`text`, `metadata`, `embedding`, `id`)\n",
        "*   Veri kümesini yükleme ve görselleştirme\n",
        "*   Veri kümesini Pandas DataFrame'e yükleme\n",
        "*   Kaydı görüntüleme\n",
        "\n",
        "### Teknik Terimler\n",
        "\n",
        "*   **Derin Göl (Deep Lake)**: Büyük veri kümelerini depolamak ve yönetmek için kullanılan bir veri gölü platformu\n",
        "*   **Vektör Deposu (Vector Store)**: Vektörleri depolamak için kullanılan bir veri deposu\n",
        "*   **Tensor**: Çok boyutlu diziler için kullanılan bir matematiksel nesne\n",
        "*   **Embedding**: Metin veya diğer verileri vektör uzayında temsil etmek için kullanılan bir teknik\n",
        "*   **Metadata**: Veriler hakkında bilgi sağlayan ek veriler\n",
        "\n",
        "### İlgili Kodlar\n",
        "\n",
        "*   `DeepLakeVectorStore`: Derin Göl (Deep Lake) vektör deposu oluşturmak için kullanılan sınıf\n",
        "*   `StorageContext`: Depolama bağlamı oluşturmak için kullanılan sınıf\n",
        "*   `VectorStoreIndex`: Vektör deposu dizini oluşturmak için kullanılan sınıf\n",
        "*   `deeplake.load`: Derin Göl (Deep Lake) veri kümesini yüklemek için kullanılan fonksiyon\n",
        "*   `ds.visualize`: Derin Göl (Deep Lake) veri kümesini görselleştirmek için kullanılan fonksiyon"
      ],
      "metadata": {
        "id": "5ZRsPqHqceAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline 3: Index-based RAG (İndeks Tabanlı RAG)\n",
        "Bu bölümde, Deep Lake ile hazırladığımız ve işlediğimiz verileri kullanarak LlamaIndex ile bir indeks tabanlı RAG pipeline'ı uygulayacağız. Heterojen (gürültü içeren) drone ile ilgili belge koleksiyonundan ilgili bilgileri alacağız ve OpenAI'ın LLM modelleri aracılığıyla yanıtı sentezleyeceğiz.\n",
        "\n",
        "## Uygulanacak İndeks Motorları\n",
        "Dört indeks motoru uygulayacağız:\n",
        "*   ## Vector Store Index Engine (Vektör Depolama İndeks Motoru): Belgelerden bir vektör depolama indeksi oluşturur, böylece benzerlik tabanlı aramaları etkin kılar.\n",
        "*   ## Tree Index (Ağaç İndeks): Belgelerden hiyerarşik bir ağaç indeksi oluşturur, alternatif bir erişim yapısı sunar.\n",
        "*   ## List Index (Liste İndeks): Belgelerden basit bir liste indeksi oluşturur.\n",
        "*   ## Keyword Table Index (Anahtar Kelime Tablosu İndeks): Belgelerden çıkarılan anahtar kelimelere dayalı bir indeks oluşturur.\n",
        "\n",
        "## LLM ile Sorgulama\n",
        "LLM ile sorgulama yapacağız:\n",
        "*   ## Query Response and Source (Sorgu Yanıtı ve Kaynağı): Kullanıcı girdisini indeks ile sorgular, ilgili belgeleri alır ve sentezlenmiş bir yanıt ile kaynak bilgisini döndürür.\n",
        "\n",
        "## Kullanıcı Girdisi ve Sorgu Parametreleri\n",
        "Kullanıcı girdisi, çalıştıracağımız dört indeks motoru için referans sorusu olacaktır. Her yanıtı indeks motorunun erişimlerine göre değerlendireceğiz ve çıktıları zaman ve skor oranlarını kullanarak ölçütleyeceğiz.\n",
        "\n",
        "Kullanıcı girdisi:\n",
        "```python\n",
        "user_input = \"How do drones identify vehicles?\"\n",
        "```\n",
        "Dört sorgu motoru, aynı parametrelerle sorunsuz bir şekilde çağrılacak. Ayarlayacağımız üç parametre:\n",
        "```python\n",
        "#similarity_top_k\n",
        "k = 3\n",
        "#temperature\n",
        "temp = 0.1\n",
        "#num_output\n",
        "mt = 1024\n",
        "```\n",
        "Bu parametreler:\n",
        "*   `k=3`: Sorgu motoru, en olası 3 yanıtı bulmak için `top-k` (en olası seçimler) değerini 3 olarak ayarlayacaktır. Bu durumda, `k` bir sıralama işlevi görecek ve LLM'yi en iyi belgeleri seçmeye zorlayacaktır.\n",
        "*   `temp=0.1`: 0.1 gibi düşük bir sıcaklık, LLM'nin kesin sonuçlar üretmesini teşvik edecektir. Sıcaklık 0.9'a yükseltilirse, yanıt daha yaratıcı olacaktır. Ancak bu durumda, hassasiyet gerektiren drone teknolojisini araştırıyoruz.\n",
        "*   `mt=1024`: Bu parametre, çıktıdaki token sayısını 1.024 ile sınırlayacaktır.\n",
        "\n",
        "## Kosinüs Benzerliği Metriği (Cosine Similarity Metric)\n",
        "Kosinüs benzerliği metriği, daha önce Chapter 2'de anlatılmıştır. Burada, yanıtlar için bir fonksiyon oluşturacağız:\n",
        "```python\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
        "    return similarity[0][0]\n",
        "```\n",
        "Bu fonksiyon, sklearn ve Hugging Face'in SentenceTransformer'ını kullanır.\n",
        "\n",
        "## Vektör Depolama İndeks Sorgu Motoru (Vector Store Index Query Engine)\n",
        "VectorStoreIndex, LlamaIndex içinde belgelerden bilgi temsil etmek ve erişmek için vektör embedding'lerini uygulayan bir indeks türüdür. Benzer anlamlara sahip belgeler, vektör uzayında daha yakın embedding'lere sahip olacaktır.\n",
        "\n",
        "```python\n",
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "vector_store_index = VectorStoreIndex.from_documents(documents)\n",
        "```\n",
        "Bu kod, vektör depolama indeksini oluşturur.\n",
        "\n",
        "```python\n",
        "print(type(vector_store_index))\n",
        "```\n",
        "Bu kod, oluşturulan vektör depolama indeksinin türünü yazdırır.\n",
        "\n",
        "```python\n",
        "vector_query_engine = vector_store_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)\n",
        "```\n",
        "Bu kod, sorgu motorunu oluşturur.\n",
        "\n",
        "## Sorgu Yanıtı ve Kaynağı\n",
        "Sorguyu yönetecek ve yanıtın içeriği hakkında bilgi döndürecek bir fonksiyon tanımlayacağız:\n",
        "```python\n",
        "import pandas as pd\n",
        "import textwrap\n",
        "\n",
        "def index_query(input_query):\n",
        "    response = vector_query_engine.query(input_query)\n",
        "    print(textwrap.fill(str(response), 100))\n",
        "    node_data = []\n",
        "    for node_with_score in response.source_nodes:\n",
        "        node = node_with_score.node\n",
        "        node_info = {\n",
        "            'Node ID': node.id_,\n",
        "            'Score': node_with_score.score,\n",
        "            'Text': node.text\n",
        "        }\n",
        "        node_data.append(node_info)\n",
        "    df = pd.DataFrame(node_data)\n",
        "    return df, response\n",
        "```\n",
        "Bu fonksiyon, sorguyu çalıştırır ve sonuçları yapılandırılmış bir biçimde döndürür.\n",
        "\n",
        "```python\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "df, response = index_query(user_input)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
        "print(df.to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "```\n",
        "Bu kod, sorgunun yürütülme süresini ölçer ve sonuçları yazdırır.\n",
        "\n",
        "## Node ID ve Düğüm Bilgisi\n",
        "Node ID, orijinal belgeye geri dönmeyi garanti eder. İlk düğümün node ID'sini almak için:\n",
        "```python\n",
        "nodeid = response.source_nodes[0].node_id\n",
        "nodeid\n",
        "```\n",
        "Bu kod, ilk düğümün node ID'sini döndürür.\n",
        "\n",
        "Düğümün tam metnini almak için:\n",
        "```python\n",
        "response.source_nodes[0].get_text()\n",
        "```\n",
        "Bu kod, düğümün tam metnini döndürür.\n",
        "\n",
        "## Önemli Noktalar\n",
        "*   Dört indeks motoru uygulanmıştır: Vector Store Index Engine, Tree Index, List Index ve Keyword Table Index.\n",
        "*   LLM ile sorgulama yapılmıştır.\n",
        "*   Kosinüs benzerliği metriği kullanılmıştır.\n",
        "*   Vektör depolama indeks sorgu motoru oluşturulmuştur.\n",
        "*   Sorgu yanıtı ve kaynağı işlenmiştir.\n",
        "*   Node ID ve düğüm bilgisi alınmıştır.\n",
        "\n",
        "Tüm kodlar tam olarak birebir aynı olmalıdır. Yukarıdaki kodları kullanarak, indeks tabanlı RAG pipeline'ını uygulayabilirsiniz."
      ],
      "metadata": {
        "id": "Wihd8ryYegxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimize Edilmiş Parçalama (Optimized Chunking)\n",
        "LlamaIndex, içerik parçalama boyutunu otomatik olarak belirleyebilir. Bu sayede, içerik daha anlamlı bir şekilde parçalanabilir.\n",
        "\n",
        "## Parçalama Boyutunun Belirlenmesi\n",
        "Aşağıdaki kod, içerik parçalama boyutunu otomatik olarak belirler:\n",
        "```python\n",
        "for node_with_score in response.source_nodes:\n",
        "    node = node_with_score.node  # NodeWithScore'dan Node nesnesini çıkar\n",
        "    chunk_size = len(node.text)\n",
        "    print(f\"Node ID: {node.id_}, Parçalama Boyutu: {chunk_size} karakter\")\n",
        "```\n",
        "Bu kod, her bir node'un (`Node`) metin uzunluğunu (`len(node.text)`) hesaplar ve parçalama boyutunu (`chunk_size`) belirler.\n",
        "\n",
        "## Performans Metriği (Performance Metric)\n",
        "Performans metriği, sorguların doğruluğu ve geçen süre temel alınarak hesaplanır. Bu fonksiyon, sorgunun performans metriğini ve yürütme süresini hesaplar ve yazdırır.\n",
        "\n",
        "### Performans Metriği Hesaplanması\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "def info_metrics(response):\n",
        "    # Performans hesapla (None skorları işle)\n",
        "    scores = [node.score for node in response.source_nodes if node.score is not None]\n",
        "    if scores:  # Geçerli skor olup olmadığını kontrol et\n",
        "        weights = np.exp(scores) / np.sum(np.exp(scores))\n",
        "        perf = np.average(scores, weights=weights) / elapsed_time\n",
        "    else:\n",
        "        perf = 0  # Tüm skorlar None ise varsayılan değer\n",
        "\n",
        "    # Sonuç, ağırlıklı ortalama skorun geçen süreye bölünmesiyle elde edilir:\n",
        "    perf = np.average(scores, weights=weights) / elapsed_time\n",
        "    return perf\n",
        "```\n",
        "Bu fonksiyon, node'ların skorlarını (`node.score`) kullanarak ağırlıklı ortalama skor hesaplar ve geçen süreye (`elapsed_time`) böler.\n",
        "\n",
        "## Ağaç İndeks Sorgu Motoru (Tree Index Query Engine)\n",
        "LlamaIndex'teki ağaç indeks (`TreeIndex`), metin belgelerini verimli bir şekilde yönetmek ve sorgulamak için hiyerarşik bir yapı oluşturur.\n",
        "\n",
        "### Ağaç İndeks Oluşturma\n",
        "Ağaç indeksi oluşturmak için aşağıdaki kod kullanılır:\n",
        "```python\n",
        "from llama_index.core import TreeIndex\n",
        "tree_index = TreeIndex.from_documents(documents)\n",
        "```\n",
        "Bu kod, `documents` adlı belge koleksiyonundan bir `TreeIndex` nesnesi oluşturur.\n",
        "\n",
        "### Ağaç İndeksi Sorgu Motoru Olarak Kullanma\n",
        "```python\n",
        "tree_query_engine = tree_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)\n",
        "```\n",
        "Bu kod, `tree_index` nesnesini bir sorgu motoru (`query_engine`) olarak yapılandırır.\n",
        "\n",
        "### Sorgu İşlemi ve Performans Metriği\n",
        "```python\n",
        "import time\n",
        "import textwrap\n",
        "\n",
        "# Zamanlayıcı başlat\n",
        "start_time = time.time()\n",
        "response = tree_query_engine.query(user_input)\n",
        "# Zamanlayıcı durdur\n",
        "end_time = time.time()\n",
        "# Yürütme süresini hesapla ve yazdır\n",
        "elapsed_time = end_time - start_time\n",
        "print(f\"Sorgu yürütme süresi: {elapsed_time:.4f} saniye\")\n",
        "print(textwrap.fill(str(response), 100))\n",
        "```\n",
        "Bu kod, sorguyu yürütür, yürütme süresini hesaplar ve sonucu yazdırır.\n",
        "\n",
        "## Önemli Noktalar\n",
        "*   Optimize edilmiş parçalama (`Optimized Chunking`), içerik parçalama boyutunu otomatik olarak belirler.\n",
        "*   Performans metriği (`Performance Metric`), sorguların doğruluğu ve geçen süre temel alınarak hesaplanır.\n",
        "*   Ağaç indeks (`Tree Index`), metin belgelerini verimli bir şekilde yönetmek ve sorgulamak için hiyerarşik bir yapı oluşturur.\n",
        "*   LlamaIndex, Deep Lake ve OpenAI entegrasyonu, AI uygulamalarını daha verimli hale getirir.\n",
        "\n",
        "## Teknik Terimler\n",
        "*   **Chunking** (Parçalama): Büyük verileri daha küçük parçalara ayırma işlemi.\n",
        "*   **LLM** (Large Language Model): Büyük dil modeli, metin işleme ve oluşturma için kullanılan bir yapay zeka modeli.\n",
        "*   **Tree Index** (Ağaç İndeks): Verileri hiyerarşik bir yapı içinde düzenleyen bir veri yapısı.\n",
        "*   **Query Engine** (Sorgu Motoru): Verileri sorgulamak için kullanılan bir bileşen.\n",
        "*   **Performance Metric** (Performans Metriği): Bir sistemin veya algoritmanın performansını ölçmek için kullanılan bir ölçüt."
      ],
      "metadata": {
        "id": "BEjMSoKRe7kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performans Metriği (Performance Metric)\n",
        "Bu bölümde, Kullanıcı Girişi (User Input) ile RAG pipeline yanıtı arasındaki benzerliği ölçmek için Kosinüs Benzerliği (Cosine Similarity) metriği kullanılmıştır.\n",
        "\n",
        "### Kod\n",
        "```python\n",
        "similarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response))\n",
        "print(f\"Kosinüs Benzerliği Skoru: {similarity_score:.3f}\")\n",
        "print(f\"Sorgu Çalıştırma Süresi: {elapsed_time:.4f} saniye\")\n",
        "performance = similarity_score / elapsed_time\n",
        "print(f\"Performans Metriği: {performance:.4f}\")\n",
        "```\n",
        "### Açıklama\n",
        "Bu kod, Kullanıcı Girişi ve RAG pipeline yanıtı arasındaki Kosinüs Benzerliği skorunu hesaplar ve sorgu çalıştırma süresini ölçer. Performans metriği, Kosinüs Benzerliği skoru ile sorgu çalıştırma süresi arasındaki oran olarak hesaplanır.\n",
        "\n",
        "## Liste İndeks Sorgu Motoru (List Index Query Engine)\n",
        "Liste İndeks, düğümlerin bir listesi olarak düşünülmemelidir. Sorgu motoru, Kullanıcı Girişi ve her bir belgeyi bir LLM (Large Language Model) için bir istem olarak işler.\n",
        "\n",
        "### Kod\n",
        "```python\n",
        "from llama_index.core import ListIndex\n",
        "list_index = ListIndex.from_documents(documents)\n",
        "list_query_engine = list_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)\n",
        "```\n",
        "### Açıklama\n",
        "Bu kod, Liste İndeks oluşturur ve onu bir sorgu motoru olarak kullanır. LLM parametreleri değiştirilmeden tutulur, böylece indeks türleri arasında karşılaştırma yapılabilir.\n",
        "\n",
        "## Anahtar Kelime İndeks Sorgu Motoru (Keyword Index Query Engine)\n",
        "Anahtar Kelime İndeks, belgelerden anahtar kelimeleri çıkarır ve onları bir tablo benzeri yapıya yerleştirir.\n",
        "\n",
        "### Kod\n",
        "```python\n",
        "from llama_index.core import KeywordTableIndex\n",
        "keyword_index = KeywordTableIndex.from_documents(documents)\n",
        "keyword_query_engine = keyword_index.as_query_engine(similarity_top_k=k, temperature=temp, num_output=mt)\n",
        "```\n",
        "### Açıklama\n",
        "Bu kod, Anahtar Kelime İndeks oluşturur ve onu bir sorgu motoru olarak kullanır. Anahtar kelimeler, ilgili düğümlere işaret eden ID'ler ile ilişkilendirilir.\n",
        "\n",
        "## Performans Karşılaştırması\n",
        "Farklı indeks türlerinin performansını karşılaştırmak için Kosinüs Benzerliği skoru ve sorgu çalıştırma süresi kullanılır.\n",
        "\n",
        "### Kod\n",
        "```python\n",
        "similarity_score = calculate_cosine_similarity_with_embeddings(user_input, str(response))\n",
        "print(f\"Kosinüs Benzerliği Skoru: {similarity_score:.3f}\")\n",
        "print(f\"Sorgu Çalıştırma Süresi: {elapsed_time:.4f} saniye\")\n",
        "performance = similarity_score / elapsed_time\n",
        "print(f\"Performans Metriği: {performance:.4f}\")\n",
        "```\n",
        "### Açıklama\n",
        "Bu kod, farklı indeks türlerinin performansını karşılaştırmak için kullanılır. Her bir indeks türü için Kosinüs Benzerliği skoru ve sorgu çalıştırma süresi ölçülür ve performans metriği hesaplanır.\n",
        "\n",
        "## Özet (Summary)\n",
        "Bu bölümde, indeks tabanlı arama ve RAG pipeline'ının dönüşümsel etkisi incelenmiştir. İndeks türleri (vektör, ağaç, liste ve anahtar kelime) ve sorgu motorları tanıtılmıştır.\n",
        "\n",
        "### Önemli Noktalar\n",
        "* İndeks tabanlı arama, RAG pipeline'ının performansını artırır.\n",
        "* Farklı indeks türleri, farklı kullanım senaryolarına uygundur.\n",
        "* Kosinüs Benzerliği skoru ve sorgu çalıştırma süresi, performans karşılaştırması için kullanılır.\n",
        "* LlamaIndex, Deep Lake ve OpenAI gibi teknolojiler, RAG pipeline'ında kullanılır.\n",
        "\n",
        "## Teknik Terimler\n",
        "* Kosinüs Benzerliği (Cosine Similarity)\n",
        "* Liste İndeks (List Index)\n",
        "* Anahtar Kelime İndeks (Keyword Index)\n",
        "* Vektör Store (Vector Store)\n",
        "* LLM (Large Language Model)\n",
        "* RAG (Retrieval-Augmented Generation)"
      ],
      "metadata": {
        "id": "efdnp3HwfTA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorular ve Cevaplar\n",
        "Aşağıdaki soruları Evet veya Hayır olarak cevaplayın:\n",
        "\n",
        "## Sorular\n",
        "1. ## İndeksler, retrieval-augmented generative AI'de (İyileştirilmiş üretken yapay zeka) hassasiyeti (precision) ve hızı (speed) artırır mı?\n",
        "Cevap: ## Evet\n",
        "Açıklama: İndeksler (Indexes), büyük veri kümelerinde (large datasets) arama yaparken (search) hızı ve hassasiyeti artırır. Retrieval-augmented generative AI (RAG), üretken yapay zeka modellerinin (generative AI models) dış bilgi kaynaklarına (external knowledge sources) erişimini sağlar ve indeksler bu süreçte önemli rol oynar.\n",
        "\n",
        "2. ## İndeksler, RAG çıktılarına (outputs) izlenebilirlik (traceability) sağlar mı?\n",
        "Cevap: ## Evet\n",
        "Açıklama: İndeksler, RAG modellerinin çıktılarına izlenebilirlik sağlar. Bu, modelin hangi bilgilere dayandığını (provenance) takip etmeyi mümkün kılar.\n",
        "\n",
        "3. ## İndeks tabanlı arama (index-based search), büyük veri kümelerinde vektör tabanlı aramadan (vector-based search) daha mı yavaştır?\n",
        "Cevap: ## Hayır\n",
        "Açıklama: İndeks tabanlı arama genellikle vektör tabanlı aramadan daha hızlıdır. Çünkü indeksler, verileri önceden işlenmiş (pre-processed) ve organize edilmiş bir şekilde saklar.\n",
        "\n",
        "4. ## LlamaIndex, Deep Lake ve OpenAI ile sorunsuz bir şekilde entegre olur mu?\n",
        "Cevap: ## Evet\n",
        "Açıklama: LlamaIndex, Deep Lake ve OpenAI gibi popüler araçlar ve platformlarla entegrasyon (integration) sağlar. Bu, geliştiricilerin (developers) farklı araçları bir arada kullanmalarını kolaylaştırır.\n",
        "\n",
        "5. ## Ağaç (tree), liste (list), vektör (vector) ve anahtar kelime (keyword) indeksleri, mevcut olan tek indeks türleri midir?\n",
        "Cevap: ## Hayır\n",
        "Açıklama: Farklı indeks türleri vardır. Ağaç, liste, vektör ve anahtar kelime indeksleri yaygın kullanılan türlerdir, ancak başka indeks türleri de mevcuttur.\n",
        "\n",
        "6. ## Anahtar kelime indeksi, veri alma işleminde anlamsal anlamaya (semantic understanding) dayanır mı?\n",
        "Cevap: ## Hayır\n",
        "Açıklama: Anahtar kelime indeksleri (keyword indexes), genellikle kelime eşleştirmesine (keyword matching) dayanır ve anlamsal anlamaya (semantic understanding) dayanmaz.\n",
        "\n",
        "7. ## LlamaIndex, parçalama (chunking) ve embedding işlemlerini otomatik olarak halleder mi?\n",
        "Cevap: ## Evet\n",
        "Açıklama: LlamaIndex, veri hazırlama (data preparation) süreçlerini otomatikleştirir, bu da parçalama ve embedding işlemlerini içerir.\n",
        "\n",
        "8. ## RAG tarafından üretilen çıktıların izlenebilirliğini sağlamak için meta veri (metadata) geliştirmeleri önemlidir?\n",
        "Cevap: ## Evet\n",
        "Açıklama: Meta veri geliştirmeleri, RAG çıktılarının izlenebilirliğini (traceability) sağlamak için önemlidir. Bu, modelin karar verme sürecini (decision-making process) anlamak için kritiktir.\n",
        "\n",
        "9. ## Gerçek zamanlı güncellemeler (real-time updates), indeks tabanlı arama sistemine kolayca uygulanabilir mi?\n",
        "Cevap: ## Hayır\n",
        "Açıklama: Gerçek zamanlı güncellemeler, indeks tabanlı arama sistemlerinde zor olabilir. Çünkü indekslerin güncellenmesi (index updates) zaman alabilir ve sistemin performansını (performance) etkileyebilir.\n",
        "\n",
        "10. ## Kosinüs benzerliği (cosine similarity), bu bölümde sorgu doğruluğunu (query accuracy) değerlendirmek için kullanılan bir metriktir?\n",
        "Cevap: ## Evet\n",
        "Açıklama: Kosinüs benzerliği, vektörler arasındaki benzerliği (vector similarity) ölçmek için kullanılan bir metriktir ve sorgu doğruluğunu değerlendirmek için kullanılır.\n",
        "\n",
        "## Önemli Noktalar:\n",
        "* ## İndeksler, retrieval-augmented generative AI'de hassasiyeti ve hızı artırır.\n",
        "* ## İndeksler, RAG çıktılarına izlenebilirlik sağlar.\n",
        "* ## LlamaIndex, Deep Lake ve OpenAI ile entegre olur.\n",
        "* ## LlamaIndex, parçalama ve embedding işlemlerini otomatik olarak halleder.\n",
        "* ## Meta veri geliştirmeleri, RAG çıktılarının izlenebilirliğini sağlamak için önemlidir.\n",
        "* ## Kosinüs benzerliği, sorgu doğruluğunu değerlendirmek için kullanılan bir metriktir.\n",
        "\n",
        "## Kod Örnekleri:\n",
        "Aşağıdaki kod örnekleri, LlamaIndex'in nasıl kullanılacağını gösterir:\n",
        "```python\n",
        "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex\n",
        "\n",
        "# Veri yükleme\n",
        "documents = SimpleDirectoryReader('data').load_data()\n",
        "\n",
        "# İndeks oluşturma\n",
        "index = GPTVectorStoreIndex.from_documents(documents)\n",
        "\n",
        "# Sorgu yapma\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"Sorgu metni\")\n",
        "print(response)\n",
        "```\n",
        "## Kod Açıklaması:\n",
        "* `SimpleDirectoryReader`: Belirtilen dizindeki dosyaları okur ve `Document` nesnelerine dönüştürür.\n",
        "* `GPTVectorStoreIndex`: Yüklenen belgelerden bir indeks oluşturur.\n",
        "* `as_query_engine()`: İndeksi bir sorgu motoruna dönüştürür.\n",
        "* `query()`: Belirtilen sorguyu çalıştırır ve sonuçları döndürür.\n",
        "\n",
        "Bu kod, LlamaIndex kullanarak veri yüklemeyi, indeks oluşturmayı ve sorgu yapmayı gösterir."
      ],
      "metadata": {
        "id": "yLcWnLIDfl7X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKccaGuI6Irm",
        "outputId": "7c9f4103-23ce-41c2-cfee-144f9c286b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Sorular ve Cevaplar\n",
            "Aşağıdaki soruları Evet veya Hayır olarak cevaplayın:\n",
            "\n",
            "## Sorular\n",
            "1. ## İndeksler, retrieval-augmented generative AI'de (İyileştirilmiş üretken yapay zeka) hassasiyeti (precision) ve hızı (speed) artırır mı?\n",
            "Cevap: ## Evet\n",
            "Açıklama: İndeksler (Indexes), büyük veri kümelerinde (large datasets) arama yaparken (search) hızı ve hassasiyeti artırır. Retrieval-augmented generative AI (RAG), üretken yapay zeka modellerinin (generative AI models) dış bilgi kaynaklarına (external knowledge sources) erişimini sağlar ve indeksler bu süreçte önemli rol oynar.\n",
            "\n",
            "2. ## İndeksler, RAG çıktılarına (outputs) izlenebilirlik (traceability) sağlar mı?\n",
            "Cevap: ## Evet\n",
            "Açıklama: İndeksler, RAG modellerinin çıktılarına izlenebilirlik sağlar. Bu, modelin hangi bilgilere dayandığını (provenance) takip etmeyi mümkün kılar.\n",
            "\n",
            "3. ## İndeks tabanlı arama (index-based search), büyük veri kümelerinde vektör tabanlı aramadan (vector-based search) daha mı yavaştır?\n",
            "Cevap: ## Hayır\n",
            "Açıklama: İndeks tabanlı arama genellikle vektör tabanlı aramadan daha hızlıdır. Çünkü indeksler, verileri önceden işlenmiş (pre-processed) ve organize edilmiş bir şekilde saklar.\n",
            "\n",
            "4. ## LlamaIndex, Deep Lake ve OpenAI ile sorunsuz bir şekilde entegre olur mu?\n",
            "Cevap: ## Evet\n",
            "Açıklama: LlamaIndex, Deep Lake ve OpenAI gibi popüler araçlar ve platformlarla entegrasyon (integration) sağlar. Bu, geliştiricilerin (developers) farklı araçları bir arada kullanmalarını kolaylaştırır.\n",
            "\n",
            "5. ## Ağaç (tree), liste (list), vektör (vector) ve anahtar kelime (keyword) indeksleri, mevcut olan tek indeks türleri midir?\n",
            "Cevap: ## Hayır\n",
            "Açıklama: Farklı indeks türleri vardır. Ağaç, liste, vektör ve anahtar kelime indeksleri yaygın kullanılan türlerdir, ancak başka indeks türleri de mevcuttur.\n",
            "\n",
            "6. ## Anahtar kelime indeksi, veri alma işleminde anlamsal anlamaya (semantic understanding) dayanır mı?\n",
            "Cevap: ## Hayır\n",
            "Açıklama: Anahtar kelime indeksleri (keyword indexes), genellikle kelime eşleştirmesine (keyword matching) dayanır ve anlamsal anlamaya (semantic understanding) dayanmaz.\n",
            "\n",
            "7. ## LlamaIndex, parçalama (chunking) ve embedding işlemlerini otomatik olarak halleder mi?\n",
            "Cevap: ## Evet\n",
            "Açıklama: LlamaIndex, veri hazırlama (data preparation) süreçlerini otomatikleştirir, bu da parçalama ve embedding işlemlerini içerir.\n",
            "\n",
            "8. ## RAG tarafından üretilen çıktıların izlenebilirliğini sağlamak için meta veri (metadata) geliştirmeleri önemlidir?\n",
            "Cevap: ## Evet\n",
            "Açıklama: Meta veri geliştirmeleri, RAG çıktılarının izlenebilirliğini (traceability) sağlamak için önemlidir. Bu, modelin karar verme sürecini (decision-making process) anlamak için kritiktir.\n",
            "\n",
            "9. ## Gerçek zamanlı güncellemeler (real-time updates), indeks tabanlı arama sistemine kolayca uygulanabilir mi?\n",
            "Cevap: ## Hayır\n",
            "Açıklama: Gerçek zamanlı güncellemeler, indeks tabanlı arama sistemlerinde zor olabilir. Çünkü indekslerin güncellenmesi (index updates) zaman alabilir ve sistemin performansını (performance) etkileyebilir.\n",
            "\n",
            "10. ## Kosinüs benzerliği (cosine similarity), bu bölümde sorgu doğruluğunu (query accuracy) değerlendirmek için kullanılan bir metriktir?\n",
            "Cevap: ## Evet\n",
            "Açıklama: Kosinüs benzerliği, vektörler arasındaki benzerliği (vector similarity) ölçmek için kullanılan bir metriktir ve sorgu doğruluğunu değerlendirmek için kullanılır.\n",
            "\n",
            "## Önemli Noktalar:\n",
            "* ## İndeksler, retrieval-augmented generative AI'de hassasiyeti ve hızı artırır.\n",
            "* ## İndeksler, RAG çıktılarına izlenebilirlik sağlar.\n",
            "* ## LlamaIndex, Deep Lake ve OpenAI ile entegre olur.\n",
            "* ## LlamaIndex, parçalama ve embedding işlemlerini otomatik olarak halleder.\n",
            "* ## Meta veri geliştirmeleri, RAG çıktılarının izlenebilirliğini sağlamak için önemlidir.\n",
            "* ## Kosinüs benzerliği, sorgu doğruluğunu değerlendirmek için kullanılan bir metriktir.\n",
            "\n",
            "## Kod Örnekleri:\n",
            "Aşağıdaki kod örnekleri, LlamaIndex'in nasıl kullanılacağını gösterir:\n",
            "```python\n",
            "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex\n",
            "\n",
            "# Veri yükleme\n",
            "documents = SimpleDirectoryReader('data').load_data()\n",
            "\n",
            "# İndeks oluşturma\n",
            "index = GPTVectorStoreIndex.from_documents(documents)\n",
            "\n",
            "# Sorgu yapma\n",
            "query_engine = index.as_query_engine()\n",
            "response = query_engine.query(\"Sorgu metni\")\n",
            "print(response)\n",
            "```\n",
            "## Kod Açıklaması:\n",
            "* `SimpleDirectoryReader`: Belirtilen dizindeki dosyaları okur ve `Document` nesnelerine dönüştürür.\n",
            "* `GPTVectorStoreIndex`: Yüklenen belgelerden bir indeks oluşturur.\n",
            "* `as_query_engine()`: İndeksi bir sorgu motoruna dönüştürür.\n",
            "* `query()`: Belirtilen sorguyu çalıştırır ve sonuçları döndürür.\n",
            "\n",
            "Bu kod, LlamaIndex kullanarak veri yüklemeyi, indeks oluşturmayı ve sorgu yapmayı gösterir.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from together import Together\n",
        "\n",
        "def ask_together(content):\n",
        "\n",
        "    client = Together(api_key=\"07e297e19eaabe78c4ae52006f8d7ea67d6470727fff514aba20559fb273ea31\")\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\",\n",
        "    messages=[{\"role\":\"user\",\"content\":content}],\n",
        "    temperature=0.51,\n",
        "    top_p=0.91,\n",
        "    seed=198\n",
        ")\n",
        "    return print(response.choices[0].message.content)\n",
        "\n",
        "\n",
        "soru = \"\"\"\n",
        "\n",
        "Aşağıdaki paragrafta anlatılan konuyu türkçe olarak tekrar düzenle ve önemli noktaları maddeler halinde yaz aynı zamanda text içinde kodlar varsa yaz ve açıkla  , türkçenin yanına ingilizce teknik terimleri parantez içinde eklermisin , ayrıca konu da önemli gördüğün eklemeleri yapabilirsin , tüm yazıları markdown ##yazı şeklinde yaz , Lütfen tüm kodları eksiksiz olarak yaz , kodlar tam olarak birebir aynı olmalıdır,Ayrıca kodları ayrıntılı olarak açıkla nerede ve nasıl kullanıldığını kodun altına yaz,Texte olan tüm konuları eklemelisin\n",
        "\n",
        "\n",
        "-----------------------------------------------------------------BAŞLA------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Questions\n",
        "Answer the following questions with Yes or No:\n",
        "\n",
        "Do indexes increase precision and speed in retrieval-augmented generative AI?\n",
        "Can indexes offer traceability for RAG outputs?\n",
        "Is index-based search slower than vector-based search for large datasets?\n",
        "Does LlamaIndex integrate seamlessly with Deep Lake and OpenAI?\n",
        "Are tree, list, vector, and keyword indexes the only types of indexes?\n",
        "Does the keyword index rely on semantic understanding to retrieve data?\n",
        "Is LlamaIndex capable of automatically handling chunking and embedding?\n",
        "Are metadata enhancements crucial for ensuring the traceability of RAG-generated outputs?\n",
        "Can real-time updates easily be applied to an index-based search system?\n",
        "Is cosine similarity a metric used in this chapter to evaluate query accuracy?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "-------------------------------------BİTİR----------------------------------------------\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ask_together(soru)"
      ]
    }
  ]
}